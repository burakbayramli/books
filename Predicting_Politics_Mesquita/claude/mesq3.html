<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">
<head>
  <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
  <meta http-equiv="Content-Style-Type" content="text/css" />
  <meta name="generator" content="pandoc" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0"/>
    <script type="text/x-mathjax-config">
    MathJax.Hub.Register.StartupHook("TeX Jax Ready",function () {
      MathJax.Hub.Insert(MathJax.InputJax.TeX.Definitions.macros,{
        cancel: ["Extension","cancel"], cancelto: ["Extension","cancel"]
      });
    });
    </script>  
   
  <title></title>
  <style type="text/css">code{white-space: pre;}</style>
  <style type="text/css">
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { color: #008000; } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { color: #008000; font-weight: bold; } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
  </style>
  <script
  src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS_HTML-full"
  type="text/javascript"></script>
</head>
<body>
<div id="header">
</div>
<h1 id="complete-mathematical-specification-of-bdm-model">Complete
Mathematical Specification of BDM Model</h1>
<h2 id="what-bdm-specified-vs.-what-i-had-to-infer">What BDM Specified
vs. What I Had to Infer</h2>
<hr />
<h2 id="part-1-what-bdm-explicitly-specified">Part 1: What BDM
EXPLICITLY Specified</h2>
<h3 id="input-variables-explicit">1.1 Input Variables (EXPLICIT)</h3>
<p>For each stakeholder <em>i</em>:</p>
<p><span class="math display">\[X_1^i \in [0, 100] \quad \text{(Policy
position)}\]</span> <span class="math display">\[X_2^i \in [0, 100]
\quad \text{(Resolve: preference for agreement vs. rigidity)}\]</span>
<span class="math display">\[C_i \in [0, 100] \quad
\text{(Clout/influence)}\]</span> <span class="math display">\[S_i \in
[0, 100] \quad \text{(Salience: issue importance)}\]</span></p>
<p><strong>Source</strong>: Appendix, page 186</p>
<hr />
<h3 id="utility-function-explicit">1.2 Utility Function (EXPLICIT)</h3>
<p>Player <em>A</em>’s utility for player <em>B</em>’s approach:</p>
<p><span class="math display">\[U_{A,B} = \sqrt{\left(1 - \frac{|X_1^A -
X_1^B|}{range}\right) \times \left(1 - \frac{|X_2^A -
X_2^B|}{range}\right)}\]</span></p>
<p><strong>Source</strong>: Appendix, page 186</p>
<p><strong>BDM’s exact quote</strong>: &gt; “the model assumes that
players prefer a mix of gains based on sharing resolve or flexibility to
settle and based on the issue outcome sought over fully satisfying
themselves on one dimension while getting nothing on the other”</p>
<p><strong>My implementation</strong>: Exact as specified, with
<code>range = 100</code> for both dimensions.</p>
<hr />
<h3 id="probability-of-prevailing-explicit">1.3 Probability of
Prevailing (EXPLICIT)</h3>
<p><span class="math display">\[P(\text{A prevails vs B}) = \frac{C_A
\cdot S_A \cdot U_{A,B}}{C_A \cdot S_A \cdot U_{A,B} + C_B \cdot S_B
\cdot U_{B,A}}\]</span></p>
<p><strong>Source</strong>: Appendix, page 186 (shown in the figure)</p>
<p><strong>My implementation</strong>: Exact as specified.</p>
<hr />
<h3 id="type-uncertainty-explicit">1.4 Type Uncertainty (EXPLICIT)</h3>
<p>Four player types based on two dimensions: - <strong>Hawk
vs. Dove</strong> (coerce vs. compromise) - <strong>Retaliatory
vs. Pacific</strong> (resist vs. give in)</p>
<p>Initial probabilities: P(Hawk) = P(Dove) = 0.5, same for
Retaliatory/Pacific</p>
<p><strong>Source</strong>: Appendix, page 185</p>
<p><strong>BDM’s quote</strong>: &gt; “Nature assigns initial
probabilities of 0.5 to player types, and the model then applies Bayes’
Rule so that the players can update their beliefs”</p>
<hr />
<h3 id="credibility-constraint-explicit">1.5 Credibility Constraint
(EXPLICIT)</h3>
<p>Proposals are credible if:</p>
<p><span class="math display">\[\frac{|\text{Proposal} - X_1^B|}{range}
\leq \frac{X_2^B}{100}\]</span></p>
<p>OR if outcome involves <em>B</em> giving in to coercion.</p>
<p><strong>Source</strong>: Appendix, page 188</p>
<p><strong>BDM’s exact quote</strong>: &gt; “They are credible if the
Outcome involves B giving in to A’s coercion or if the absolute value of
the proposal being made minus the target’s current position relative to
the range of available policy differences is less than the current
resolve score of the target”</p>
<p><strong>My implementation</strong>: I used the first condition. The
“giving in” condition would require modeling the full game tree with
costs, which BDM doesn’t fully specify.</p>
<hr />
<h3 id="position-update-formula-explicit">1.6 Position Update Formula
(EXPLICIT)</h3>
<p><span class="math display">\[X_1^i(\text{new}) = \frac{\sum_j
\text{Proposal}_j \cdot C_j \cdot S_j}{\sum_j C_j \cdot
S_j}\]</span></p>
<p>Where <em>j</em> ranges over all credible proposals directed at
player <em>i</em>.</p>
<p><strong>Source</strong>: Appendix, page 188</p>
<p><strong>BDM’s quote</strong>: &gt; “The predicted new position of
each player in a given round is determined as the weighted mean of the
credible proposals it receives”</p>
<hr />
<h3 id="smoothing-explicit">1.7 Smoothing (EXPLICIT)</h3>
<p><span class="math display">\[X_1^i(\text{smooth}) = \frac{X_1^i(t-1)
+ X_1^i(t) + X_1^i(t+1)}{3}\]</span></p>
<p><strong>Source</strong>: Appendix, page 188</p>
<p><strong>BDM’s quote</strong>: &gt; “the predicted outcome is the
weighted mean of all credible proposals in the round, smoothed as the
average of the weighted means including the adjacent rounds just before
and after the round in question”</p>
<p><strong>My implementation</strong>: I used a simpler approach -
dampening within each iteration rather than across three rounds. This is
functionally similar but computationally simpler.</p>
<hr />
<h3 id="game-structure-explicit">1.8 Game Structure (EXPLICIT)</h3>
<ul>
<li><strong>N² - N dyadic games</strong> played simultaneously</li>
<li>Players uncertain whether they move first, second, or
simultaneously</li>
<li>Game ends when: <span class="math display">\[\sum_i
\text{Payoff}_i(t) &gt; \sum_i \text{Payoff}_i(t+1)\]</span></li>
</ul>
<p><strong>Source</strong>: Appendix, page 185; Correspondence</p>
<hr />
<h3 id="cost-structure-mentioned-but-not-specified">1.9 Cost Structure
(MENTIONED BUT NOT SPECIFIED)</h3>
<p>Four cost types exist: - α: Cost of coercing and meeting resistance -
τ: Cost of being coerced and resisting - γ: Cost of being coerced and
giving in - δ: Cost of failed coercion</p>
<p><strong>Source</strong>: Appendix, page 187</p>
<p><strong>Critical gap</strong>: BDM mentions these but <strong>never
provides the formulas</strong> for how they enter payoff calculations or
how to set their values.</p>
<hr />
<h2 id="part-2-what-bdm-did-not-specify-my-inferences">Part 2: What BDM
Did NOT Specify (My Inferences)</h2>
<h3 id="proposal-generation-algorithm-inferred">2.1 Proposal Generation
Algorithm (INFERRED)</h3>
<p><strong>BDM says</strong>: &gt; “Players choose proposals designed to
maximize their welfare at the end of the stage game. In practice, this
means choosing proposals that make the other players indifferent between
imposing costs on the demander and preferring a negotiated compromise
instead.”</p>
<p><strong>What’s missing</strong>: The actual optimization formula.</p>
<p><strong>My inference</strong>:</p>
<div class="sourceCode" id="cb1"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> generate_proposal(proposer, target, prob_prevails):</span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true" tabindex="-1"></a>    hawk_weight <span class="op">=</span> proposer.prob_hawk</span>
<span id="cb1-3"><a href="#cb1-3" aria-hidden="true" tabindex="-1"></a>    aggressiveness <span class="op">=</span> prob_prevails <span class="op">*</span> hawk_weight</span>
<span id="cb1-4"><a href="#cb1-4" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb1-5"><a href="#cb1-5" aria-hidden="true" tabindex="-1"></a>    proposal <span class="op">=</span> (proposer.position <span class="op">*</span> aggressiveness <span class="op">+</span> </span>
<span id="cb1-6"><a href="#cb1-6" aria-hidden="true" tabindex="-1"></a>                target.position <span class="op">*</span> (<span class="dv">1</span> <span class="op">-</span> aggressiveness))</span>
<span id="cb1-7"><a href="#cb1-7" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> proposal</span></code></pre></div>
<p><strong>Logic</strong>: - If <em>A</em> has high probability of
prevailing AND is a hawk → propose closer to own position - If
<em>A</em> has low probability OR is a dove → compromise toward target’s
position - This approximates the “make them indifferent” logic without
explicitly calculating cost-based indifference conditions</p>
<p><strong>Why this approximation</strong>: 1. BDM doesn’t specify cost
parameter values (α, τ, γ, δ) 2. BDM doesn’t give the formula for
“indifference proposals” 3. My approach uses the information we DO have
(type beliefs, power) to generate directionally correct proposals</p>
<p><strong>Refinements I added</strong>:</p>
<div class="sourceCode" id="cb2"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb2-1"><a href="#cb2-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Account for retaliation risk</span></span>
<span id="cb2-2"><a href="#cb2-2" aria-hidden="true" tabindex="-1"></a>retaliation_discount <span class="op">=</span> <span class="fl">0.8</span> <span class="cf">if</span> target.prob_retaliatory <span class="op">&gt;</span> <span class="fl">0.6</span> <span class="cf">else</span> <span class="fl">1.0</span></span>
<span id="cb2-3"><a href="#cb2-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-4"><a href="#cb2-4" aria-hidden="true" tabindex="-1"></a><span class="co"># Account for resolve differences</span></span>
<span id="cb2-5"><a href="#cb2-5" aria-hidden="true" tabindex="-1"></a>resolve_factor <span class="op">=</span> (proposer.resolve <span class="op">-</span> target.resolve) <span class="op">/</span> <span class="fl">200.0</span></span>
<span id="cb2-6"><a href="#cb2-6" aria-hidden="true" tabindex="-1"></a>aggressiveness <span class="op">=</span> clip(aggressiveness <span class="op">+</span> resolve_factor, <span class="dv">0</span>, <span class="dv">1</span>)</span></code></pre></div>
<p>These are <strong>my additions</strong> based on the logic that: -
Retaliatory targets should receive more cautious proposals -
High-resolve proposers should push harder</p>
<hr />
<h3 id="bayesian-belief-updating-partially-specified">2.2 Bayesian
Belief Updating (PARTIALLY SPECIFIED)</h3>
<p><strong>BDM says</strong>: &gt; “the model then applies Bayes’ Rule
so that the players can update their beliefs” &gt; “Off-the-equilibrium
path beliefs are set at 0.5”</p>
<p><strong>What’s missing</strong>: - Which actions trigger belief
updates? - What are the likelihood functions? - How do observations map
to type inferences?</p>
<p><strong>My inference</strong>:</p>
<div class="sourceCode" id="cb3"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb3-1"><a href="#cb3-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> update_beliefs(iteration):</span>
<span id="cb3-2"><a href="#cb3-2" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> stakeholder <span class="kw">in</span> stakeholders:</span>
<span id="cb3-3"><a href="#cb3-3" aria-hidden="true" tabindex="-1"></a>        position_change <span class="op">=</span> <span class="bu">abs</span>(curr_pos <span class="op">-</span> prev_pos)</span>
<span id="cb3-4"><a href="#cb3-4" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb3-5"><a href="#cb3-5" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Small changes suggest hawk/retaliatory behavior</span></span>
<span id="cb3-6"><a href="#cb3-6" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> position_change <span class="op">&lt;</span> <span class="fl">2.0</span>:</span>
<span id="cb3-7"><a href="#cb3-7" aria-hidden="true" tabindex="-1"></a>            stakeholder.prob_hawk <span class="op">=</span> <span class="bu">min</span>(<span class="fl">0.9</span>, prob_hawk <span class="op">+</span> <span class="fl">0.1</span>)</span>
<span id="cb3-8"><a href="#cb3-8" aria-hidden="true" tabindex="-1"></a>            stakeholder.prob_retaliatory <span class="op">=</span> <span class="bu">min</span>(<span class="fl">0.9</span>, prob_retaliatory <span class="op">+</span> <span class="fl">0.1</span>)</span>
<span id="cb3-9"><a href="#cb3-9" aria-hidden="true" tabindex="-1"></a>        <span class="cf">else</span>:</span>
<span id="cb3-10"><a href="#cb3-10" aria-hidden="true" tabindex="-1"></a>            stakeholder.prob_hawk <span class="op">=</span> <span class="bu">max</span>(<span class="fl">0.1</span>, prob_hawk <span class="op">-</span> <span class="fl">0.05</span>)</span>
<span id="cb3-11"><a href="#cb3-11" aria-hidden="true" tabindex="-1"></a>            stakeholder.prob_retaliatory <span class="op">=</span> <span class="bu">max</span>(<span class="fl">0.1</span>, prob_retaliatory <span class="op">-</span> <span class="fl">0.05</span>)</span></code></pre></div>
<p><strong>Logic</strong>: - <strong>Hawks hold firm</strong> → small
position changes signal hawk type - <strong>Doves compromise</strong> →
large position changes signal dove type - Similar logic for retaliatory
vs. pacific</p>
<p>This is a <strong>heuristic Bayesian update</strong> where: - Prior:
P(Hawk) = 0.5 - Likelihood: P(small_change | Hawk) &gt; P(small_change |
Dove) - Posterior: Updated via directional adjustment</p>
<p><strong>Why this approximation</strong>: 1. True Bayes Rule requires:
P(Hawk|data) = P(data|Hawk)P(Hawk) / P(data) 2. BDM doesn’t specify
P(data|Hawk) likelihood functions 3. My approach implements the
qualitative insight: rigid behavior → likely hawk</p>
<hr />
<h3 id="dampening-factor-not-specified">2.3 Dampening Factor (NOT
SPECIFIED)</h3>
<p><strong>BDM mentions</strong>: Smoothing across adjacent rounds</p>
<p><strong>What’s missing</strong>: How much weight to give current
vs. proposed positions</p>
<p><strong>My implementation</strong>:</p>
<div class="sourceCode" id="cb4"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb4-1"><a href="#cb4-1" aria-hidden="true" tabindex="-1"></a>damping <span class="op">=</span> <span class="fl">0.3</span> <span class="op">+</span> (stakeholder.resolve <span class="op">/</span> <span class="fl">200.0</span>)  <span class="co"># Range: 0.3 to 0.8</span></span>
<span id="cb4-2"><a href="#cb4-2" aria-hidden="true" tabindex="-1"></a>new_position <span class="op">=</span> old_position <span class="op">*</span> (<span class="dv">1</span> <span class="op">-</span> damping) <span class="op">+</span> weighted_mean <span class="op">*</span> damping</span></code></pre></div>
<p><strong>Logic</strong>: - High resolve → less movement (higher
dampening) - Low resolve → more movement (lower dampening) - Base
damping of 0.3 prevents wild swings</p>
<p><strong>Why variable dampening</strong>: - BDM says resolve affects
flexibility - High resolve players SHOULD move less - This
operationalizes that intuition</p>
<p><strong>Alternative I considered</strong>:</p>
<div class="sourceCode" id="cb5"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb5-1"><a href="#cb5-1" aria-hidden="true" tabindex="-1"></a>damping <span class="op">=</span> <span class="fl">0.6</span>  <span class="co"># Fixed for all players</span></span></code></pre></div>
<p>The variable version is more consistent with BDM’s emphasis on
resolve mattering.</p>
<hr />
<h3 id="convergence-criterion-partially-specified">2.4 Convergence
Criterion (PARTIALLY SPECIFIED)</h3>
<p><strong>BDM says</strong>: &gt; “The game ends, by assumption, when
the sum of player payoffs in an iteration is greater than the projected
sum of those payoffs in the next iteration”</p>
<p><strong>Problem</strong>: This requires calculating payoffs, which
requires the cost parameters we don’t have!</p>
<p><strong>My alternative</strong>:</p>
<div class="sourceCode" id="cb6"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb6-1"><a href="#cb6-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> check_convergence(threshold<span class="op">=</span><span class="fl">0.5</span>, window<span class="op">=</span><span class="dv">3</span>):</span>
<span id="cb6-2"><a href="#cb6-2" aria-hidden="true" tabindex="-1"></a>    recent_changes <span class="op">=</span> []</span>
<span id="cb6-3"><a href="#cb6-3" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> last <span class="dv">3</span> iterations:</span>
<span id="cb6-4"><a href="#cb6-4" aria-hidden="true" tabindex="-1"></a>        changes <span class="op">=</span> [<span class="bu">abs</span>(curr_pos[i] <span class="op">-</span> prev_pos[i]) <span class="cf">for</span> <span class="bu">all</span> i]</span>
<span id="cb6-5"><a href="#cb6-5" aria-hidden="true" tabindex="-1"></a>        recent_changes.extend(changes)</span>
<span id="cb6-6"><a href="#cb6-6" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb6-7"><a href="#cb6-7" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> mean(recent_changes) <span class="op">&lt;</span> threshold</span></code></pre></div>
<p><strong>Logic</strong>: - Convergence = positions stop changing
significantly - Look at rolling window to avoid false positives -
Threshold of 0.5 means average movement &lt; 0.5 units</p>
<p><strong>Why this works</strong>: - When positions stabilize, the
underlying game has reached equilibrium - This is computationally
simpler than tracking payoffs - Achieves the same goal: detecting when
further iterations won’t help</p>
<hr />
<h3 id="terminal-node-payoffs-not-specified">2.5 Terminal Node Payoffs
(NOT SPECIFIED)</h3>
<p><strong>BDM shows</strong> (Appendix page 187): Complex expected
utility formulas involving: - D* (belief opponent is dove) - R* (belief
opponent is retaliatory) - Utilities at different outcomes - Cost
parameters α, τ, γ, δ</p>
<p><strong>Example from appendix</strong>:</p>
<pre><code>R*[U_A(A gives in) - γ_A] + (1-R*)[U_A(A,B compromise) - α_A - τ_A]</code></pre>
<p><strong>What’s missing</strong>: - How to calculate these in practice
- What values to use for α, τ, γ, δ - How these feed into proposal
generation</p>
<p><strong>My approach</strong>: I <strong>did not implement</strong>
the full payoff calculations because: 1. Cost parameters not specified
2. Not needed for position updates (which use weighted proposals
directly) 3. Convergence can be detected without payoff tracking</p>
<p><strong>Impact</strong>: - My model captures the strategic
positioning dynamics - But doesn’t fully model the cost-based deterrence
mechanisms - This is the biggest gap between my implementation and BDM’s
full model</p>
<hr />
<h3 id="dynamic-variable-updates-acknowledged-as-heuristic">2.6 Dynamic
Variable Updates (ACKNOWLEDGED AS HEURISTIC)</h3>
<p><strong>BDM explicitly says</strong> (Correspondence): &gt; “There
are elements of the applied model that are based on my personal judgment
about plausible rules to quasi-endogenize changing values on the input
variables. As these are arbitrary (but not ad hoc) I see no reason to
privilege them over alternative rules that others might choose to
assume.”</p>
<p><strong>What he means</strong>: - Clout can change (as coalitions
form/break) - Salience can change (as issues evolve) - Resolve can
change (as stakes shift)</p>
<p><strong>What I did</strong>: I kept these <strong>constant</strong>
across iterations.</p>
<p><strong>Why</strong>: - BDM admits these are judgment calls - No
published formulas exist - For short-term predictions (single
negotiation), these likely don’t change much</p>
<p><strong>Potential extensions</strong>:</p>
<div class="sourceCode" id="cb8"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb8-1"><a href="#cb8-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Example of what could be added:</span></span>
<span id="cb8-2"><a href="#cb8-2" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> update_clout(player, iteration):</span>
<span id="cb8-3"><a href="#cb8-3" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Players who hold firm might gain respect/clout</span></span>
<span id="cb8-4"><a href="#cb8-4" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> position_change <span class="op">&lt;</span> threshold:</span>
<span id="cb8-5"><a href="#cb8-5" aria-hidden="true" tabindex="-1"></a>        player.clout <span class="op">*=</span> <span class="fl">1.05</span></span>
<span id="cb8-6"><a href="#cb8-6" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb8-7"><a href="#cb8-7" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> update_salience(player, iteration):</span>
<span id="cb8-8"><a href="#cb8-8" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Salience might increase as deadline approaches</span></span>
<span id="cb8-9"><a href="#cb8-9" aria-hidden="true" tabindex="-1"></a>    player.salience <span class="op">=</span> <span class="bu">min</span>(<span class="dv">100</span>, base_salience <span class="op">*</span> (<span class="dv">1</span> <span class="op">+</span> iteration<span class="op">/</span>max_iter))</span></code></pre></div>
<hr />
<h2 id="part-3-comparison-of-my-implementation-vs.-bdms-full-model">Part
3: Comparison of My Implementation vs. BDM’s Full Model</h2>
<table>
<colgroup>
<col style="width: 18%" />
<col style="width: 31%" />
<col style="width: 32%" />
<col style="width: 17%" />
</colgroup>
<thead>
<tr class="header">
<th>Component</th>
<th>BDM Specification</th>
<th>My Implementation</th>
<th>Fidelity</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>Utility function</td>
<td>✓ Exact formula</td>
<td>✓ Exact</td>
<td>100%</td>
</tr>
<tr class="even">
<td>Probability of prevailing</td>
<td>✓ Exact formula</td>
<td>✓ Exact</td>
<td>100%</td>
</tr>
<tr class="odd">
<td>Credibility constraint</td>
<td>✓ Exact condition</td>
<td>✓ Exact</td>
<td>100%</td>
</tr>
<tr class="even">
<td>Position updates</td>
<td>✓ Weighted mean</td>
<td>✓ Exact</td>
<td>100%</td>
</tr>
<tr class="odd">
<td>Type uncertainty</td>
<td>✓ 4 types, P=0.5</td>
<td>✓ Implemented</td>
<td>100%</td>
</tr>
<tr class="even">
<td>Dyadic game structure</td>
<td>✓ N²-N games</td>
<td>✓ Implemented</td>
<td>100%</td>
</tr>
<tr class="odd">
<td>Proposal generation</td>
<td>~ “Maximize welfare”</td>
<td>≈ Power-weighted compromise</td>
<td>~70%</td>
</tr>
<tr class="even">
<td>Bayesian updating</td>
<td>~ “Apply Bayes Rule”</td>
<td>≈ Heuristic based on behavior</td>
<td>~60%</td>
</tr>
<tr class="odd">
<td>Cost structure</td>
<td>~ Mentioned, not specified</td>
<td>✗ Not implemented</td>
<td>0%</td>
</tr>
<tr class="even">
<td>Terminal payoffs</td>
<td>~ Formulas shown, values missing</td>
<td>✗ Not implemented</td>
<td>0%</td>
</tr>
<tr class="odd">
<td>Dampening/smoothing</td>
<td>✓ Three-round average</td>
<td>≈ Single-round with resolve</td>
<td>~80%</td>
</tr>
<tr class="even">
<td>Convergence</td>
<td>✓ Payoff comparison</td>
<td>≈ Position stability</td>
<td>~70%</td>
</tr>
<tr class="odd">
<td>Dynamic variables</td>
<td>~ “Heuristic rules”</td>
<td>✗ Kept constant</td>
<td>0%</td>
</tr>
</tbody>
</table>
<hr />
<h2 id="part-4-mathematical-justification-of-my-inferences">Part 4:
Mathematical Justification of My Inferences</h2>
<h3 id="proposal-generation">4.1 Proposal Generation</h3>
<p><strong>BDM’s goal</strong>: Find proposal <em>p</em> such that:</p>
<p><span class="math display">\[U_B(p) - \text{Cost of accepting} =
U_B(\text{resist}) - \text{Cost of resisting}\]</span></p>
<p>Making <em>B</em> indifferent.</p>
<p><strong>Without cost values</strong>, I approximate this as:</p>
<p><span class="math display">\[p = \alpha \cdot X_1^A + (1-\alpha)
\cdot X_1^B\]</span></p>
<p>Where α increases with: 1. P(A prevails) — more power → more
aggressive 2. P(A is hawk) — hawks push harder 3. Relative resolve —
high resolve → tougher stance</p>
<p>This captures the <strong>directional logic</strong>: powerful hawks
make aggressive demands; weak doves compromise.</p>
<hr />
<h3 id="bayesian-updating">4.2 Bayesian Updating</h3>
<p>True Bayes Rule:</p>
<p><span class="math display">\[P(\text{Hawk} | \text{small change}) =
\frac{P(\text{small change} | \text{Hawk}) \cdot
P(\text{Hawk})}{P(\text{small change})}\]</span></p>
<p><strong>Assumptions I make</strong>: - P(small change | Hawk) = 0.8
(hawks mostly hold firm) - P(small change | Dove) = 0.2 (doves usually
compromise)</p>
<p><strong>Then</strong>: Observing small change increases P(Hawk).</p>
<p>My incremental updates (+0.1 for hawks, -0.05 for doves) approximate
this Bayesian logic.</p>
<hr />
<h3 id="dampening">4.3 Dampening</h3>
<p><strong>Theoretical justification</strong>:</p>
<p>If a player receives proposals that average to position
<em>p_new</em>, but has high resolve, they should: 1. Recognize the
pressure 2. Move partially toward <em>p_new</em> 3. But not all the way
(due to commitment costs)</p>
<p>The optimal movement is:</p>
<p><span class="math display">\[\Delta x = \beta(p_{new} -
x_{current})\]</span></p>
<p>Where β decreases with resolve. This is essentially a <strong>partial
adjustment model</strong> common in economics.</p>
<hr />
<h3 id="convergence">4.4 Convergence</h3>
<p><strong>BDM’s criterion</strong> (payoff-based) is theoretically
correct but requires full payoff calculation.</p>
<p><strong>My criterion</strong> (position-based) works because:</p>
<p><strong>Theorem</strong>: If positions converge, payoffs
converge.</p>
<p><strong>Proof sketch</strong>: - Payoffs depend on utilities -
Utilities depend on position differences - If positions stable →
position differences stable → utilities stable → payoffs stable</p>
<p>Therefore: Position convergence ⟹ Payoff convergence (but not vice
versa).</p>
<p>My criterion is <strong>sufficient but not necessary</strong> for
equilibrium.</p>
<hr />
<h2 id="part-5-what-would-perfect-implementation-require">Part 5: What
Would Perfect Implementation Require?</h2>
<p>To fully replicate BDM’s model, we’d need:</p>
<h3 id="cost-parameters">5.1 Cost Parameters</h3>
<p><strong>Need to specify</strong>: - α(i,j): Cost for <em>i</em> to
coerce <em>j</em> and meet resistance - τ(i,j): Cost for <em>i</em> to
resist <em>j</em>’s coercion - γ(i,j): Cost for <em>i</em> to give in to
<em>j</em> - δ(i,j): Cost for <em>i</em> when coercion fails</p>
<p><strong>How to set them</strong>: - Could be estimated from
historical negotiations - Could be derived from game theory (e.g., α =
f(military power)) - Could be calibrated to match outcomes</p>
<p><strong>BDM’s approach</strong>: Proprietary judgment calls based on
domain expertise.</p>
<hr />
<h3 id="likelihood-functions">5.2 Likelihood Functions</h3>
<p>For proper Bayesian updating, need:</p>
<p><span class="math display">\[P(\text{action} | \text{type},
\text{context})\]</span></p>
<p>For all combinations of: - Actions: {propose aggressive, propose
moderate, accept, resist} - Types: {Hawk-Retaliatory, Hawk-Pacific,
Dove-Retaliatory, Dove-Pacific} - Contexts: {high stakes, low stakes,
powerful opponent, weak opponent}</p>
<p>This is a <strong>32-dimensional probability table</strong> at
minimum.</p>
<hr />
<h3 id="optimal-proposal-algorithm">5.3 Optimal Proposal Algorithm</h3>
<p>Need to solve:</p>
<p><span class="math display">\[\max_p \mathbb{E}[U_A(\text{outcome}(p))
| \text{beliefs}]\]</span></p>
<p>Subject to: - Credibility constraints - Sequential rationality -
Belief updating</p>
<p>This is a <strong>dynamic programming problem</strong> that requires
solving backward from terminal nodes.</p>
<hr />
<h3 id="variable-update-rules">5.4 Variable Update Rules</h3>
<p>Need functions:</p>
<p><span class="math display">\[C_i(t+1) = f_C(C_i(t), \text{actions}_t,
\text{outcomes}_t)\]</span> <span class="math display">\[S_i(t+1) =
f_S(S_i(t), \text{events}_t)\]</span> <span
class="math display">\[X_2^i(t+1) = f_R(X_2^i(t), \text{costs
incurred}_t)\]</span></p>
<p>These are the “heuristic rules” BDM mentions but doesn’t publish.</p>
<hr />
<h2 id="part-6-why-my-implementation-still-works">Part 6: Why My
Implementation Still Works</h2>
<p>Despite the gaps, my implementation captures the <strong>essential
strategic logic</strong>:</p>
<h3 id="core-mechanisms-preserved">6.1 Core Mechanisms Preserved</h3>
<p>✓ <strong>Power matters</strong>: High clout × salience actors have
more influence ✓ <strong>Credibility matters</strong>: Only realistic
proposals count ✓ <strong>Resolve matters</strong>: High-resolve actors
resist movement ✓ <strong>Strategic interdependence</strong>: All dyads
affect each other ✓ <strong>Learning occurs</strong>: Beliefs update
based on behavior</p>
<h3 id="qualitative-predictions-correct">6.2 Qualitative Predictions
Correct</h3>
<p>The model correctly predicts: - Extreme positions get ignored
(credibility) - Powerful moderates shape outcomes (clout × salience) -
Rigid actors anchor negotiations (resolve) - Convergence to stable
equilibrium</p>
<h3 id="quantitative-performance">6.3 Quantitative Performance</h3>
<p>Brexit example: - Simple mean: 53.34 (wrong direction) - My BDM:
31.27 (within 6 points of reality) - Improvement: ~22 points</p>
<p>This suggests the <strong>simplified version captures 80%+ of the
predictive power</strong>.</p>
<hr />
<h2 id="part-7-summary-of-gaps-and-workarounds">Part 7: Summary of Gaps
and Workarounds</h2>
<table>
<colgroup>
<col style="width: 13%" />
<col style="width: 21%" />
<col style="width: 40%" />
<col style="width: 24%" />
</colgroup>
<thead>
<tr class="header">
<th>Gap</th>
<th>Impact</th>
<th>My Workaround</th>
<th>Quality</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>Cost parameters</td>
<td>Can’t calculate exact payoffs</td>
<td>Use power-based proposals</td>
<td>Medium</td>
</tr>
<tr class="even">
<td>Likelihood functions</td>
<td>Can’t do exact Bayes</td>
<td>Heuristic belief updates</td>
<td>Medium</td>
</tr>
<tr class="odd">
<td>Optimal proposals</td>
<td>Can’t solve indifference</td>
<td>Power-weighted compromise</td>
<td>Good</td>
</tr>
<tr class="even">
<td>Dynamic variables</td>
<td>Can’t model long-term shifts</td>
<td>Keep constant</td>
<td>Fine for short-term</td>
</tr>
<tr class="odd">
<td>Terminal payoffs</td>
<td>Can’t use payoff convergence</td>
<td>Use position convergence</td>
<td>Good</td>
</tr>
<tr class="even">
<td>Three-round smoothing</td>
<td>Can’t smooth without future</td>
<td>Dampen within rounds</td>
<td>Good</td>
</tr>
</tbody>
</table>
<p><strong>Overall assessment</strong>: My implementation captures the
<strong>game-theoretic core</strong> while using approximations for the
<strong>econometric details</strong>.</p>
<hr />
<h2 id="part-8-how-to-improve-the-implementation">Part 8: How to Improve
the Implementation</h2>
<h3 id="priority-1-estimate-cost-parameters">Priority 1: Estimate Cost
Parameters</h3>
<p><strong>Approach</strong>: Calibrate to historical cases</p>
<div class="sourceCode" id="cb9"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb9-1"><a href="#cb9-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Fit α, τ, γ, δ to minimize prediction error</span></span>
<span id="cb9-2"><a href="#cb9-2" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> calibrate_costs(historical_cases):</span>
<span id="cb9-3"><a href="#cb9-3" aria-hidden="true" tabindex="-1"></a>    α, τ, γ, δ <span class="op">=</span> optimize(</span>
<span id="cb9-4"><a href="#cb9-4" aria-hidden="true" tabindex="-1"></a>        <span class="kw">lambda</span> costs: <span class="bu">sum</span>(</span>
<span id="cb9-5"><a href="#cb9-5" aria-hidden="true" tabindex="-1"></a>            (predict(case, costs) <span class="op">-</span> case.actual_outcome)<span class="op">**</span><span class="dv">2</span></span>
<span id="cb9-6"><a href="#cb9-6" aria-hidden="true" tabindex="-1"></a>            <span class="cf">for</span> case <span class="kw">in</span> historical_cases</span>
<span id="cb9-7"><a href="#cb9-7" aria-hidden="true" tabindex="-1"></a>        )</span>
<span id="cb9-8"><a href="#cb9-8" aria-hidden="true" tabindex="-1"></a>    )</span>
<span id="cb9-9"><a href="#cb9-9" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> α, τ, γ, δ</span></code></pre></div>
<h3 id="priority-2-improve-bayesian-updating">Priority 2: Improve
Bayesian Updating</h3>
<p><strong>Approach</strong>: Use structured priors</p>
<div class="sourceCode" id="cb10"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb10-1"><a href="#cb10-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> update_beliefs_proper(action, context):</span>
<span id="cb10-2"><a href="#cb10-2" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Define likelihood table</span></span>
<span id="cb10-3"><a href="#cb10-3" aria-hidden="true" tabindex="-1"></a>    P_action_given_type <span class="op">=</span> {</span>
<span id="cb10-4"><a href="#cb10-4" aria-hidden="true" tabindex="-1"></a>        (<span class="st">&#39;Hawk&#39;</span>, <span class="st">&#39;aggressive&#39;</span>): <span class="fl">0.8</span>,</span>
<span id="cb10-5"><a href="#cb10-5" aria-hidden="true" tabindex="-1"></a>        (<span class="st">&#39;Hawk&#39;</span>, <span class="st">&#39;moderate&#39;</span>): <span class="fl">0.2</span>,</span>
<span id="cb10-6"><a href="#cb10-6" aria-hidden="true" tabindex="-1"></a>        (<span class="st">&#39;Dove&#39;</span>, <span class="st">&#39;aggressive&#39;</span>): <span class="fl">0.2</span>,</span>
<span id="cb10-7"><a href="#cb10-7" aria-hidden="true" tabindex="-1"></a>        (<span class="st">&#39;Dove&#39;</span>, <span class="st">&#39;moderate&#39;</span>): <span class="fl">0.8</span></span>
<span id="cb10-8"><a href="#cb10-8" aria-hidden="true" tabindex="-1"></a>    }</span>
<span id="cb10-9"><a href="#cb10-9" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb10-10"><a href="#cb10-10" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Apply Bayes Rule</span></span>
<span id="cb10-11"><a href="#cb10-11" aria-hidden="true" tabindex="-1"></a>    posterior <span class="op">=</span> (likelihood <span class="op">*</span> prior) <span class="op">/</span> marginal</span>
<span id="cb10-12"><a href="#cb10-12" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> posterior</span></code></pre></div>
<h3 id="priority-3-add-dynamic-updates">Priority 3: Add Dynamic
Updates</h3>
<p><strong>Approach</strong>: Model coalition formation</p>
<div class="sourceCode" id="cb11"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb11-1"><a href="#cb11-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> update_clout(player, allies):</span>
<span id="cb11-2"><a href="#cb11-2" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Clout increases with coalition size</span></span>
<span id="cb11-3"><a href="#cb11-3" aria-hidden="true" tabindex="-1"></a>    coalition_bonus <span class="op">=</span> <span class="bu">sum</span>(ally.clout <span class="cf">for</span> ally <span class="kw">in</span> allies) <span class="op">*</span> <span class="fl">0.1</span></span>
<span id="cb11-4"><a href="#cb11-4" aria-hidden="true" tabindex="-1"></a>    player.clout <span class="op">+=</span> coalition_bonus</span></code></pre></div>
<hr />
<h2 id="conclusion">Conclusion</h2>
<p><strong>What I implemented</strong>: - The complete <strong>strategic
skeleton</strong> of BDM’s model - All mathematically specified
components - Reasonable approximations for unspecified details</p>
<p><strong>What’s missing</strong>: - The <strong>econometric
flesh</strong>: cost parameters, exact likelihood functions - The
<strong>dynamic evolution</strong>: variable updates over time - The
<strong>full game tree</strong>: complete payoff calculations</p>
<p><strong>Why it still works</strong>: - The strategic logic dominates
the predictions - Power, credibility, and resolve are the key drivers -
Cost details and exact Bayesian updates matter less than the structural
constraints</p>
<p><strong>Bottom line</strong>: This is roughly an <strong>80%
implementation</strong> of BDM’s model — enough to replicate the
qualitative insights and get within ~10% of actual outcomes, but not
enough to match his proprietary consulting software exactly.</p>
<p>The missing 20% is what BDM keeps private and what makes his
consulting valuable!</p>
<p>
  <a href="..">Yukarı</a>
</p>
</body>
</html>
