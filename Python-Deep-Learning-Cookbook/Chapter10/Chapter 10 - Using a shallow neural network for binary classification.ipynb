{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.callbacks import EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data can be downloaded at https://archive.ics.uci.edu/ml/machine-learning-databases/undocumented/connectionist-bench/sonar/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe = pd.read_csv(\"../Data/sonar.all-data\", header=None)\n",
    "data = dataframe.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data[:,0:60].astype(float)\n",
    "y = data[:,60]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = LabelEncoder()\n",
    "encoder.fit(y)\n",
    "y = encoder.transform(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(32, input_dim=60, activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "callbacks = [EarlyStopping(monitor='val_acc', patience=20)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 187 samples, validate on 21 samples\n",
      "Epoch 1/1000\n",
      "187/187 [==============================] - 0s - loss: 0.6961 - acc: 0.5241 - val_loss: 0.7581 - val_acc: 0.0000e+00\n",
      "Epoch 2/1000\n",
      "187/187 [==============================] - 0s - loss: 0.6759 - acc: 0.5989 - val_loss: 0.6934 - val_acc: 0.4762\n",
      "Epoch 3/1000\n",
      "187/187 [==============================] - 0s - loss: 0.6522 - acc: 0.6524 - val_loss: 0.7379 - val_acc: 0.2857\n",
      "Epoch 4/1000\n",
      "187/187 [==============================] - 0s - loss: 0.6358 - acc: 0.6952 - val_loss: 0.7303 - val_acc: 0.3333\n",
      "Epoch 5/1000\n",
      "187/187 [==============================] - 0s - loss: 0.6066 - acc: 0.7005 - val_loss: 0.7116 - val_acc: 0.3810\n",
      "Epoch 6/1000\n",
      "187/187 [==============================] - 0s - loss: 0.5807 - acc: 0.7166 - val_loss: 0.7182 - val_acc: 0.3810\n",
      "Epoch 7/1000\n",
      "187/187 [==============================] - 0s - loss: 0.5593 - acc: 0.7594 - val_loss: 0.7462 - val_acc: 0.3810\n",
      "Epoch 8/1000\n",
      "187/187 [==============================] - 0s - loss: 0.5320 - acc: 0.7487 - val_loss: 0.7613 - val_acc: 0.3810\n",
      "Epoch 9/1000\n",
      "187/187 [==============================] - 0s - loss: 0.5140 - acc: 0.7487 - val_loss: 0.7638 - val_acc: 0.3810\n",
      "Epoch 10/1000\n",
      "187/187 [==============================] - 0s - loss: 0.4930 - acc: 0.7754 - val_loss: 0.5576 - val_acc: 0.8095\n",
      "Epoch 11/1000\n",
      "187/187 [==============================] - 0s - loss: 0.4961 - acc: 0.7701 - val_loss: 0.5997 - val_acc: 0.6190\n",
      "Epoch 12/1000\n",
      "187/187 [==============================] - 0s - loss: 0.4794 - acc: 0.7807 - val_loss: 0.6362 - val_acc: 0.5714\n",
      "Epoch 13/1000\n",
      "187/187 [==============================] - 0s - loss: 0.4669 - acc: 0.7701 - val_loss: 0.6488 - val_acc: 0.5714\n",
      "Epoch 14/1000\n",
      "187/187 [==============================] - 0s - loss: 0.4495 - acc: 0.7968 - val_loss: 0.4256 - val_acc: 0.8571\n",
      "Epoch 15/1000\n",
      "187/187 [==============================] - 0s - loss: 0.4412 - acc: 0.7807 - val_loss: 0.5374 - val_acc: 0.7143\n",
      "Epoch 16/1000\n",
      "187/187 [==============================] - 0s - loss: 0.4411 - acc: 0.7968 - val_loss: 0.5941 - val_acc: 0.6190\n",
      "Epoch 17/1000\n",
      "187/187 [==============================] - 0s - loss: 0.4342 - acc: 0.8235 - val_loss: 0.6263 - val_acc: 0.5714\n",
      "Epoch 18/1000\n",
      "187/187 [==============================] - 0s - loss: 0.4264 - acc: 0.7914 - val_loss: 0.5970 - val_acc: 0.5714\n",
      "Epoch 19/1000\n",
      "187/187 [==============================] - 0s - loss: 0.4162 - acc: 0.8235 - val_loss: 0.6332 - val_acc: 0.5714\n",
      "Epoch 20/1000\n",
      "187/187 [==============================] - 0s - loss: 0.4115 - acc: 0.8021 - val_loss: 0.5561 - val_acc: 0.6190\n",
      "Epoch 21/1000\n",
      "187/187 [==============================] - 0s - loss: 0.4102 - acc: 0.8075 - val_loss: 0.3963 - val_acc: 0.8571\n",
      "Epoch 22/1000\n",
      "187/187 [==============================] - 0s - loss: 0.4082 - acc: 0.8289 - val_loss: 0.6249 - val_acc: 0.5714\n",
      "Epoch 23/1000\n",
      "187/187 [==============================] - 0s - loss: 0.3985 - acc: 0.8342 - val_loss: 0.5147 - val_acc: 0.7143\n",
      "Epoch 24/1000\n",
      "187/187 [==============================] - 0s - loss: 0.3837 - acc: 0.8289 - val_loss: 0.3100 - val_acc: 0.9524\n",
      "Epoch 25/1000\n",
      "187/187 [==============================] - 0s - loss: 0.4034 - acc: 0.8235 - val_loss: 0.4187 - val_acc: 0.8571\n",
      "Epoch 26/1000\n",
      "187/187 [==============================] - 0s - loss: 0.3795 - acc: 0.8396 - val_loss: 0.6791 - val_acc: 0.5238\n",
      "Epoch 27/1000\n",
      "187/187 [==============================] - 0s - loss: 0.3843 - acc: 0.8342 - val_loss: 0.4852 - val_acc: 0.7143\n",
      "Epoch 28/1000\n",
      "187/187 [==============================] - 0s - loss: 0.3700 - acc: 0.8396 - val_loss: 0.5573 - val_acc: 0.6190\n",
      "Epoch 29/1000\n",
      "187/187 [==============================] - 0s - loss: 0.3647 - acc: 0.8449 - val_loss: 0.6461 - val_acc: 0.5714\n",
      "Epoch 30/1000\n",
      "187/187 [==============================] - 0s - loss: 0.3635 - acc: 0.8503 - val_loss: 0.4572 - val_acc: 0.7619\n",
      "Epoch 31/1000\n",
      "187/187 [==============================] - 0s - loss: 0.3634 - acc: 0.8235 - val_loss: 0.4954 - val_acc: 0.7143\n",
      "Epoch 32/1000\n",
      "187/187 [==============================] - 0s - loss: 0.3405 - acc: 0.8663 - val_loss: 1.0005 - val_acc: 0.3810\n",
      "Epoch 33/1000\n",
      "187/187 [==============================] - 0s - loss: 0.3773 - acc: 0.8182 - val_loss: 0.3946 - val_acc: 0.9048\n",
      "Epoch 34/1000\n",
      "187/187 [==============================] - 0s - loss: 0.3490 - acc: 0.8770 - val_loss: 0.4199 - val_acc: 0.7619\n",
      "Epoch 35/1000\n",
      "187/187 [==============================] - 0s - loss: 0.3447 - acc: 0.8663 - val_loss: 0.5505 - val_acc: 0.6667\n",
      "Epoch 36/1000\n",
      "187/187 [==============================] - 0s - loss: 0.3513 - acc: 0.8449 - val_loss: 0.4539 - val_acc: 0.7619\n",
      "Epoch 37/1000\n",
      "187/187 [==============================] - 0s - loss: 0.3362 - acc: 0.8610 - val_loss: 0.3835 - val_acc: 0.9048\n",
      "Epoch 38/1000\n",
      "187/187 [==============================] - 0s - loss: 0.3293 - acc: 0.8877 - val_loss: 0.3050 - val_acc: 0.9048\n",
      "Epoch 39/1000\n",
      "187/187 [==============================] - 0s - loss: 0.3374 - acc: 0.8449 - val_loss: 0.2869 - val_acc: 0.9524\n",
      "Epoch 40/1000\n",
      "187/187 [==============================] - 0s - loss: 0.3286 - acc: 0.8663 - val_loss: 0.6227 - val_acc: 0.5714\n",
      "Epoch 41/1000\n",
      "187/187 [==============================] - 0s - loss: 0.3260 - acc: 0.8770 - val_loss: 0.6401 - val_acc: 0.5714\n",
      "Epoch 42/1000\n",
      "187/187 [==============================] - 0s - loss: 0.3159 - acc: 0.8770 - val_loss: 0.4240 - val_acc: 0.8095\n",
      "Epoch 43/1000\n",
      "187/187 [==============================] - 0s - loss: 0.3218 - acc: 0.8663 - val_loss: 0.5316 - val_acc: 0.6667\n",
      "Epoch 44/1000\n",
      "187/187 [==============================] - 0s - loss: 0.3106 - acc: 0.8824 - val_loss: 0.4015 - val_acc: 0.8095\n",
      "Epoch 45/1000\n",
      "187/187 [==============================] - 0s - loss: 0.3050 - acc: 0.8877 - val_loss: 0.5687 - val_acc: 0.6190\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f02e8b27198>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_epochs = 1000\n",
    "batch_size = 2\n",
    "model.fit(X, y, epochs=n_epochs, batch_size=batch_size, validation_split=0.1, callbacks=callbacks)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
