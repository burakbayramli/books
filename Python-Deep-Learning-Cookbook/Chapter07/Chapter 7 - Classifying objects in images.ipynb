{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import glob\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "import keras\n",
    "from keras.models import Sequential, load_model\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten, Conv2D, MaxPooling2D, Lambda, Cropping2D\n",
    "from keras.utils import np_utils\n",
    "from keras import optimizers\n",
    "from keras.callbacks import EarlyStopping\n",
    "\n",
    "SEED = 2017"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data can be downloaded at http://download.tensorflow.org/example_images/flower_photos.tgz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify data directory and extract all file names\n",
    "DATA_DIR = 'Data/'\n",
    "images = glob.glob(DATA_DIR + \"flower_photos/*/*.jpg\")\n",
    "# Extract labels from file names\n",
    "labels = [x.split('/')[3] for x in images]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_labels = set(labels)\n",
    "plt.figure(figsize=(15, 15))\n",
    "i = 1\n",
    "for label in unique_labels:\n",
    "    image = images[labels.index(label)]\n",
    "    img = cv2.imread(image)\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    plt.subplot(5, 5, i)\n",
    "    plt.title(\"{0} ({1})\".format(label, labels.count(label)))\n",
    "    i += 1\n",
    "    _ = plt.imshow(img)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = LabelBinarizer()\n",
    "encoder.fit(labels)\n",
    "y = encoder.transform(labels).astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_val, y_train , y_val = train_test_split(images, y, test_size=0.2, random_state=SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define architecture\n",
    "model = Sequential()\n",
    "model.add(Lambda(lambda x: (x / 255.) - 0.5, input_shape=(100, 100, 3)))\n",
    "model.add(Conv2D(16, (5, 5), activation='relu', padding='same'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(Dropout(0.75))\n",
    "model.add(Conv2D(32, (5, 5), activation='relu', padding='same'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(Dropout(0.75))\n",
    "model.add(Conv2D(64, (3, 3), activation='relu', padding='same'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(Dropout(0.75))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(Dropout(0.75))\n",
    "model.add(Dense(5, activation='softmax'))\n",
    "\n",
    "# Define optimizer and compile\n",
    "opt = optimizers.Adam()\n",
    "model.compile(loss='categorical_crossentropy', optimizer=opt, metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_rows = img_cols = 100\n",
    "img_channels = 3\n",
    "\n",
    "def batchgen(x, y, batch_size, transform=False):\n",
    "    # Create empty numpy arrays\n",
    "    images = np.zeros((batch_size, img_rows, img_cols, img_channels))\n",
    "    class_id = np.zeros((batch_size, len(y[0])))\n",
    "\n",
    "    while 1:\n",
    "        for n in range(batch_size):\n",
    "            i = np.random.randint(len(x))\n",
    "            x_ = cv2.imread(x[i])\n",
    "            x_ = cv2.cvtColor(x_, cv2.COLOR_BGR2RGB)\n",
    "            # The images have different sizes, we transform all to 100x100 pixels\n",
    "            x_ = cv2.resize(x_, (100, 100)) \n",
    "            images[n] = x_\n",
    "            class_id[n] = y[i]\n",
    "            yield images, class_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "callbacks = [EarlyStopping(monitor='val_acc', patience=5)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 256\n",
    "n_epochs = 100\n",
    "steps_per_epoch = len(X_train) // batch_size\n",
    "val_steps = len(X_val) // batch_size\n",
    "\n",
    "train_generator = batchgen(X_train, y_train, batch_size, True)\n",
    "val_generator = batchgen(X_val, y_val, batch_size, True)\n",
    "\n",
    "history = model.fit_generator(train_generator, \n",
    "                               steps_per_epoch=steps_per_epoch, \n",
    "                               epochs=n_epochs, \n",
    "                               validation_data=val_generator,\n",
    "                               validation_steps=val_steps,\n",
    "                              callbacks=callbacks\n",
    "                             )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history.history['acc'])\n",
    "plt.plot(history.history['val_acc'])\n",
    "plt.title('Model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epochs')\n",
    "plt.legend(['train', 'validation'], loc='lower right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_generator = batchgen(X_val, y_val, 1, False)\n",
    "preds = model.predict_generator(test_generator, steps=len(X_val))\n",
    "\n",
    "y_val_ = [np.argmax(x) for x in y_val]\n",
    "y_preds = [np.argmax(x) for x in preds]\n",
    "accuracy_score(y_val_, y_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_predictions = 5\n",
    "plt.figure(figsize=(15, 15))\n",
    "for i in range(n_predictions):\n",
    "  \n",
    "    plt.subplot(n_predictions, n_predictions, i+1)\n",
    "    plt.title(\"{0} ({1})\".format(list(set(labels))[np.argmax(preds[i])], \n",
    "                                 list(set(labels))[np.argmax(y_val[i])]))\n",
    "    img = cv2.imread(X_val[i])\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    plt.axis('off')\n",
    "    plt.imshow(img)\n",
    "    plt.tight_layout() \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
