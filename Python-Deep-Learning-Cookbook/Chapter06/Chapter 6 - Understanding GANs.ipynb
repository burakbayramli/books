{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Input, Dense, Activation, Flatten, Reshape\n",
    "from keras.layers import Conv2D, Conv2DTranspose, UpSampling2D\n",
    "from keras.layers import LeakyReLU, Dropout\n",
    "from keras.layers import BatchNormalization\n",
    "from keras.optimizers import Adam\n",
    "from keras import initializers\n",
    "\n",
    "from keras.datasets import mnist\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
    "\n",
    "img_rows, img_cols = X_train.shape[1:]\n",
    "\n",
    "X_train = (X_train.reshape(-1, img_rows*img_cols, 1).astype(np.float32)-127.5)/127.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def discriminator_model(dropout=0.5):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(1024, input_dim=784, kernel_initializer=initializers.RandomNormal(stddev=0.02)))\n",
    "    model.add(LeakyReLU(0.2))\n",
    "    model.add(Dropout(dropout))\n",
    "    model.add(Dense(512))\n",
    "    model.add(LeakyReLU(0.2))\n",
    "    model.add(Dropout(dropout))\n",
    "    model.add(Dense(256))\n",
    "    model.add(LeakyReLU(0.2))\n",
    "    model.add(Dropout(dropout))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    opt = Adam(lr=0.0001)\n",
    "    model.compile(loss='binary_crossentropy', optimizer=opt)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generator_model():\n",
    "    model = Sequential()\n",
    "    model.add(Dense(256, input_dim=100, kernel_initializer=initializers.RandomNormal(stddev=0.02)))\n",
    "    model.add(LeakyReLU(0.2))\n",
    "    model.add(Dense(512))\n",
    "    model.add(LeakyReLU(0.2))\n",
    "    model.add(Dense(1024))\n",
    "    model.add(LeakyReLU(0.2))\n",
    "    model.add(Dense(784, activation='tanh'))\n",
    "    opt = Adam(lr=0.00005)\n",
    "    model.compile(loss='binary_crossentropy', optimizer=opt)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "discriminator = discriminator_model()\n",
    "generator = generator_model()\n",
    "discriminator.trainable = False\n",
    "gan_input = Input(shape=(100,))\n",
    "x = generator(gan_input)\n",
    "gan_output = discriminator(x)\n",
    "gan = Model(inputs=gan_input, outputs=gan_output)\n",
    "opt = Adam(lr=0.0001)\n",
    "gan.compile(loss='binary_crossentropy', optimizer=opt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_images(samples=16, step=0):\n",
    "    plt.figure(figsize=(5,5))\n",
    "    for i in range(samples):\n",
    "        noise = np.random.uniform(-1, 1, size=[batch_size, 100])#np.random.normal(0, 1, size=[batch_size, 100])\n",
    "        images = generator.predict(noise)\n",
    "        plt.subplot(4, 4, i+1)\n",
    "        image = images[i, :,]\n",
    "        image = np.reshape(image, [img_rows, img_cols])\n",
    "        plt.imshow(image, cmap='gray')\n",
    "        plt.axis('off')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "n_steps = 100000\n",
    "plot_every = 1000\n",
    "\n",
    "noise_input = np.random.uniform(-1, 1, size=[16, 100])\n",
    "for step in range(n_steps):\n",
    "    \n",
    "    noise = np.random.uniform(-1, 1, size=[batch_size, 100])\n",
    "    batch = X_train[np.random.randint(0, X_train.shape[0], size=batch_size)].reshape(batch_size, 784)\n",
    "\n",
    "    gen_output = generator.predict(noise)\n",
    "    X = np.concatenate([batch, gen_output])\n",
    "\n",
    "    y_D = np.zeros(2*batch_size)\n",
    "    y_D[:batch_size] = 1\n",
    "\n",
    "    discriminator.trainable = True\n",
    "    loss_D = discriminator.train_on_batch(X, y_D)\n",
    "\n",
    "    noise = np.random.uniform(-1, 1, size=[batch_size, 100])\n",
    "    y_G = np.ones(batch_size)\n",
    "    discriminator.trainable = False\n",
    "    loss_G = gan.train_on_batch(noise, y_G)\n",
    "    \n",
    "    if step % plot_every == 0:\n",
    "        print('Step {}'.format(step))\n",
    "        plot_images(samples=noise_input.shape[0], step=(step+1))\n",
    "        "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
