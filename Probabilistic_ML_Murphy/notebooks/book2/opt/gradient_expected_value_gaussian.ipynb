{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f540d7de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bonnet's thm: d/dm E[f(z)] = E[d/dz f(z)] for z ~ N(m,v)\n",
    "#Price's thm:  d/dv E[f(z)] = 0.5 E[d^2/dz^2 f(z)] for z ~ N(m,v)\n",
    "\n",
    "# Note that we are taking derivatives wrt the parameters of the sampling distribution\n",
    "# We rely on the fact that TFP Gaussian samples are reparameterizable\n",
    "\n",
    "import numpy as np\n",
    "import jax\n",
    "import jax.numpy as jnp\n",
    "try:\n",
    "    import tensorflow_probability as tfp\n",
    "except ModuleNotFoundError:\n",
    "    %pip install -qq tensorflow-probability\n",
    "    import tensorflow_probability as tfp\n",
    "tfp = tfp.substrates.jax\n",
    "tfd = tfp.distributions\n",
    "\n",
    "key = jax.random.PRNGKey(0)\n",
    "nsamples = 10000\n",
    "\n",
    "\n",
    "def f(z):\n",
    "  return jnp.square(z) # arbitrary fn\n",
    "\n",
    "def expect_f(params):\n",
    "  m, v = params\n",
    "  dist = tfd.Normal(m, jnp.sqrt(v))\n",
    "  zs = dist.sample(nsamples, key)\n",
    "  return jnp.mean(f(zs))\n",
    "\n",
    "def expect_grad(params):\n",
    "  m, v = params\n",
    "  dist = tfd.Normal(m, jnp.sqrt(v))\n",
    "  zs = dist.sample(nsamples, key)\n",
    "  grads = jax.vmap(jax.grad(f))(zs)\n",
    "  return jnp.mean(grads)\n",
    "\n",
    "def expect_grad2(params):\n",
    "  m, v = params\n",
    "  dist = tfd.Normal(m, jnp.sqrt(v))\n",
    "  zs = dist.sample(nsamples, key)\n",
    "  #g = jax.grad(f)\n",
    "  #grads = jax.vmap(jax.grad(g))(zs)\n",
    "  grads = jax.vmap(jax.hessian(f))(zs)\n",
    "  return jnp.mean(grads)\n",
    "\n",
    "\n",
    "params = (1.0, 2.0)\n",
    "\n",
    "\n",
    "e1 = expect_grad(params)\n",
    "e2 = expect_grad2(params)\n",
    "print([e1, 0.5*e2])\n",
    "\n",
    "grads = jax.grad(expect_f)(params)\n",
    "print(grads)\n",
    "\n",
    "assert np.allclose(e1, grads[0], atol=1e-1)\n",
    "assert np.allclose(0.5 * e2, grads[1], atol=1e-1)\n",
    "\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
