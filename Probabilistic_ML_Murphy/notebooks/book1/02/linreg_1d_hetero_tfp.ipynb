{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c635ed17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Linear regression using MLE with fixed variance and input-dependent variance.\n",
    "# Adapted from\n",
    "# https://colab.sandbox.google.com/github/tensorflow/probability/blob/master/tensorflow_probability/examples/jupyter_notebooks/Probabilistic_Layers_Regression.ipynb#scrollTo=5zCEYpzu7bDX\n",
    "\n",
    "\n",
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "from pprint import pprint\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "\n",
    "try:\n",
    "    import tensorflow.compat.v2 as tf\n",
    "except ModuleNotFoundError:\n",
    "    %pip install -qq tensorflow\n",
    "    import tensorflow.compat.v2 as tf\n",
    "tf.enable_v2_behavior()\n",
    "\n",
    "try:\n",
    "    import tensorflow_probability as tfp\n",
    "except ModuleNotFoundError:\n",
    "    %pip install -qq tensorflow-probability\n",
    "    import tensorflow_probability as tfp\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "\n",
    "figdir = \"figures\"\n",
    "\n",
    "\n",
    "def savefig(fname):\n",
    "    plt.savefig(os.path.join(figdir, fname))\n",
    "\n",
    "\n",
    "sns.reset_defaults()\n",
    "# sns.set_style('whitegrid')\n",
    "# sns.set_context('talk')\n",
    "sns.set_context(context=\"talk\", font_scale=0.7)\n",
    "\n",
    "tfd = tfp.distributions\n",
    "\n",
    "\n",
    "# @title Synthesize dataset.\n",
    "w0 = 0.125\n",
    "b0 = 5.0\n",
    "x_range = [-20, 60]\n",
    "\n",
    "\n",
    "def load_dataset(n=150, n_tst=150):\n",
    "    np.random.seed(43)\n",
    "\n",
    "    def s(x):\n",
    "        g = (x - x_range[0]) / (x_range[1] - x_range[0])\n",
    "        return 3 * (0.25 + g**2.0)\n",
    "\n",
    "    x = (x_range[1] - x_range[0]) * np.random.rand(n) + x_range[0]\n",
    "    eps = np.random.randn(n) * s(x)\n",
    "    y = (w0 * x * (1.0 + np.sin(x)) + b0) + eps\n",
    "    x = x[..., np.newaxis]\n",
    "    x_tst = np.linspace(*x_range, num=n_tst).astype(np.float32)\n",
    "    x_tst = x_tst[..., np.newaxis]\n",
    "    return y, x, x_tst\n",
    "\n",
    "\n",
    "y, x, x_tst = load_dataset()\n",
    "\n",
    "\n",
    "plt.figure()\n",
    "# plt.figure(figsize=[8, 5])  # inches\n",
    "plt.plot(x, y, \"b.\", label=\"observed\")\n",
    "savefig(\"linreg_1d_hetero_data.pdf\")\n",
    "plt.show()\n",
    "\n",
    "\n",
    "### Fixed output variance\n",
    "model = tf.keras.Sequential(\n",
    "    [\n",
    "        tf.keras.layers.Dense(1),  # 1 linear layer\n",
    "        tfp.layers.DistributionLambda(lambda t: tfd.Normal(loc=t, scale=1)),\n",
    "    ]\n",
    ")\n",
    "\n",
    "negloglik = lambda y, rv_y: -rv_y.log_prob(y)\n",
    "model.compile(optimizer=tf.optimizers.Adam(learning_rate=0.01), loss=negloglik)\n",
    "history = model.fit(x, y, epochs=1000, verbose=False)\n",
    "[print(np.squeeze(w.numpy())) for w in model.weights]\n",
    "yhat = model(x_tst)\n",
    "assert isinstance(yhat, tfd.Distribution)\n",
    "\n",
    "plt.plot(history.history[\"loss\"], label=\"Train\")\n",
    "# plt.plot(history.history['val_loss'], label='Val')\n",
    "plt.legend()\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"NLL\")\n",
    "plt.show()\n",
    "\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(x, y, \"b.\", label=\"observed\")\n",
    "plt.plot(x_tst, yhat.mean(), \"r\", label=\"mean\", linewidth=4)\n",
    "savefig(\"linreg_1d_hetero_mean.pdf\")\n",
    "plt.show()\n",
    "\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(x, y, \"b.\", label=\"observed\")\n",
    "m = yhat.mean()\n",
    "s = yhat.stddev()\n",
    "plt.plot(x_tst, m, \"r\", linewidth=4, label=\"mean\")\n",
    "plt.plot(x_tst, m + 2 * s, \"g\", linewidth=2, label=r\"mean + 2 stddev\")\n",
    "plt.plot(x_tst, m - 2 * s, \"g\", linewidth=2, label=r\"mean - 2 stddev\")\n",
    "savefig(\"linreg_1d_hetero_var_fixed.pdf\")\n",
    "plt.show()\n",
    "\n",
    "# Data-dependent variance (heteroskedastic)\n",
    "\n",
    "# mu(x) = b + wx\n",
    "# sigma(x) = softplus( 0.05 * b' + w' x)\n",
    "model = tf.keras.Sequential(\n",
    "    [\n",
    "        tf.keras.layers.Dense(1 + 1),  # linear model for mean and variance\n",
    "        tfp.layers.DistributionLambda(\n",
    "            lambda t: tfd.Normal(loc=t[..., :1], scale=1e-3 + tf.math.softplus(0.05 * t[..., 1:]))\n",
    "        ),\n",
    "    ]\n",
    ")\n",
    "\n",
    "model.compile(optimizer=tf.optimizers.Adam(learning_rate=0.01), loss=negloglik)\n",
    "model.fit(x, y, epochs=1000, verbose=False)\n",
    "yhat = model(x_tst)\n",
    "assert isinstance(yhat, tfd.Distribution)\n",
    "\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(x, y, \"b.\", label=\"observed\")\n",
    "m = yhat.mean()\n",
    "s = yhat.stddev()\n",
    "\n",
    "plt.plot(x_tst, m, \"r\", linewidth=4, label=\"mean\")\n",
    "plt.plot(x_tst, m + 2 * s, \"g\", linewidth=2, label=r\"mean + 2 stddev\")\n",
    "plt.plot(x_tst, m - 2 * s, \"g\", linewidth=2, label=r\"mean - 2 stddev\")\n",
    "savefig(\"linreg_1d_hetero_var_adaptive.pdf\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
