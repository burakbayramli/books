{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fb53018",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from numpy.linalg import cholesky\n",
    "try:\n",
    "    from sklearn.linear_model import LogisticRegression\n",
    "except ModuleNotFoundError:\n",
    "    %pip install -qq scikit-learn\n",
    "    from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "\n",
    "np.random.seed(12)\n",
    "\n",
    "\n",
    "def gaussSample(mu, sigma, n):\n",
    "    A = cholesky(sigma)\n",
    "    Z = np.random.normal(loc=0, scale=1, size=(len(mu), n))\n",
    "    return np.dot(A, Z).T + mu\n",
    "\n",
    "\n",
    "def sqDistance(p, q):\n",
    "    pSOS = np.sum(p ** 2, axis=1)\n",
    "    qSOS = np.sum(q ** 2, axis=1)\n",
    "    pSOS = np.repeat(pSOS[..., np.newaxis], len(qSOS), axis=1)\n",
    "    dist = pSOS + qSOS - 2 * np.dot(p, q.T)\n",
    "    return dist\n",
    "\n",
    "\n",
    "def kernelRbfSigma(X1, X2, sigma):\n",
    "    Z = 1.0 / np.sqrt(2 * np.pi * sigma ** 2)\n",
    "    S = sqDistance(X1, X2)\n",
    "    K = Z * np.exp(-1 / (2 * sigma ** 2) * S)\n",
    "    return K\n",
    "\n",
    "\n",
    "def createXORdata(doplot=False):\n",
    "    off1 = gaussSample([1, 1], 0.5 * np.eye(2), 20)\n",
    "    off2 = gaussSample([5, 5], 0.5 * np.eye(2), 20)\n",
    "    on1 = gaussSample([1, 5], 0.5 * np.eye(2), 20)\n",
    "    on2 = gaussSample([5, 1], 0.5 * np.eye(2), 20)\n",
    "    X = np.concatenate([off1, off2, on1, on2], axis=0)\n",
    "    y = np.concatenate([np.zeros((len(off1) + len(off2))), np.ones((len(on1) + len(on2)))], axis=0)\n",
    "\n",
    "    if doplot:\n",
    "        plt.plot(X[y == 0, 0], X[y == 0, 1], 'ob', MarkerSize=8)\n",
    "        plt.plot(X[y == 1, 0], X[y == 1, 1], '+r', MarkerSize=8)\n",
    "        plt.show()\n",
    "    return X, y\n",
    "\n",
    "\n",
    "def addOnes(X):\n",
    "    X = np.concatenate((np.ones((len(X), 1)), X), axis=1)\n",
    "    return X\n",
    "\n",
    "\n",
    "def degexpand(x, deg, addO=0):\n",
    "    n, m = x.shape\n",
    "\n",
    "    temp = x\n",
    "    for i in range(1, deg):\n",
    "        xx = np.concatenate((x, temp ** (i + 1)), axis=1)\n",
    "        x = xx\n",
    "\n",
    "    if addO:\n",
    "        xx = addOnes(xx)\n",
    "\n",
    "    return xx\n",
    "\n",
    "\n",
    "def rescaleData(x):\n",
    "    minVal = -1\n",
    "    maxVal = 1\n",
    "\n",
    "    minx = np.min(X, axis=0)\n",
    "    rangex = np.max(X, axis=0) - np.min(X, axis=0)\n",
    "    y = (x - minx) / rangex\n",
    "\n",
    "    y = y * (maxVal - minVal)\n",
    "    y = y + minVal\n",
    "    return y\n",
    "\n",
    "\n",
    "def rbf_prototype(X1, protoTypesStnd, rbfScale):\n",
    "    X1 = (X1 - X1.mean(axis=0)) / X1.std(axis=0)\n",
    "    X1 = kernelRbfSigma(X1, protoTypesStnd, rbfScale)\n",
    "    X1 = addOnes(X1)\n",
    "    return X1\n",
    "\n",
    "\n",
    "def poly_data(X1, deg):\n",
    "    X1 = rescaleData(X1)\n",
    "    X1 = degexpand(X1, deg)\n",
    "    X1 = addOnes(X1)\n",
    "    return X1\n",
    "\n",
    "\n",
    "X, y = createXORdata(False)\n",
    "tol = 1e-2\n",
    "\n",
    "model = LogisticRegression(tol=tol)\n",
    "model.fit(X, y)\n",
    "ypred = model.predict(X)\n",
    "errorRate = np.mean(ypred != y)\n",
    "\n",
    "clf = LogisticRegression()\n",
    "clf.fit(X, y)\n",
    "\n",
    "fig, ax1 = plt.subplots(1, 1, figsize=(9, 6))\n",
    "# Retrieve the model parameters.\n",
    "b = clf.intercept_[0]\n",
    "w1, w2 = clf.coef_.T\n",
    "# Calculate the intercept and gradient of the decision boundary.\n",
    "c = -b / w2\n",
    "m = -w1 / w2\n",
    "\n",
    "x_min, x_max = X[:, 0].min() - .5, X[:, 0].max() + .5\n",
    "y_min, y_max = X[:, 1].min() - .5, X[:, 1].max() + .5\n",
    "xd = np.array([x_min, x_max])\n",
    "yd = m * xd + c\n",
    "ax1.plot(xd, yd, 'k', lw=1, ls='--')\n",
    "h = .02  # step size in the mesh\n",
    "xx, yy = np.meshgrid(np.arange(x_min, x_max, h), np.arange(y_min, y_max, h))\n",
    "X_plot_raw = np.c_[xx.ravel(), yy.ravel()]\n",
    "\n",
    "Z = clf.predict(X_plot_raw)\n",
    "\n",
    "# Put the result into a color plot\n",
    "Z = Z.reshape(xx.shape)\n",
    "\n",
    "ax1.pcolormesh(xx, yy, Z, cmap='Set3')\n",
    "\n",
    "# Plot also the training points\n",
    "ax1.scatter(X[:, 0], X[:, 1], c=y, edgecolors='k')\n",
    "ax1.set_xlim(xx.min(), xx.max())\n",
    "ax1.set_ylim(yy.min(), yy.max())\n",
    "ax1.set_ylabel(r'$x_2$')\n",
    "ax1.set_xlabel(r'$x_1$')\n",
    "ax1.set_title('Simple Logistic regression')\n",
    "fig.savefig('figures/logregXorLinear.png')\n",
    "\n",
    "rbfScale = 1\n",
    "polydeg = 2\n",
    "protoTypes = np.array([[1,1], [1,5], [5,1], [5,5]])\n",
    "\n",
    "protoTypesStnd = (protoTypes - protoTypes.mean(axis=0)) / protoTypes.std(axis=0)\n",
    "\n",
    "X_rbf = rbf_prototype(X, protoTypesStnd, rbfScale)\n",
    "lr = LogisticRegression(tol=tol)\n",
    "lr.fit(X_rbf, y)\n",
    "\n",
    "x_min, x_max = X[:, 0].min() - .5, X[:, 0].max() + .5\n",
    "y_min, y_max = X[:, 1].min() - .5, X[:, 1].max() + .5\n",
    "h = .02  # step size in the mesh\n",
    "xx, yy = np.meshgrid(np.arange(x_min, x_max, h), np.arange(y_min, y_max, h))\n",
    "X_plot_raw = np.c_[xx.ravel(), yy.ravel()]\n",
    "X_plot = rbf_prototype(X_plot_raw, protoTypesStnd, rbfScale)\n",
    "Z = lr.predict(X_plot)\n",
    "\n",
    "# Put the result into a color plot\n",
    "Z = Z.reshape(xx.shape)\n",
    "\n",
    "fig, ax2 = plt.subplots(1, 1, figsize=(9, 6))\n",
    "ax2.pcolormesh(xx, yy, Z, cmap='Set3')\n",
    "\n",
    "# Plot also the training points\n",
    "ax2.scatter(X[:, 0], X[:, 1], c=y, edgecolors='k')\n",
    "ax2.scatter(protoTypes[:, 0], protoTypes[:, 1], marker='*', c='r', s=90)\n",
    "ax2.set_xlabel(r'$x_1$')\n",
    "ax2.set_ylabel(r'$x_2$')\n",
    "\n",
    "ax2.set_xlim(xx.min(), xx.max())\n",
    "ax2.set_ylim(yy.min(), yy.max())\n",
    "ax2.set_title('rbf prototypes')\n",
    "fig.savefig('figures/logregXorRbfProto.png')\n",
    "\n",
    "X_poly = poly_data(X, 10)\n",
    "lr = LogisticRegression(tol=tol)\n",
    "lr.fit(X_poly, y)\n",
    "\n",
    "x_min, x_max = X[:, 0].min() - .5, X[:, 0].max() + .5\n",
    "y_min, y_max = X[:, 1].min() - .5, X[:, 1].max() + .5\n",
    "h = .02  # step size in the mesh\n",
    "xx, yy = np.meshgrid(np.arange(x_min, x_max, h), np.arange(y_min, y_max, h))\n",
    "X_plot_raw = np.c_[xx.ravel(), yy.ravel()]\n",
    "X_plot = poly_data(X_plot_raw, 10)\n",
    "Z = lr.predict(X_plot)\n",
    "\n",
    "# Put the result into a color plot\n",
    "Z = Z.reshape(xx.shape)\n",
    "fig, ax3 = plt.subplots(1, 1, figsize=(9, 6))\n",
    "ax3.pcolormesh(xx, yy, Z, cmap='Set3')\n",
    "\n",
    "# Plot also the training points\n",
    "ax3.scatter(X[:, 0], X[:, 1], c=y, edgecolors='k')\n",
    "ax3.set_xlabel(r'$x_1$')\n",
    "ax3.set_ylabel(r'$x_2$')\n",
    "ax3.set_title('poly10')\n",
    "ax3.set_xlim(xx.min(), xx.max())\n",
    "ax3.set_ylim(yy.min(), yy.max())\n",
    "fig.savefig('figures/logregXorPoly.png')\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
