{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "name": "flax_intro.ipynb",
   "provenance": [],
   "collapsed_sections": [],
   "toc_visible": true,
   "authorship_tag": "ABX9TyOWKlhk6+ajDPQPnxM2A9sa",
   "include_colab_link": true
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  }
 },
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "view-in-github",
    "colab_type": "text"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/probml/probml-notebooks/blob/main/notebooks/flax_intro.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rF208fIxvq8m"
   },
   "source": [
    "# Introduction to neural networks using Flax\n",
    "\n",
    "\n",
    "\n",
    "Flax / Linen is a neural net library, built on top of JAX, \"designed to offer an implicit variable management API to save the user from having to manually thread thousands of variables through a complex tree of functions.\" To handle both current and future JAX transforms (configured and composed in any way), Linen Modules are defined as explicit functions of the form\n",
    "$$\n",
    "f(v_{in}, x) \\rightarrow v_{out}, y\n",
    "$$\n",
    "Where $v_{in}$ is the collection of variables (eg. parameters) and PRNG state used by the model, $v_{out}$ the mutated output variable collections, $x$ the input data and $y$ the output data. We illustrate this below. Our tutorial is based on the official [flax intro](https://flax.readthedocs.io/en/latest/notebooks/flax_basics.html) and [linen colab](https://github.com/google/flax/blob/master/docs/notebooks/linen_intro.ipynb). Details are in the [flax source code](https://flax.readthedocs.io/en/latest/_modules/index.html). Note: please be sure to read our [JAX tutorial](https://colab.research.google.com/github/probml/probml-notebooks/blob/main/notebooks/jax_intro.ipynb) first.\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "uRAzAXYXvztz"
   },
   "source": [
    "import numpy as np\n",
    "\n",
    "# np.set_printoptions(precision=3)\n",
    "np.set_printoptions(formatter={\"float\": lambda x: \"{0:0.5f}\".format(x)})\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ],
   "execution_count": 12,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "68kI74E1vvEI",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "0da6a0d8-aacf-4366-c7a7-f810765709fe"
   },
   "source": [
    "import jax\n",
    "\n",
    "print(jax.__version__)\n",
    "print(jax.devices())\n",
    "\n",
    "from jax import lax, random, numpy as jnp\n",
    "\n",
    "key = random.PRNGKey(0)"
   ],
   "execution_count": 2,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "WARNING:absl:No GPU/TPU found, falling back to CPU. (Set TF_CPP_MIN_LOG_LEVEL=0 and rerun for more info.)\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "0.2.19\n",
      "[<jaxlib.xla_extension.Device object at 0x7f8642e14af0>]\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "N3dXu6XY6U0H"
   },
   "source": [
    "from typing import Any, Callable, Dict, Iterator, Mapping, Optional, Sequence, Tuple\n",
    "\n",
    "# Useful type aliases\n",
    "Array = jnp.ndarray\n",
    "PRNGKey = Array\n",
    "Batch = Mapping[str, np.ndarray]\n",
    "OptState = Any"
   ],
   "execution_count": 13,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7pcNcE9_Qj_l",
    "outputId": "107ed9cb-1d4b-46ab-8032-60836e4b083e"
   },
   "source": [
    "# Install Flax at head:\n",
    "!pip install --upgrade -q git+https://github.com/google/flax.git"
   ],
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "text": [
      "  Building wheel for flax (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
     ],
     "name": "stdout"
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "s80k9sonQfDi"
   },
   "source": [
    "import flax\n",
    "from flax.core import freeze, unfreeze\n",
    "from flax import linen as nn\n",
    "from flax import optim\n",
    "\n",
    "from jax.config import config\n",
    "\n",
    "# config.enable_omnistaging() # Linen requires enabling omnistaging"
   ],
   "execution_count": 15,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aGrUFJYxjyL7"
   },
   "source": [
    "# MLP in vanilla JAX\n",
    "\n",
    "We construct a simple MLP with L hidden layers (relu activation), and scalar output (linear activation).\n",
    "\n",
    "Note: JAX and Flax, like NumPy, are row-based systems, meaning that vectors are represented as row vectors and not column vectors. \n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "mWQGVJMP0VMB"
   },
   "source": [
    "# We define the parameter initializers using a signature that is flax-compatible\n",
    "# https://flax.readthedocs.io/en/latest/_modules/jax/_src/nn/initializers.html\n",
    "\n",
    "\n",
    "def weights_init(key, shape, dtype=jnp.float32):\n",
    "    return random.normal(key, shape, dtype)\n",
    "    # return jnp.ones(shape, dtype)\n",
    "\n",
    "\n",
    "def bias_init(key, shape, dtype=jnp.float32):\n",
    "    return jnp.zeros(shape, dtype)\n",
    "\n",
    "\n",
    "def relu(a):\n",
    "    return jnp.maximum(a, 0)"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "GepkhhTh-9b-"
   },
   "source": [
    "# A minimal MLP class\n",
    "\n",
    "\n",
    "class MLP0:\n",
    "    features: Sequence[int]  # number of features in each layer\n",
    "\n",
    "    def __init__(self, features):  # class constructor\n",
    "        self.features = features\n",
    "\n",
    "    def init(self, key, x):  # initialize parameters\n",
    "        in_size = np.shape(x)[1]\n",
    "        sizes = np.concatenate(([in_size], self.features))\n",
    "        nlayers = len(sizes)\n",
    "        params = {}\n",
    "        for i in range(nlayers - 1):\n",
    "            in_size = sizes[i]\n",
    "            out_size = sizes[i + 1]\n",
    "            subkey1, subkey2, key = random.split(key, num=3)\n",
    "            W = weights_init(subkey1, (in_size, out_size))\n",
    "            b = bias_init(subkey2, out_size)\n",
    "            params[f\"W{i}\"] = W\n",
    "            params[f\"b{i}\"] = b\n",
    "        return params\n",
    "\n",
    "    def apply(self, params, x):  # forwards pass\n",
    "        activations = x\n",
    "        nhidden_layers = len(self.features) - 1\n",
    "        for i in range(nhidden_layers):\n",
    "            W = params[f\"W{i}\"]\n",
    "            b = params[f\"b{i}\"]\n",
    "            outputs = jnp.dot(activations, W) + b\n",
    "            activations = relu(outputs)\n",
    "        # for final layer, no activation function\n",
    "        i = nhidden_layers\n",
    "        outputs = jnp.dot(activations, params[f\"W{i}\"]) + params[f\"b{i}\"]\n",
    "        return outputs"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8jFS4SNO0V_I",
    "outputId": "72d9d449-742e-45d1-9641-a4f3a6390e26"
   },
   "source": [
    "key = random.PRNGKey(0)\n",
    "D = 3\n",
    "N = 2\n",
    "x = random.normal(\n",
    "    key,\n",
    "    (\n",
    "        N,\n",
    "        D,\n",
    "    ),\n",
    ")\n",
    "layer_sizes = [3, 1]  # 1 hidden layer of size 3, 1 scalar output\n",
    "\n",
    "model0 = MLP0(layer_sizes)\n",
    "params0 = model0.init(key, x)\n",
    "\n",
    "print(\"params\")\n",
    "for k, v in params0.items():\n",
    "    print(k, v.shape)\n",
    "    print(v)\n",
    "\n",
    "\n",
    "y0 = model0.apply(params0, x)\n",
    "print(\"\\noutput\")\n",
    "print(y0)"
   ],
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "text": [
      "params\n",
      "W0 (3, 3)\n",
      "[[-1.83021 1.18417 0.06777]\n",
      " [0.34588 0.37858 -0.65318]\n",
      " [0.18976 0.45157 -0.33964]]\n",
      "b0 (3,)\n",
      "[0.00000 0.00000 0.00000]\n",
      "W1 (3, 1)\n",
      "[[-1.74905]\n",
      " [1.83313]\n",
      " [-0.23808]]\n",
      "b1 (1,)\n",
      "[0.00000]\n",
      "\n",
      "output\n",
      "[[-0.09538]\n",
      " [2.78382]]\n"
     ],
     "name": "stdout"
    }
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rBtPT-drBkGA"
   },
   "source": [
    "# Our first flax model\n",
    "\n",
    "Here we recreate the vanilla model in flax. Since we don't specify how the parameters are initialized, the behavior will not be identical to the vanilla model --- we will fix this below, but for now, we focus on model construction.\n",
    "\n",
    "We see that the model is a subclass of `nn.Module`, which is a subclass of Python's dataclass. The child class (written by the user) must define a `model.call(inputs)` method, that applies the function to the input, and a `model.setup()` method, that creates the modules inside this model.\n",
    "\n",
    "The module (parent) class defines two main methods: `model.apply(variables, input`, that applies the function to the input (and variables) to generate an output; and `model.init(key, input)`, that initializes the variables and returns them as a \"frozen dictionary\". This dictionary can contain multiple *kinds* of variables. In the example below, the only kind are parameters, which are immutable variables (that will usually get updated in an external optimization loop, as we show later). The parameters are  automatically named after the corresponding module (here, dense0, dense1, etc).  In this example, both modules are dense layers, so their parameters are a weight matrix (called 'kernel') and a bias vector.\n",
    "\n",
    "The hyper-parameters (in this case, the size of each layer) are stored as attributes of the class, and are specified when the module is constructed."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "3zueDo1r0Qav"
   },
   "source": [
    "class MLP(nn.Module):\n",
    "    features: Sequence[int]\n",
    "    default_attr: int = 42\n",
    "\n",
    "    def setup(self):\n",
    "        print(\"setup\")\n",
    "        self.layers = [nn.Dense(feat) for feat in self.features]\n",
    "\n",
    "    def __call__(self, inputs):\n",
    "        print(\"call\")\n",
    "        x = inputs\n",
    "        for i, lyr in enumerate(self.layers):\n",
    "            x = lyr(x)\n",
    "            if i != len(self.layers) - 1:\n",
    "                x = nn.relu(x)\n",
    "        return x"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "OoYDn8lX7_ZH",
    "outputId": "9aed2723-3248-417b-9a25-408ef49763d7"
   },
   "source": [
    "key = random.PRNGKey(0)\n",
    "D = 3\n",
    "N = 2\n",
    "x = random.normal(\n",
    "    key,\n",
    "    (\n",
    "        N,\n",
    "        D,\n",
    "    ),\n",
    ")\n",
    "layer_sizes = [3, 1]  # 1 hidden layer of size 3, 1 scalar output\n",
    "\n",
    "print(\"calling constructor\")\n",
    "model = MLP(layer_sizes)  # just initialize attributes of the object\n",
    "print(\"OUTPUT\")\n",
    "print(model)\n",
    "\n",
    "print(\"\\ncalling init\")\n",
    "variables = model.init(key, x)  # calls setup then __call___\n",
    "print(\"OUTPUT\")\n",
    "print(variables)\n",
    "\n",
    "\n",
    "print(\"Calling apply\")\n",
    "y = model.apply(variables, x)  # calls setup then __call___\n",
    "print(y)"
   ],
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "text": [
      "calling constructor\n",
      "OUTPUT\n",
      "MLP(\n",
      "    # attributes\n",
      "    features = [3, 1]\n",
      "    default_attr = 42\n",
      ")\n",
      "\n",
      "calling init\n",
      "setup\n",
      "call\n",
      "OUTPUT\n",
      "FrozenDict({\n",
      "    params: {\n",
      "        layers_0: {\n",
      "            kernel: DeviceArray([[0.57725, 0.43926, 0.69045],\n",
      "                         [0.02542, 0.50461, 0.56675],\n",
      "                         [0.07185, 0.17350, -0.04227]], dtype=float32),\n",
      "            bias: DeviceArray([0.00000, 0.00000, 0.00000], dtype=float32),\n",
      "        },\n",
      "        layers_1: {\n",
      "            kernel: DeviceArray([[0.24313],\n",
      "                         [0.94535],\n",
      "                         [-0.12602]], dtype=float32),\n",
      "            bias: DeviceArray([0.00000], dtype=float32),\n",
      "        },\n",
      "    },\n",
      "})\n",
      "\n",
      "W0\n",
      "[[0.57725 0.43926 0.69045]\n",
      " [0.02542 0.50461 0.56675]\n",
      " [0.07185 0.17350 -0.04227]]\n",
      "Calling apply\n",
      "setup\n",
      "call\n",
      "[[0.02978]\n",
      " [0.66403]]\n"
     ],
     "name": "stdout"
    }
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5lwM1j1WksDG"
   },
   "source": [
    "# Compact modules\n",
    "\n",
    "To reduce the amount of boiler plate code, flax makes it possible to define a module just by writing the `call` method, avoiding the need to write a `setup` function. The corresponding layers will be created when the `init` funciton is called, so the input shape can be inferred lazily (when passed an input). "
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Akq_iXXdktwb",
    "outputId": "2827db63-b8a0-4500-dd78-bd6b49f72065"
   },
   "source": [
    "class MLP(nn.Module):\n",
    "    features: Sequence[int]\n",
    "\n",
    "    @nn.compact\n",
    "    def __call__(self, inputs):\n",
    "        x = inputs\n",
    "        for i, feat in enumerate(self.features):\n",
    "            x = nn.Dense(feat)(x)\n",
    "            if i != len(self.features) - 1:\n",
    "                x = nn.relu(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "model = MLP(layer_sizes)\n",
    "print(model)\n",
    "\n",
    "params = model.init(key, x)\n",
    "print(params)\n",
    "\n",
    "y = model.apply(params, x)\n",
    "print(y)"
   ],
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "text": [
      "MLP(\n",
      "    # attributes\n",
      "    features = [3, 1]\n",
      ")\n",
      "FrozenDict({\n",
      "    params: {\n",
      "        Dense_0: {\n",
      "            kernel: DeviceArray([[0.28216, 1.03322, 0.07901],\n",
      "                         [0.15159, -0.50100, -0.22373],\n",
      "                         [-0.40327, -0.39875, -0.09402]], dtype=float32),\n",
      "            bias: DeviceArray([0.00000, 0.00000, 0.00000], dtype=float32),\n",
      "        },\n",
      "        Dense_1: {\n",
      "            kernel: DeviceArray([[0.25432],\n",
      "                         [0.76792],\n",
      "                         [0.48329]], dtype=float32),\n",
      "            bias: DeviceArray([0.00000], dtype=float32),\n",
      "        },\n",
      "    },\n",
      "})\n",
      "[[0.56035]\n",
      " [1.07065]]\n"
     ],
     "name": "stdout"
    }
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dNiuZ54yB7Gj"
   },
   "source": [
    "# Explicit parameter initialization\n",
    "\n",
    "We can control the initialization of the random parameters in each submodule by specifying an init function. Below we show how to initialize our MLP to match the vanilla JAX model. We then check both methods give the same outputs."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "5W_lEFsU4t04"
   },
   "source": [
    "def make_const_init(x):\n",
    "    def init_params(key, shape, dtype=jnp.float32):\n",
    "        return x\n",
    "\n",
    "    return init_params\n",
    "\n",
    "\n",
    "class MLP_init(nn.Module):\n",
    "    features: Sequence[int]\n",
    "    params_init: Dict\n",
    "\n",
    "    def setup(self):\n",
    "        nlayers = len(self.features)\n",
    "        layers = []\n",
    "        for i in range(nlayers):\n",
    "            W = self.params_init[f\"W{i}\"]\n",
    "            b = self.params_init[f\"b{i}\"]\n",
    "            weights_init = make_const_init(W)\n",
    "            bias_init = make_const_init(b)\n",
    "            layer = nn.Dense(self.features[i], kernel_init=weights_init, bias_init=bias_init)\n",
    "            layers.append(layer)\n",
    "        self.layers = layers\n",
    "\n",
    "    def __call__(self, inputs):\n",
    "        x = inputs\n",
    "        for i, lyr in enumerate(self.layers):\n",
    "            x = lyr(x)\n",
    "            if i != len(self.layers) - 1:\n",
    "                x = nn.relu(x)\n",
    "        return x"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "R27PhzrLY_zJ",
    "outputId": "adaba9d1-90a4-444b-95be-cef4da0768fe"
   },
   "source": [
    "params_init = params0\n",
    "model = MLP_init(layer_sizes, params_init)\n",
    "print(model)\n",
    "\n",
    "variables = model.init(key, x)\n",
    "params = variables[\"params\"]\n",
    "print(params)\n",
    "\n",
    "W0 = params0[\"W0\"]\n",
    "W = params[\"layers_0\"][\"kernel\"]\n",
    "assert np.allclose(W, W0)\n",
    "\n",
    "y = model.apply(variables, x)\n",
    "print(y)\n",
    "assert np.allclose(y, y0)"
   ],
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "text": [
      "MLP_init(\n",
      "    # attributes\n",
      "    features = [3, 1]\n",
      "    params_init = {'W0': DeviceArray([[-1.83021, 1.18417, 0.06777],\n",
      "                 [0.34588, 0.37858, -0.65318],\n",
      "                 [0.18976, 0.45157, -0.33964]], dtype=float32), 'b0': DeviceArray([0.00000, 0.00000, 0.00000], dtype=float32), 'W1': DeviceArray([[-1.74905],\n",
      "                 [1.83313],\n",
      "                 [-0.23808]], dtype=float32), 'b1': DeviceArray([0.00000], dtype=float32)}\n",
      ")\n",
      "FrozenDict({\n",
      "    layers_0: {\n",
      "        kernel: DeviceArray([[-1.83021, 1.18417, 0.06777],\n",
      "                     [0.34588, 0.37858, -0.65318],\n",
      "                     [0.18976, 0.45157, -0.33964]], dtype=float32),\n",
      "        bias: DeviceArray([0.00000, 0.00000, 0.00000], dtype=float32),\n",
      "    },\n",
      "    layers_1: {\n",
      "        kernel: DeviceArray([[-1.74905],\n",
      "                     [1.83313],\n",
      "                     [-0.23808]], dtype=float32),\n",
      "        bias: DeviceArray([0.00000], dtype=float32),\n",
      "    },\n",
      "})\n",
      "[[-0.09538]\n",
      " [2.78382]]\n"
     ],
     "name": "stdout"
    }
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Rf8avaA_nGJ1"
   },
   "source": [
    "# Creating your own modules\n",
    "\n",
    "Now we illustrate how to create a module with its own parameters, instead of relying on composing built-in primitives. As an example, we write our own dense layer class."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "WUJ98XpSnS8F",
    "outputId": "ccdc09ef-f87f-4234-d64e-0bd583406851"
   },
   "source": [
    "class SimpleDense(nn.Module):\n",
    "    features: int  # num output features for this layer\n",
    "    kernel_init: Callable = nn.initializers.lecun_normal()\n",
    "    bias_init: Callable = nn.initializers.zeros\n",
    "\n",
    "    @nn.compact\n",
    "    def __call__(self, inputs):\n",
    "        features_in = inputs.shape[-1]  # infer shape from input\n",
    "        features_out = self.features\n",
    "        kernel = self.param(\"kernel\", self.kernel_init, (features_in, features_out))\n",
    "        bias = self.param(\"bias\", self.bias_init, (features_out,))\n",
    "        outputs = jnp.dot(inputs, kernel) + bias\n",
    "        return outputs\n",
    "\n",
    "\n",
    "model = SimpleDense(features=3)\n",
    "print(model)\n",
    "\n",
    "vars = model.init(key, x)\n",
    "print(vars)\n",
    "\n",
    "y = model.apply(vars, x)\n",
    "print(y)"
   ],
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "text": [
      "SimpleDense(\n",
      "    # attributes\n",
      "    features = 3\n",
      "    kernel_init = init\n",
      "    bias_init = zeros\n",
      ")\n",
      "FrozenDict({\n",
      "    params: {\n",
      "        kernel: DeviceArray([[0.32718, 0.05599, 0.17998],\n",
      "                     [-0.12295, 0.70712, 0.28972],\n",
      "                     [0.13731, -0.02853, -0.62830]], dtype=float32),\n",
      "        bias: DeviceArray([0.00000, 0.00000, 0.00000], dtype=float32),\n",
      "    },\n",
      "})\n",
      "[[0.30842 -0.91549 -0.74603]\n",
      " [0.36248 0.24616 0.36943]]\n"
     ],
     "name": "stdout"
    }
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BJpBh933-GTW"
   },
   "source": [
    "# Stochastic layers\n",
    "\n",
    "Some layers may need a source of randomness. If so, we must pass them a PRNG in the `init` and `apply` functions, in addition to the PRNG used for parameter initialization. We illustrate this below using dropout. We construct two versions, one which is stochastic (for training), and one which is deterministic (for evaluation). "
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "tMSpLucO-Yfj",
    "outputId": "9726f1f3-ca25-4946-f9da-29692b1b034c"
   },
   "source": [
    "class Block(nn.Module):\n",
    "    features: int\n",
    "    training: bool\n",
    "\n",
    "    @nn.compact\n",
    "    def __call__(self, inputs):\n",
    "        x = nn.Dense(self.features)(inputs)\n",
    "        x = nn.Dropout(rate=0.5)(x, deterministic=not self.training)\n",
    "        return x\n",
    "\n",
    "\n",
    "N = 1\n",
    "D = 2\n",
    "x = random.uniform(key, (N, D))\n",
    "\n",
    "model = Block(features=3, training=True)\n",
    "key = random.PRNGKey(0)\n",
    "variables = model.init({\"params\": key, \"dropout\": key}, x)\n",
    "# variables = model.init(key, x) # cannot share the rng\n",
    "print(\"variables\", variables)\n",
    "\n",
    "# Apply stochastic model\n",
    "for i in range(2):\n",
    "    key, subkey = random.split(key)\n",
    "    y = model.apply(variables, x, rngs={\"dropout\": subkey})\n",
    "    print(f\"train output {i}, \", y)\n",
    "\n",
    "# Now make a deterministic version\n",
    "eval_model = Block(features=3, training=False)\n",
    "key = random.PRNGKey(0)\n",
    "# variables = eval_model.init({'params': key, 'dropout': key}, x)\n",
    "for i in range(2):\n",
    "    key, subkey = random.split(key)\n",
    "    y = eval_model.apply(variables, x, rngs={\"dropout\": subkey})\n",
    "    print(f\"eval output {i}, \", y)"
   ],
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "text": [
      "variables FrozenDict({\n",
      "    params: {\n",
      "        Dense_0: {\n",
      "            kernel: DeviceArray([[0.99988, -0.14086, -0.99796],\n",
      "                         [1.46673, 0.59637, 0.38263]], dtype=float32),\n",
      "            bias: DeviceArray([0.00000, 0.00000, 0.00000], dtype=float32),\n",
      "        },\n",
      "    },\n",
      "})\n",
      "train output 0,  [[0.00000 1.05814 0.00000]]\n",
      "train output 1,  [[3.12202 1.05814 0.32862]]\n",
      "eval output 0,  [[1.56101 0.52907 0.16431]]\n",
      "eval output 1,  [[1.56101 0.52907 0.16431]]\n"
     ],
     "name": "stdout"
    }
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CHieB2aAumdg"
   },
   "source": [
    "# Stateful layers\n",
    "\n",
    "In addition to parameters, linen modules can contain other kinds of variables, which may be mutable as we illustrate below.\n",
    "Indeed, parameters are just a special case of variable.\n",
    "In particular, this line\n",
    "```\n",
    "p = self.param('param_name', init_fn, shape, dtype)\n",
    "```\n",
    "is a convenient shorthand for this:\n",
    "```\n",
    "p = self.variable('params', 'param_name', lambda s, d: init_fn(self.make_rng('params'), s, d), shape, dtype).value\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EAQxx2Tu8xln"
   },
   "source": [
    "## Example: counter"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "BeGNa8zaut41",
    "outputId": "eb8923e0-ed62-46f9-f11b-80dec053e31a"
   },
   "source": [
    "class Counter(nn.Module):\n",
    "    @nn.compact\n",
    "    def __call__(self):\n",
    "        # variable(collection, name, init_fn, *init_args)\n",
    "        counter1 = self.variable(\"counter\", \"count1\", lambda: jnp.zeros((), jnp.int32))\n",
    "        counter2 = self.variable(\"counter\", \"count2\", lambda: jnp.zeros((), jnp.int32))\n",
    "        is_initialized = self.has_variable(\"counter\", \"count1\")\n",
    "        if is_initialized:\n",
    "            counter1.value += 1\n",
    "            counter2.value += 2\n",
    "        return counter1.value, counter2.value\n",
    "\n",
    "\n",
    "model = Counter()\n",
    "print(model)\n",
    "\n",
    "init_variables = model.init(key)  # calls the `call` method\n",
    "print(\"initialized variables:\\n\", init_variables)\n",
    "counter = init_variables[\"counter\"][\"count1\"]\n",
    "print(\"counter 1 value\", counter)\n",
    "\n",
    "y, mutated_variables = model.apply(init_variables, mutable=[\"counter\"])\n",
    "print(\"mutated variables:\\n\", mutated_variables)\n",
    "print(\"output:\\n\", y)"
   ],
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "text": [
      "Counter()\n",
      "initialized variables:\n",
      " FrozenDict({\n",
      "    counter: {\n",
      "        count1: DeviceArray(1, dtype=int32),\n",
      "        count2: DeviceArray(2, dtype=int32),\n",
      "    },\n",
      "})\n",
      "counter 1 value 1\n",
      "mutated variables:\n",
      " FrozenDict({\n",
      "    counter: {\n",
      "        count1: DeviceArray(2, dtype=int32),\n",
      "        count2: DeviceArray(4, dtype=int32),\n",
      "    },\n",
      "})\n",
      "output:\n",
      " (DeviceArray(2, dtype=int32), DeviceArray(4, dtype=int32))\n"
     ],
     "name": "stdout"
    }
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1IaC2RT1v65t"
   },
   "source": [
    "## Combining mutable variables and immutable parameters\n",
    "\n",
    "We can combine mutable variables with immutable parameters.\n",
    "As an example, consider a simplified version of batch normalization, which \n",
    " computes the running mean of its inputs, and adds an optimzable offset (bias) term. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "NXP19telv_Y_"
   },
   "source": [
    "class BiasAdderWithRunningMean(nn.Module):\n",
    "    decay: float = 0.99\n",
    "\n",
    "    @nn.compact\n",
    "    def __call__(self, x):\n",
    "        is_initialized = self.has_variable(\"params\", \"bias\")\n",
    "\n",
    "        # variable(collection, name, init_fn, *init_args)\n",
    "        ra_mean = self.variable(\"batch_stats\", \"mean\", lambda s: jnp.zeros(s), x.shape[1:])\n",
    "\n",
    "        dummy_mutable = self.variable(\"mutables\", \"dummy\", lambda s: 42, 0)\n",
    "\n",
    "        # param(name, init_fn, *init_args)\n",
    "        bias = self.param(\"bias\", lambda rng, shape: jnp.ones(shape), x.shape[1:])\n",
    "\n",
    "        if is_initialized:\n",
    "            ra_mean.value = self.decay * ra_mean.value + (1.0 - self.decay) * jnp.mean(x, axis=0, keepdims=True)\n",
    "\n",
    "        return x - ra_mean.value + bias"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "x_WsMGY8xA_x"
   },
   "source": [
    "\n",
    "The intial variables are:\n",
    "params = (bias=1), batch_stats=(mean=0)\n",
    "\n",
    "If we pass in x=ones(N,D), the  running average becomes\n",
    "$$\n",
    "0.99*0 + (1-0.99)*1 = 0.01\n",
    "$$\n",
    "and the output becomes\n",
    "$$\n",
    "1 - 0.01 + 1 = 1.99\n",
    "$$\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dvXKCE8yxiTu",
    "outputId": "4ddb1117-32a0-481d-d8bb-876010d0e821"
   },
   "source": [
    "key = random.PRNGKey(0)\n",
    "N = 2\n",
    "D = 5\n",
    "x = jnp.ones((N, D))\n",
    "model = BiasAdderWithRunningMean()\n",
    "\n",
    "variables = model.init(key, x)\n",
    "print(\"initial variables:\\n\", variables)\n",
    "nonstats, stats = variables.pop(\"batch_stats\")\n",
    "print(\"nonstats\", nonstats)\n",
    "print(\"stats\", stats)"
   ],
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "text": [
      "initial variables:\n",
      " FrozenDict({\n",
      "    batch_stats: {\n",
      "        mean: DeviceArray([0.00000, 0.00000, 0.00000, 0.00000, 0.00000], dtype=float32),\n",
      "    },\n",
      "    mutables: {\n",
      "        dummy: 42,\n",
      "    },\n",
      "    params: {\n",
      "        bias: DeviceArray([1.00000, 1.00000, 1.00000, 1.00000, 1.00000], dtype=float32),\n",
      "    },\n",
      "})\n",
      "nonstats FrozenDict({\n",
      "    mutables: {\n",
      "        dummy: 42,\n",
      "    },\n",
      "    params: {\n",
      "        bias: DeviceArray([1.00000, 1.00000, 1.00000, 1.00000, 1.00000], dtype=float32),\n",
      "    },\n",
      "})\n",
      "stats FrozenDict({\n",
      "    mean: DeviceArray([0.00000, 0.00000, 0.00000, 0.00000, 0.00000], dtype=float32),\n",
      "})\n"
     ],
     "name": "stdout"
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Ytr2_w9U12PT",
    "outputId": "30555a51-9b09-4ef2-8222-98c9b52e4a47"
   },
   "source": [
    "y, mutables = model.apply(variables, x, mutable=[\"batch_stats\"])\n",
    "print(\"output\", y)\n",
    "print(\"mutables\", mutables)"
   ],
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "text": [
      "output [[1.99000 1.99000 1.99000 1.99000 1.99000]\n",
      " [1.99000 1.99000 1.99000 1.99000 1.99000]]\n",
      "mutables FrozenDict({\n",
      "    batch_stats: {\n",
      "        mean: DeviceArray([[0.01000, 0.01000, 0.01000, 0.01000, 0.01000]], dtype=float32),\n",
      "    },\n",
      "})\n"
     ],
     "name": "stdout"
    }
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "B1g2GW3f3B-Z"
   },
   "source": [
    "To call the function with the updated batch stats, we have to stitch together the new mutated state with the old state, as shown below.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "cpBb21A72Bdj",
    "outputId": "d5ce7521-90c4-48a0-a180-4f02be5fe5f8"
   },
   "source": [
    "variables = unfreeze(nonstats)\n",
    "print(variables)\n",
    "variables[\"batch_stats\"] = mutables[\"batch_stats\"]\n",
    "variables = freeze(variables)\n",
    "print(variables)"
   ],
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "text": [
      "{'mutables': {'dummy': 42}, 'params': {'bias': DeviceArray([1.00000, 1.00000, 1.00000, 1.00000, 1.00000], dtype=float32)}}\n",
      "FrozenDict({\n",
      "    mutables: {\n",
      "        dummy: 42,\n",
      "    },\n",
      "    params: {\n",
      "        bias: DeviceArray([1.00000, 1.00000, 1.00000, 1.00000, 1.00000], dtype=float32),\n",
      "    },\n",
      "    batch_stats: {\n",
      "        mean: DeviceArray([[0.01000, 0.01000, 0.01000, 0.01000, 0.01000]], dtype=float32),\n",
      "    },\n",
      "})\n"
     ],
     "name": "stdout"
    }
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sa7nH74Y5-Lg"
   },
   "source": [
    "If we pass in x=2*ones(N,D), the running average gets updated to\n",
    "$$\n",
    "0.99 * 0.01 + (1-0.99) * 2.0 = 0.0299\n",
    "$$\n",
    "and the output becomes\n",
    "$$\n",
    "2- 0.0299 + 1 = 2.9701\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "t2dF2si51QN5",
    "outputId": "6177ee1c-41b7-40e6-d954-d0c1c85b0180"
   },
   "source": [
    "x = 2 * jnp.ones((N, D))\n",
    "y, mutables = model.apply(variables, x, mutable=[\"batch_stats\"])\n",
    "print(\"output\", y)\n",
    "print(\"batch_stats\", mutables)\n",
    "\n",
    "assert np.allclose(y, 2.9701)\n",
    "assert np.allclose(mutables[\"batch_stats\"][\"mean\"], 0.0299)"
   ],
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "text": [
      "output [[2.97010 2.97010 2.97010 2.97010 2.97010]\n",
      " [2.97010 2.97010 2.97010 2.97010 2.97010]]\n",
      "batch_stats FrozenDict({\n",
      "    batch_stats: {\n",
      "        mean: DeviceArray([[0.02990, 0.02990, 0.02990, 0.02990, 0.02990]], dtype=float32),\n",
      "    },\n",
      "})\n"
     ],
     "name": "stdout"
    }
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cnBmgGxOoPKU"
   },
   "source": [
    "# Optimization\n",
    "\n",
    "Flax has several built-in (first-order) optimizers, as we illustrate below on a random linear function. (Note that we can also fit a model defined in flax using some other kind of optimizer, such as that provided by the [optax library](https://github.com/deepmind/optax).)"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "OTHgj_pMra3H",
    "outputId": "d142c2bb-c725-47e6-8cba-5b55f9f16b48"
   },
   "source": [
    "D = 5\n",
    "key = jax.random.PRNGKey(0)\n",
    "params = {\"w\": jax.random.normal(key, (D,))}\n",
    "print(params)\n",
    "\n",
    "x = jax.random.normal(key, (D,))\n",
    "\n",
    "\n",
    "def loss(params):\n",
    "    w = params[\"w\"]\n",
    "    return jnp.dot(x, w)\n",
    "\n",
    "\n",
    "loss_grad_fn = jax.value_and_grad(loss)\n",
    "v, g = loss_grad_fn(params)\n",
    "print(v)\n",
    "print(g)"
   ],
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "text": [
      "{'w': DeviceArray([0.18784, -1.28334, -0.27109, 1.24906, 0.24447], dtype=float32)}\n",
      "3.375659\n",
      "{'w': DeviceArray([0.18784, -1.28334, -0.27109, 1.24906, 0.24447], dtype=float32)}\n"
     ],
     "name": "stdout"
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "7KdmBHa8oWFY",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "3695c5f5-339c-4e27-d80e-30d100ddae66"
   },
   "source": [
    "from flax import optim\n",
    "\n",
    "optimizer_def = optim.Momentum(learning_rate=0.1, beta=0.9)\n",
    "print(optimizer_def)\n",
    "\n",
    "optimizer = optimizer_def.create(params)\n",
    "print(optimizer)"
   ],
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "text": [
      "<flax.optim.momentum.Momentum object at 0x7fbd09abceb8>\n",
      "Optimizer(optimizer_def=<flax.optim.momentum.Momentum object at 0x7fbd09abceb8>, state=OptimizerState(step=DeviceArray(0, dtype=int32), param_states={'w': _MomentumParamState(momentum=DeviceArray([0.00000, 0.00000, 0.00000, 0.00000, 0.00000], dtype=float32))}), target={'w': DeviceArray([0.18784, -1.28334, -0.27109, 1.24906, 0.24447], dtype=float32)})\n"
     ],
     "name": "stdout"
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1JpgauX_ox_w",
    "outputId": "c649c61c-93ba-41a0-a834-2c254a53a243"
   },
   "source": [
    "for i in range(10):\n",
    "    params = optimizer.target\n",
    "    loss_val, grad = loss_grad_fn(params)\n",
    "    optimizer = optimizer.apply_gradient(grad)\n",
    "    params = optimizer.target\n",
    "    print(\"step {}, loss {:0.3f}, params {}\".format(i, loss_val, params))"
   ],
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "text": [
      "step 0, loss -10.593, params {'w': DeviceArray([-0.71837, 4.90788, 1.03673, -4.77677, -0.93493], dtype=float32)}\n",
      "step 1, loss -12.910, params {'w': DeviceArray([-0.85316, 5.82877, 1.23126, -5.67306, -1.11035], dtype=float32)}\n",
      "step 2, loss -15.332, params {'w': DeviceArray([-0.99326, 6.78590, 1.43345, -6.60462, -1.29268], dtype=float32)}\n",
      "step 3, loss -17.849, params {'w': DeviceArray([-1.13813, 7.77566, 1.64252, -7.56794, -1.48122], dtype=float32)}\n",
      "step 4, loss -20.453, params {'w': DeviceArray([-1.28730, 8.79477, 1.85780, -8.55983, -1.67536], dtype=float32)}\n",
      "step 5, loss -23.133, params {'w': DeviceArray([-1.44033, 9.84031, 2.07866, -9.57743, -1.87453], dtype=float32)}\n",
      "step 6, loss -25.884, params {'w': DeviceArray([-1.59685, 10.90963, 2.30454, -10.61818, -2.07823], dtype=float32)}\n",
      "step 7, loss -28.696, params {'w': DeviceArray([-1.75650, 12.00035, 2.53494, -11.67977, -2.28600], dtype=float32)}\n",
      "step 8, loss -31.565, params {'w': DeviceArray([-1.91897, 13.11033, 2.76941, -12.76010, -2.49745], dtype=float32)}\n",
      "step 9, loss -34.485, params {'w': DeviceArray([-2.08397, 14.23764, 3.00754, -13.85730, -2.71220], dtype=float32)}\n"
     ],
     "name": "stdout"
    }
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_ITTDWT2ECxC"
   },
   "source": [
    "# Worked example: MLP for MNIST \n",
    "\n",
    "We demonstrate how to fit a shallow MLP to MNIST using Flax.\n",
    "We use this function:\n",
    "https://github.com/probml/pyprobml/blob/master/scripts/fit_flax.py\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vavamofruHS_"
   },
   "source": [
    "## Import code"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "W71bGFI46Cc0",
    "outputId": "5a29b55a-e940-4fc0-d40d-9b84a0e54c46",
    "colab": {
     "base_uri": "https://localhost:8080/"
    }
   },
   "source": [
    "!pip install superimport"
   ],
   "execution_count": 4,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Collecting superimport\n",
      "  Downloading superimport-0.3.3.tar.gz (5.8 kB)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from superimport) (2.23.0)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->superimport) (2.10)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->superimport) (2021.5.30)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->superimport) (1.24.3)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->superimport) (3.0.4)\n",
      "Building wheels for collected packages: superimport\n",
      "  Building wheel for superimport (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for superimport: filename=superimport-0.3.3-py3-none-any.whl size=5766 sha256=4a2891b002c0f5f3e2330adca027096d023e29accf21b2ae4ceb6b89445ef44f\n",
      "  Stored in directory: /root/.cache/pip/wheels/0f/0a/7e/ba2303ac54e68950f97db02ebf09ee4ef5c794e1adb656cb68\n",
      "Successfully built superimport\n",
      "Installing collected packages: superimport\n",
      "Successfully installed superimport-0.3.3\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ItaIH9dyocZA",
    "outputId": "32330bd5-a0ff-49c2-8946-18a6b89238c1"
   },
   "source": [
    "\n",
    "!wget https://raw.githubusercontent.com/probml/pyprobml/master/scripts/fit_flax.py   \n",
    "import fit_flax as ff\n",
    "ff.test()\n"
   ],
   "execution_count": 5,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "--2021-09-11 03:30:48--  https://raw.githubusercontent.com/probml/pyprobml/master/scripts/fit_flax.py\n",
      "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
      "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 5638 (5.5K) [text/plain]\n",
      "Saving to: ‘fit_flax.py.1’\n",
      "\n",
      "\rfit_flax.py.1         0%[                    ]       0  --.-KB/s               \rfit_flax.py.1       100%[===================>]   5.51K  --.-KB/s    in 0s      \n",
      "\n",
      "2021-09-11 03:30:48 (65.1 MB/s) - ‘fit_flax.py.1’ saved [5638/5638]\n",
      "\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "ERROR: superimport : missing python module: flax \n",
      "Trying try to install automatcially\n",
      "WARNING:root:Package was not found in the reverse index, trying pypi.\n",
      "/usr/local/lib/python3.7/dist-packages/jax/_src/config.py:171: UserWarning: enable_omnistaging() is a no-op in JAX versions 0.2.12 and higher;\n",
      "see https://github.com/google/jax/blob/main/design_notes/omnistaging.md\n",
      "  \"enable_omnistaging() is a no-op in JAX versions 0.2.12 and higher;\\n\"\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "testing fit-flax\n",
      "train step: 0, loss: 1.9212, accuracy: 0.33\n",
      "train step: 1, loss: 1.8051, accuracy: 0.33\n",
      "FrozenDict({\n",
      "    Dense_0: {\n",
      "        bias: DeviceArray([-0.05753, -0.06485, 0.01820, -0.06623, 0.03506, 0.01663,\n",
      "                     0.03751, 0.03186, 0.03567, 0.01368], dtype=float32),\n",
      "        kernel: DeviceArray([[0.04317, -0.03052, 0.00153, -0.08923, 0.00806, 0.00845,\n",
      "                      0.01886, 0.01948, 0.01805, 0.00214],\n",
      "                     [0.05920, 0.03486, -0.01555, 0.05232, -0.03050, -0.01319,\n",
      "                      -0.02862, -0.02186, -0.02522, -0.01143],\n",
      "                     [0.01316, 0.02697, -0.01047, 0.09079, -0.02449, -0.01311,\n",
      "                      -0.02791, -0.02281, -0.02392, -0.00822],\n",
      "                     [0.04932, -0.15770, -0.00438, 0.08807, -0.02104, -0.00335,\n",
      "                      0.00400, 0.02333, 0.02383, -0.00208],\n",
      "                     [0.05093, -0.04816, -0.00149, -0.04978, -0.00104, 0.00457,\n",
      "                      0.01233, 0.01710, 0.01562, -0.00007]], dtype=float32),\n",
      "    },\n",
      "})\n",
      "{'train_loss': [DeviceArray(1.92125, dtype=float32), DeviceArray(1.80505, dtype=float32)], 'train_accuracy': [DeviceArray(0.33333, dtype=float32), DeviceArray(0.33333, dtype=float32)], 'test_loss': [DeviceArray(1.80505, dtype=float32), DeviceArray(1.59708, dtype=float32)], 'test_accuracy': [DeviceArray(0.33333, dtype=float32), DeviceArray(0.66667, dtype=float32)]}\n",
      "test passed\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "E_xSZi3v03pC"
   },
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "SIIkAHep6nyN"
   },
   "source": [
    "import tensorflow_datasets as tfds\n",
    "import tensorflow as tf"
   ],
   "execution_count": 9,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "l4uNqjBIW0we",
    "outputId": "4690ea0c-4c45-4f8b-8249-76c630e00d1f"
   },
   "source": [
    "def process_record(batch):\n",
    "    image = batch[\"image\"]\n",
    "    label = batch[\"label\"]\n",
    "    # flatten image to vector\n",
    "    shape = image.get_shape().as_list()\n",
    "    D = np.prod(shape)  # no batch dimension\n",
    "    image = tf.reshape(image, (D,))\n",
    "    # rescale to -1..+1\n",
    "    image = tf.cast(image, dtype=tf.float32)\n",
    "    image = ((image / 255.0) - 0.5) * 2.0\n",
    "    # convert to standard names\n",
    "    return {\"X\": image, \"y\": label}\n",
    "\n",
    "\n",
    "def load_mnist(split, batch_size):\n",
    "    dataset, info = tfds.load(\"mnist\", split=split, with_info=True)\n",
    "    dataset = dataset.map(process_record)\n",
    "    if split == \"train\":\n",
    "        dataset = dataset.shuffle(10 * batch_size, seed=0)\n",
    "    dataset = dataset.batch(batch_size)\n",
    "    dataset = dataset.prefetch(tf.data.experimental.AUTOTUNE)\n",
    "    dataset = dataset.cache()\n",
    "    dataset = dataset.repeat()\n",
    "    dataset = tfds.as_numpy(dataset)  # leave TF behind\n",
    "    num_examples = info.splits[split].num_examples\n",
    "    return iter(dataset), num_examples\n",
    "\n",
    "\n",
    "batch_size = 100\n",
    "train_iter, num_train = load_mnist(\"train\", batch_size)\n",
    "test_iter, num_test = load_mnist(\"test\", batch_size)\n",
    "\n",
    "num_epochs = 3\n",
    "num_steps = num_train // batch_size\n",
    "print(f\"{num_epochs} epochs with batch size {batch_size} will take {num_steps} steps\")\n",
    "\n",
    "batch = next(train_iter)\n",
    "print(batch[\"X\"].shape)\n",
    "print(batch[\"y\"].shape)"
   ],
   "execution_count": 10,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "3 epochs with batch size 100 will take 600 steps\n",
      "(100, 784)\n",
      "(100,)\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rLiWUSjR05BQ"
   },
   "source": [
    "## Model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "cLwAwqd4Nzvy"
   },
   "source": [
    "class Model(nn.Module):\n",
    "    nhidden: int\n",
    "    nclasses: int\n",
    "\n",
    "    @nn.compact\n",
    "    def __call__(self, x):\n",
    "        if self.nhidden > 0:\n",
    "            x = nn.Dense(self.nhidden)(x)\n",
    "            x = nn.relu(x)\n",
    "        x = nn.Dense(self.nclasses)(x)  # logits\n",
    "        x = nn.log_softmax(x)  # log probabilities\n",
    "        return x"
   ],
   "execution_count": 16,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9JsVFGfU628j"
   },
   "source": [
    "## Training loop\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 867
    },
    "id": "KDAJthPTvxI7",
    "outputId": "2467ef1a-2327-420d-e594-6871b77cc104"
   },
   "source": [
    "model = Model(nhidden=128, nclasses=10)\n",
    "rng = jax.random.PRNGKey(0)\n",
    "num_steps = 200\n",
    "\n",
    "params, history = ff.fit_model(model, rng, num_steps, train_iter, test_iter, print_every=20)\n",
    "\n",
    "display(history)"
   ],
   "execution_count": 17,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "train step: 0, loss: 2.4736, accuracy: 0.13\n",
      "train step: 20, loss: 1.3480, accuracy: 0.60\n",
      "train step: 40, loss: 0.6385, accuracy: 0.80\n",
      "train step: 60, loss: 0.9009, accuracy: 0.71\n",
      "train step: 80, loss: 0.6118, accuracy: 0.83\n",
      "train step: 100, loss: 0.3172, accuracy: 0.91\n",
      "train step: 120, loss: 0.5050, accuracy: 0.82\n",
      "train step: 140, loss: 0.5362, accuracy: 0.83\n",
      "train step: 160, loss: 0.4464, accuracy: 0.86\n",
      "train step: 180, loss: 0.7583, accuracy: 0.81\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "{'test_accuracy': [DeviceArray(0.14000, dtype=float32),\n",
       "  DeviceArray(0.61000, dtype=float32),\n",
       "  DeviceArray(0.82000, dtype=float32),\n",
       "  DeviceArray(0.80000, dtype=float32),\n",
       "  DeviceArray(0.82000, dtype=float32),\n",
       "  DeviceArray(0.83000, dtype=float32),\n",
       "  DeviceArray(0.86000, dtype=float32),\n",
       "  DeviceArray(0.84000, dtype=float32),\n",
       "  DeviceArray(0.85000, dtype=float32),\n",
       "  DeviceArray(0.86000, dtype=float32)],\n",
       " 'test_loss': [DeviceArray(2.60662, dtype=float32),\n",
       "  DeviceArray(1.52616, dtype=float32),\n",
       "  DeviceArray(0.58906, dtype=float32),\n",
       "  DeviceArray(0.77289, dtype=float32),\n",
       "  DeviceArray(0.62323, dtype=float32),\n",
       "  DeviceArray(0.55543, dtype=float32),\n",
       "  DeviceArray(0.45732, dtype=float32),\n",
       "  DeviceArray(0.54828, dtype=float32),\n",
       "  DeviceArray(0.61440, dtype=float32),\n",
       "  DeviceArray(0.54720, dtype=float32)],\n",
       " 'train_accuracy': [DeviceArray(0.13000, dtype=float32),\n",
       "  DeviceArray(0.60000, dtype=float32),\n",
       "  DeviceArray(0.80000, dtype=float32),\n",
       "  DeviceArray(0.71000, dtype=float32),\n",
       "  DeviceArray(0.83000, dtype=float32),\n",
       "  DeviceArray(0.91000, dtype=float32),\n",
       "  DeviceArray(0.82000, dtype=float32),\n",
       "  DeviceArray(0.83000, dtype=float32),\n",
       "  DeviceArray(0.86000, dtype=float32),\n",
       "  DeviceArray(0.81000, dtype=float32)],\n",
       " 'train_loss': [DeviceArray(2.47364, dtype=float32),\n",
       "  DeviceArray(1.34795, dtype=float32),\n",
       "  DeviceArray(0.63851, dtype=float32),\n",
       "  DeviceArray(0.90089, dtype=float32),\n",
       "  DeviceArray(0.61182, dtype=float32),\n",
       "  DeviceArray(0.31721, dtype=float32),\n",
       "  DeviceArray(0.50501, dtype=float32),\n",
       "  DeviceArray(0.53616, dtype=float32),\n",
       "  DeviceArray(0.44640, dtype=float32),\n",
       "  DeviceArray(0.75831, dtype=float32)]}"
      ]
     },
     "metadata": {}
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 279
    },
    "id": "RWv2Sspl8EAN",
    "outputId": "51acc788-1f60-4711-d6f6-c9254c8c061d"
   },
   "source": [
    "plt.figure()\n",
    "plt.plot(history[\"test_accuracy\"], \"o-\", label=\"test accuracy\")\n",
    "plt.xlabel(\"num. minibatches\")\n",
    "plt.legend()\n",
    "plt.show()"
   ],
   "execution_count": 19,
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     }
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "oWe69Z51Q3Kz"
   },
   "source": [
    ""
   ],
   "execution_count": null,
   "outputs": []
  }
 ]
}