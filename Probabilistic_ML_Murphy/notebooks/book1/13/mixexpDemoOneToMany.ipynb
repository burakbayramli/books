{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e8d4601",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "try:\n",
    "    import probml_utils as pml\n",
    "except ModuleNotFoundError:\n",
    "    %pip install -qq git+https://github.com/probml/probml-utils.git\n",
    "    import probml_utils as pml\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "try:\n",
    "    import pandas as pd\n",
    "except ModuleNotFoundError:\n",
    "    %pip install -qq pandas\n",
    "    import pandas as pd\n",
    "from scipy.special import logsumexp\n",
    "try:\n",
    "    from sklearn.linear_model import LinearRegression\n",
    "except ModuleNotFoundError:\n",
    "    %pip install -qq scikit-learn\n",
    "    from sklearn.linear_model import LinearRegression\n",
    "from scipy.stats import multivariate_normal\n",
    "import probml_utils as pml\n",
    "\n",
    "n = 200\n",
    "np.random.seed(1)\n",
    "y = np.random.rand(n, 1)\n",
    "eta = np.random.randn(n,1)*0.05\n",
    "x = y + 0.3*np.sin(2*3.1415*y) + eta\n",
    "data = np.concatenate((x, y), axis=1)\n",
    "K = 3\n",
    "\n",
    "X = x.reshape(-1, 1)\n",
    "y = y.reshape(-1, 1)\n",
    "xtest = (x)\n",
    "ytest = (y)\n",
    "\n",
    "plt.figure()\n",
    "plt.scatter(x, y, edgecolors='blue', color=\"none\")\n",
    "plt.title('Inverse problem')\n",
    "pml.savefig('mixexp_inverse.pdf')\n",
    "plt.show()\n",
    "\n",
    "def normalizelogspace(x):\n",
    "  L = logsumexp(x, axis=1).reshape(-1, 1)\n",
    "  Lnew = np.repeat(L, 3, axis=1)\n",
    "  y = x - Lnew\n",
    "  return y, Lnew\n",
    "\n",
    "def is_pos_def(x):\n",
    "    return np.all(np.linalg.eigvals(x) > 0)\n",
    "\n",
    "K = 3 #nmix\n",
    "D = np.size(X, axis=1)\n",
    "N = np.size(X, axis=0)\n",
    "norm = 50\n",
    "max_iter = 39\n",
    "iteration = 0\n",
    "r = np.zeros((N, K))\n",
    "while iteration < max_iter:\n",
    "\n",
    "      #E-step :\n",
    "      np.random.seed(iteration)\n",
    "      Wy = 0.1*np.random.randn(D, K)\n",
    "      bias = 0.3*np.random.randn(D, K)\n",
    "      mixweights = np.random.rand(1, K)\n",
    "      normmw =  np.linalg.norm(mixweights)\n",
    "      mixweights = mixweights/normmw\n",
    "      sigma2 = 0.1*np.random.randn(1, K)\n",
    "      q = np.log(mixweights)\n",
    "      logprior = np.repeat(q, N, axis=0)\n",
    "      loglik = np.zeros((N, K))\n",
    "      for k in range(K):\n",
    "        vecM = X*Wy[:, k] + bias[:, k]\n",
    "        vecM = vecM.reshape(200, )\n",
    "        cov = sigma2[0, k]\n",
    "        cov = np.abs(cov)\n",
    "        vecX = y\n",
    "        x = multivariate_normal.logpdf(vecX, mean=vecM, cov=cov)\n",
    "        x = x /norm\n",
    "        loglik[:, k] = x\n",
    "      logpost = loglik + logprior\n",
    "      logpost, logZ = normalizelogspace(logpost)\n",
    "      ll = np.sum(logZ)\n",
    "      post = np.exp(logpost)\n",
    "\n",
    "      #M-step:\n",
    "      r = post\n",
    "      mixweights = np.sum(r, axis=0)/N\n",
    "      mixweights = mixweights.reshape(1, -1)\n",
    "\n",
    "      for k in range(K):\n",
    "        reg = LinearRegression()\n",
    "        model = reg.fit(X, y, r[:, k])\n",
    "        Wy[:, k] = model.coef_\n",
    "        bias[:, k] = model.intercept_\n",
    "        yhat_ = np.multiply(X, Wy[:, k]) + bias[:, k]\n",
    "        sigma2[:, k] = np.sum(np.multiply(r[:, k], np.square(y-yhat_))) / sum(r[:, k])\n",
    "\n",
    "      iteration = iteration + 1\n",
    "\n",
    "N = np.size(X, axis=0)\n",
    "D = np.size(X, axis=1)\n",
    "K = 3\n",
    "weights = np.repeat(mixweights, N, axis=0)\n",
    "muk = np.zeros((N, K))\n",
    "vk = np.zeros((N, K))\n",
    "mu = np.zeros((N, ))\n",
    "v = np.zeros((N, 1))\n",
    "b = 0.3*np.random.randn(D, K)\n",
    "for k in range(K):\n",
    "    w = X*Wy[:, k] + bias[:, k]\n",
    "    w = w.reshape(-1, )\n",
    "    muk[:, k] = w\n",
    "    q = np.multiply(weights[:, k], muk[:, k])\n",
    "    mu = mu + q\n",
    "    vk[:, k] = sigma2[:, k]\n",
    "    v = v + np.multiply(weights[:, k], (vk[:, k] + np.square(muk[:, k]))).reshape(-1, 1)\n",
    "\n",
    "v = v - np.square(mu).reshape(-1, 1)\n",
    "\n",
    "plt.figure()\n",
    "plt.scatter(xtest, y, edgecolors='blue', color=\"none\")\n",
    "plt.plot(xtest, muk[:, 0])\n",
    "plt.plot(xtest, muk[:, 1])\n",
    "plt.plot(xtest, muk[:, 2])\n",
    "plt.title('Expert-predictions')\n",
    "pml.savefig('mixexp_expert_predictions.pdf')\n",
    "plt.show()\n",
    "\n",
    "plt.figure()\n",
    "for i in range(K):\n",
    "  plt.scatter(y, post[:, i])\n",
    "plt.title('Gating functions')\n",
    "pml.savefig('mixexp_gating_functions.pdf')\n",
    "plt.show()\n",
    "\n",
    "map = np.empty((K, 1))\n",
    "map = np.argmax(post, axis=1)\n",
    "map = map.reshape(-1, 1)\n",
    "yhat = np.empty((N, 1))\n",
    "for i in range(N):\n",
    "  yhat[i, 0] = muk[i, map[i, 0]]\n",
    "\n",
    "plt.figure()\n",
    "plt.scatter(xtest, yhat, marker=6, color='black')\n",
    "plt.scatter(xtest, mu, marker='X', color='red')\n",
    "plt.scatter(xtest, y, edgecolors='blue', color=\"none\")\n",
    "plt.title('prediction')\n",
    "plt.legend(['mode', 'mean'])\n",
    "pml.savefig('mixexp_predictions.pdf')\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
