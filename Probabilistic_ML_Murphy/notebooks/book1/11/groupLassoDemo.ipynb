{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b533dd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Author: Meduri Venkata Shivaditya\n",
    "\"\"\"\n",
    "Figure 11.16 and 11.17 in the book \"Probabilistic Machine Learning: An Introduction by Kevin P. Murphy\"\n",
    "Dependencies: spams(pip install -qq spams), group-lasso(pip install -qq group-lasso)\n",
    "Illustration of group lasso:\n",
    "To show the effectiveness of group lasso, in this code we demonstrate:\n",
    "a)Actual Data b)Vanilla Lasso c)Group lasso(L2 norm) d)Group Lasso(L infinity norm)\n",
    "on signal which is piecewise gaussian and on signal which is piecewise constant\n",
    "we apply the regression methods to the linear model - y = XW + ε and estimate and plot W\n",
    "(X)Data: 1024(rows) x 4096(dimensions)\n",
    "(W)Coefficients : 4096(dimensions)x1(coefficient for the corresponding row)\n",
    "(ε)Noise(simulated via  N(0,1e-4)): 4096(dimensions) x 1(Noise for the corresponding row)\n",
    "(y)Target Variable: 1024(rows) x 1(dimension) \n",
    "\n",
    "##### Debiasing step #####\n",
    "\n",
    "Lasso Regression estimator is prone to biasing\n",
    "Large coefficients are shrunk towards zero\n",
    "This is why lasso stands for “least absolute selection and shrinkage operator”\n",
    "A simple solution to the biased estimate problem, known as debiasing, is to use a two-stage\n",
    "estimation process: we first estimate the support of the weight vector (i.e., identify which elements\n",
    "are non-zero) using lasso; we then re-estimate the chosen coefficients using least squares.\n",
    "\n",
    "Sec. 11.5.3. in the book \"Probabilistic Machine Learning: An Introduction by Kevin P. Murphy\"\n",
    "for more information\n",
    "\n",
    "\"\"\"\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "import scipy.linalg\n",
    "\n",
    "try:\n",
    "    from group_lasso import GroupLasso\n",
    "except ModuleNotFoundError:\n",
    "    %pip install -qq group_lasso\n",
    "    from group_lasso import GroupLasso\n",
    "try:\n",
    "    from sklearn import linear_model\n",
    "except ModuleNotFoundError:\n",
    "    %pip install -qq scikit-learn\n",
    "    from sklearn import linear_model\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "try:\n",
    "    import spams\n",
    "except ModuleNotFoundError:\n",
    "    %pip install -qq spams\n",
    "    import spams\n",
    "from scipy.linalg import lstsq\n",
    "import warnings\n",
    "\n",
    "warnings.simplefilter(action=\"ignore\", category=FutureWarning)\n",
    "\n",
    "np.random.seed(0)\n",
    "\n",
    "\n",
    "def generate_data(signal_type):\n",
    "    \"\"\"\n",
    "    Generate X, Y and ε for the linear model y = XW + ε\n",
    "    \"\"\"\n",
    "    dim = 2**12\n",
    "    rows = 2**10\n",
    "    n_active = 8\n",
    "    n_groups = 64\n",
    "    size_groups = dim / n_groups\n",
    "    # Selecting 8 groups randomly\n",
    "    rand_perm = np.random.permutation(n_groups)\n",
    "    actives = rand_perm[:n_active]\n",
    "    groups = np.ceil(np.transpose(np.arange(dim) + 1) / size_groups)  # Group number for each column\n",
    "    # Generating W actual\n",
    "    W = np.zeros((dim, 1))\n",
    "    if signal_type == \"piecewise_gaussian\":\n",
    "        for i in range(n_active):\n",
    "            W[groups == actives[i]] = np.random.randn(len(W[groups == actives[i]]), 1)\n",
    "    elif signal_type == \"piecewise_constant\":\n",
    "        for i in range(n_active):\n",
    "            W[groups == actives[i]] = np.ones((len(W[groups == actives[i]]), 1))\n",
    "    X = np.random.randn(rows, dim)\n",
    "    sigma = 0.02\n",
    "    Y = np.dot(X, W) + sigma * np.random.randn(rows, 1)  # y = XW + ε\n",
    "    return X, Y, W, groups\n",
    "\n",
    "\n",
    "def groupLasso_demo(signal_type, fig_start):\n",
    "    X, Y, W_actual, groups = generate_data(signal_type)\n",
    "    # Plotting the actual W\n",
    "    plt.figure(0 + fig_start)\n",
    "    plt.plot(W_actual)\n",
    "    plt.title(\"Original (D = 4096, number groups = 64, active groups = 8)\")\n",
    "    plt.savefig(\"W_actual_{}.png\".format(signal_type), dpi=300)\n",
    "    ##### Applying Lasso Regression #####\n",
    "    # L1 norm is the sum of absolute values of coefficients\n",
    "    lasso_reg = linear_model.Lasso(alpha=0.5)\n",
    "    lasso_reg.fit(X, Y)\n",
    "    W_lasso_reg = lasso_reg.coef_\n",
    "    ##### Debiasing step #####\n",
    "    ba = np.argwhere(W_lasso_reg != 0)  # Finding where the coefficients are not zero\n",
    "    X_debiased = X[:, ba]\n",
    "    W_lasso_reg_debiased = np.linalg.lstsq(\n",
    "        X_debiased[:, :, 0], Y\n",
    "    )  # Re-estimate the chosen coefficients using least squares\n",
    "    W_lasso_reg_debiased_2 = np.zeros((4096))\n",
    "    W_lasso_reg_debiased_2[ba] = W_lasso_reg_debiased[0]\n",
    "    lasso_reg_mse = mean_squared_error(W_actual, W_lasso_reg_debiased_2)\n",
    "    plt.figure(1 + fig_start)\n",
    "    plt.plot(W_lasso_reg_debiased_2)\n",
    "    plt.title(\"Standard L1 (debiased 1, regularization param(L1 = 0.5), MSE = {:.4f})\".format(lasso_reg_mse))\n",
    "    plt.savefig(\"W_lasso_reg_{}.png\".format(signal_type), dpi=300)\n",
    "    ##### Applying Group Lasso L2 regression #####\n",
    "    # L2 norm is the square root of sum of squares of coefficients\n",
    "    # PNLL(W) = NLL(W) + regularization_parameter * Σ(groups)L2-norm\n",
    "    group_lassoL2_reg = GroupLasso(\n",
    "        groups=groups,\n",
    "        group_reg=3,\n",
    "        l1_reg=1,\n",
    "        frobenius_lipschitz=True,\n",
    "        scale_reg=\"inverse_group_size\",\n",
    "        subsampling_scheme=1,\n",
    "        supress_warning=True,\n",
    "        n_iter=1000,\n",
    "        tol=1e-3,\n",
    "    )\n",
    "    group_lassoL2_reg.fit(X, Y)\n",
    "    W_groupLassoL2_reg = group_lassoL2_reg.coef_\n",
    "    ##### Debiasing step #####\n",
    "    ba = np.argwhere(W_groupLassoL2_reg != 0)  # Finding where the coefficients are not zero\n",
    "    X_debiased = X[:, ba]\n",
    "    W_group_lassoL2_reg_debiased = np.linalg.lstsq(\n",
    "        X_debiased[:, :, 0], Y\n",
    "    )  # Re-estimate the chosen coefficients using least squares\n",
    "    W_group_lassoL2_reg_debiased_2 = np.zeros((4096))\n",
    "    W_group_lassoL2_reg_debiased_2[ba] = W_group_lassoL2_reg_debiased[0]\n",
    "    groupLassoL2_mse = mean_squared_error(W_actual, W_group_lassoL2_reg_debiased_2)\n",
    "    plt.figure(2 + fig_start)\n",
    "    plt.plot(W_group_lassoL2_reg_debiased_2)\n",
    "    plt.title(\"Block-L2 (debiased 1, regularization param(L2 = 3, L1=1), MSE = {:.4f})\".format(groupLassoL2_mse))\n",
    "    plt.savefig(\"W_groupLassoL2_reg_{}.png\".format(signal_type), dpi=300)\n",
    "    ##### Applying Group Lasso Linf regression #####\n",
    "    # To use spams library, it is necessary to convert data to fortran normalized arrays\n",
    "    # visit http://spams-devel.gforge.inria.fr/ for the documentation of spams library\n",
    "    # Linf is the supremum of all the coeifficients\n",
    "    # PNLL(W) = NLL(W) + regularization_parameter * Σ(groups)Linf-norm\n",
    "    X_normalized = np.asfortranarray(X - np.tile(np.mean(X, 0), (X.shape[0], 1)), dtype=float)\n",
    "    X_normalized = spams.normalize(X_normalized)\n",
    "    Y_normalized = np.asfortranarray(Y - np.tile(np.mean(Y, 0), (Y.shape[0], 1)), dtype=float)\n",
    "    Y_normalized = spams.normalize(Y_normalized)\n",
    "    groups_modified = np.concatenate([[i] for i in groups]).reshape(-1, 1)\n",
    "    W_initial = np.zeros((X_normalized.shape[1], Y_normalized.shape[1]), dtype=float, order=\"F\")\n",
    "    param = {\n",
    "        \"numThreads\": -1,\n",
    "        \"verbose\": True,\n",
    "        \"lambda2\": 3,\n",
    "        \"lambda1\": 1,\n",
    "        \"max_it\": 500,\n",
    "        \"L0\": 0.1,\n",
    "        \"tol\": 1e-2,\n",
    "        \"intercept\": False,\n",
    "        \"pos\": False,\n",
    "        \"loss\": \"square\",\n",
    "    }\n",
    "    param[\"regul\"] = \"group-lasso-linf\"\n",
    "    param2 = param.copy()\n",
    "    param[\"size_group\"] = 64\n",
    "    param2[\"groups\"] = groups_modified\n",
    "    (W_groupLassoLinf_reg, optim_info) = spams.fistaFlat(Y_normalized, X_normalized, W_initial, True, **param)\n",
    "    ##### Debiasing step #####\n",
    "    ba = np.argwhere(W_groupLassoLinf_reg != 0)  # Finding where the coefficients are not zero\n",
    "    X_debiased = X[:, ba[:, 0]]\n",
    "    W_groupLassoLinf_reg_debiased = np.linalg.lstsq(\n",
    "        X_debiased, Y\n",
    "    )  # Re-estimate the chosen coefficients using least squares\n",
    "    W_group_lassoLinf_reg_debiased_2 = np.zeros((4096))\n",
    "    W_group_lassoLinf_reg_debiased_2[ba] = W_groupLassoLinf_reg_debiased[0]\n",
    "    groupLassoLinf_mse = mean_squared_error(W_actual, W_group_lassoLinf_reg_debiased_2)\n",
    "    plt.figure(3 + fig_start)\n",
    "    axes = plt.gca()\n",
    "    plt.plot(W_group_lassoLinf_reg_debiased_2)\n",
    "    plt.title(\"Block-Linf (debiased 1, regularization param(L2 = 3, L1=1), MSE = {:.4f})\".format(groupLassoLinf_mse))\n",
    "    plt.savefig(\"W_groupLassoLinf_reg_{}.png\".format(signal_type), dpi=300)\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def main():\n",
    "    groupLasso_demo(\"piecewise_gaussian\", fig_start=0)\n",
    "    groupLasso_demo(\"piecewise_constant\", fig_start=4)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
