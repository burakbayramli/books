{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ceeb4252",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Compares L1, L2, allSubsets, and OLS linear regression on the prostate data set\n",
    "Author : Aleyna Kara (@karalleyna)\n",
    "Based on https://github.com/probml/pmtk3/blob/master/demos/prostateComparison.m\n",
    "Sourced from https://github.com/empathy87/The-Elements-of-Statistical-Learning-Python-Notebooks/blob/master/examples/Prostate%20Cancer.ipynb\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "try:\n",
    "    import probml_utils as pml\n",
    "except ModuleNotFoundError:\n",
    "    %pip install -qq git+https://github.com/probml/probml-utils.git\n",
    "    import probml_utils as pml\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "try:\n",
    "    import pandas as pd\n",
    "except ModuleNotFoundError:\n",
    "    %pip install -qq pandas\n",
    "    import pandas as pd\n",
    "from itertools import combinations\n",
    "\n",
    "try:\n",
    "    from sklearn.linear_model import Ridge\n",
    "except ModuleNotFoundError:\n",
    "    %pip install -qq scikit-learn\n",
    "    from sklearn.linear_model import Ridge\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV, KFold\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "\n",
    "def get_features_and_label(dataset, is_training):\n",
    "    \"\"\"\n",
    "    Gets matrices representing features and target from the original data set\n",
    "    Parameters\n",
    "    ----------\n",
    "    dataset: DataFrame\n",
    "      Original dataset\n",
    "    is_training : str\n",
    "      Label to show whether a data point is in training data or not.\n",
    "        * \"T\" -> Training data\n",
    "        * \"F\" -> Test data\n",
    "    Return\n",
    "    ------\n",
    "      X : ndarray\n",
    "        Feature matrix\n",
    "      y : ndarray\n",
    "        Lpsa values of each data point.\n",
    "    \"\"\"\n",
    "    X = dataset.loc[dataset.train == is_training].drop(\"train\", axis=1)\n",
    "    y = X.pop(\"lpsa\").values\n",
    "    X = X.to_numpy()\n",
    "    return X, y\n",
    "\n",
    "\n",
    "class OneStandardErrorRuleModel:\n",
    "    \"\"\"\n",
    "    Select the least complex model among one standard error of the best.\n",
    "    Attributes\n",
    "    ----------\n",
    "        estimator :\n",
    "            A regression model to be parametrized.\n",
    "        params : dict\n",
    "            * Keys : The parameter of the model to be chosen by cross-validation.\n",
    "            * Values : The values for the parameter to be tried.\n",
    "        cv : Int\n",
    "            The number of folds for cross-validation.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, estimator, params, cv=10):\n",
    "        self.estimator = estimator\n",
    "        self.cv = cv\n",
    "        self.params = params\n",
    "        self.random_state = 69438  # Seed of the pseudo random number generator\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        grid_search = GridSearchCV(\n",
    "            self.estimator,\n",
    "            self.params,\n",
    "            cv=KFold(self.cv, shuffle=True, random_state=self.random_state),\n",
    "            scoring=\"neg_mean_squared_error\",\n",
    "            return_train_score=True,\n",
    "        )\n",
    "        grid_search = grid_search.fit(X, y)\n",
    "        # Gets best estimator according to one standard error rule model\n",
    "        model_idx = self._get_best_estimator(grid_search.cv_results_)\n",
    "        self.refit(X, y, model_idx)\n",
    "        return self\n",
    "\n",
    "    def _get_best_estimator(self, cv_results):\n",
    "        cv_mean_errors = -cv_results[\"mean_test_score\"]  # Mean errors\n",
    "        cv_errors = -np.vstack([cv_results[f\"split{i}_test_score\"] for i in range(self.cv)]).T\n",
    "        cv_mean_errors_std = np.std(cv_errors, ddof=1, axis=1) / np.sqrt(self.cv)  # Standard errors\n",
    "\n",
    "        # Finds smallest mean and standard error\n",
    "        cv_min_error, cv_min_error_std = self._get_cv_min_error(cv_mean_errors, cv_mean_errors_std)\n",
    "\n",
    "        error_threshold = cv_min_error + cv_min_error_std\n",
    "        # Finds the least complex model within one standard error of the best\n",
    "        model_idx = np.argmax(cv_mean_errors < error_threshold)\n",
    "        cv_mean_error_ = cv_mean_errors[model_idx]\n",
    "        cv_mean_errors_std_ = cv_mean_errors_std[model_idx]\n",
    "        return model_idx\n",
    "\n",
    "    def _get_cv_min_error(self, cv_mean_errors, cv_mean_errors_std):\n",
    "        # Gets the index of the model with minimum mean error\n",
    "        best_model_idx = np.argmin(cv_mean_errors)\n",
    "        cv_min_error = cv_mean_errors[best_model_idx]\n",
    "        cv_min_error_std = cv_mean_errors_std[best_model_idx]\n",
    "        return cv_min_error, cv_min_error_std\n",
    "\n",
    "    def refit(self, X, y, model_idx):\n",
    "        if self.params:\n",
    "            param_name = list(self.params.keys())[0]\n",
    "            self.estimator.set_params(**{param_name: self.params[param_name][model_idx]})\n",
    "        # Fits the selected model\n",
    "        self.estimator.fit(X, y)\n",
    "\n",
    "    def get_test_scores(self, y_test, y_pred):\n",
    "        y_test, y_pred = y_test.reshape((1, -1)), y_pred.reshape((1, -1))\n",
    "        errors = (y_test - y_pred) ** 2  # Least sqaure errors\n",
    "        error = np.mean(errors)  # Mean least sqaure errors\n",
    "        error_std = np.std(errors, ddof=1) / np.sqrt(y_test.size)  # Standard errors\n",
    "        return error, error_std\n",
    "\n",
    "\n",
    "class BestSubsetRegression(LinearRegression):\n",
    "    \"\"\"\n",
    "    Linear regression based on the best features subset of fixed size.\n",
    "    Attributes\n",
    "    ----------\n",
    "        subset_size : Int\n",
    "            The number of features in the subset.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, subset_size=1):\n",
    "        LinearRegression.__init__(self)\n",
    "        self.subset_size = subset_size\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        best_combination, best_mse = None, np.inf\n",
    "        best_intercept_, best_coef_ = None, None\n",
    "        # Tries all combinations of subset_size\n",
    "        for combination in combinations(range(X.shape[1]), self.subset_size):\n",
    "            X_subset = X[:, combination]\n",
    "            LinearRegression.fit(self, X_subset, y)\n",
    "            mse = mean_squared_error(y, self.predict(X_subset))\n",
    "            # Updates the best combination if it gives better result than the current best\n",
    "            if best_mse > mse:\n",
    "                best_combination, best_mse = combination, mse\n",
    "                best_intercept_, best_coef_ = self.intercept_, self.coef_\n",
    "        LinearRegression.fit(self, X, y)\n",
    "        # Sets intercept and parameters\n",
    "        self.intercept_ = best_intercept_\n",
    "        self.coef_[:] = 0\n",
    "        self.coef_[list(best_combination)] = best_coef_\n",
    "        return self\n",
    "\n",
    "\n",
    "path = \"https://raw.githubusercontent.com/probml/probml-data/main/data/prostate/prostate.csv\"\n",
    "X = pd.read_csv(path, sep=\"\\t\").iloc[:, 1:]\n",
    "X_train, y_train = get_features_and_label(X, \"T\")\n",
    "X_test, y_test = get_features_and_label(X, \"F\")\n",
    "\n",
    "# Standardizes training and test data\n",
    "scaler = StandardScaler().fit(X.loc[:, \"lcavol\":\"pgg45\"])\n",
    "X_train = scaler.transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "n_models, cv, n_alphas = 4, 10, 30\n",
    "_, n_features = X_train.shape\n",
    "alpha_lasso, alpha_ridge = [0.680, 0.380, 0.209, 0.100, 0.044, 0.027, 0.012, 0.001], [\n",
    "    436,\n",
    "    165,\n",
    "    82,\n",
    "    44,\n",
    "    27,\n",
    "    12,\n",
    "    4,\n",
    "    1e-05,\n",
    "]\n",
    "\n",
    "linear_regression = OneStandardErrorRuleModel(LinearRegression(), {}).fit(X_train, y_train)\n",
    "bs_regression = OneStandardErrorRuleModel(BestSubsetRegression(), {\"subset_size\": list(range(1, 9))}).fit(\n",
    "    X_train, y_train\n",
    ")\n",
    "ridge_regression = OneStandardErrorRuleModel(Ridge(), {\"alpha\": alpha_ridge}).fit(X_train, y_train)\n",
    "lasso_regression = OneStandardErrorRuleModel(Lasso(), {\"alpha\": alpha_lasso}).fit(X_train, y_train)\n",
    "\n",
    "regressions = [linear_regression, bs_regression, ridge_regression, lasso_regression]\n",
    "\n",
    "residuals = np.zeros((X_test.shape[0], n_models))  # (num of test data) x num of models\n",
    "table = np.zeros(\n",
    "    (n_features + 3, n_models)\n",
    ")  # (num of features + 1(mean error) + 1(std error) + 1(bias coef)) x num of models\n",
    "\n",
    "for i in range(n_models):\n",
    "    table[:, i] = regressions[i].estimator.intercept_  # bias\n",
    "    table[1 : n_features + 1, i] = regressions[i].estimator.coef_\n",
    "    y_pred = regressions[i].estimator.predict(X_test)\n",
    "    table[n_features + 1 :, i] = np.r_[regressions[i].get_test_scores(y_test, y_pred)]\n",
    "    residuals[:, i] = np.abs(y_test - y_pred)\n",
    "\n",
    "xlabels = [\"Term\", \"LS\", \"Best Subset\", \"Ridge\", \"Lasso\"]  # column headers\n",
    "row_labels = np.r_[\n",
    "    [[\"Intercept\"]], X.columns[:-2].to_numpy().reshape(-1, 1), [[\"Test Error\"], [\"Std Error\"]]\n",
    "]  # row headers\n",
    "row_values = np.c_[row_labels, np.round(table, 3)]\n",
    "\n",
    "fig = plt.figure(figsize=(10, 4))\n",
    "ax = plt.gca()\n",
    "\n",
    "fig.patch.set_visible(False)\n",
    "ax.axis(\"off\")\n",
    "ax.axis(\"tight\")\n",
    "\n",
    "table = ax.table(cellText=row_values, colLabels=xlabels, loc=\"center\", cellLoc=\"center\")\n",
    "table.set_fontsize(20)\n",
    "table.scale(1.5, 1.5)\n",
    "fig.tight_layout()\n",
    "pml.savefig(\"prostate-subsets-coef.pdf\")\n",
    "plt.show()\n",
    "\n",
    "plt.figure()\n",
    "plt.boxplot(residuals)\n",
    "plt.xticks(np.arange(n_models) + 1, xlabels[1:])\n",
    "pml.savefig(\"prostate-subsets-CV.pdf\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
