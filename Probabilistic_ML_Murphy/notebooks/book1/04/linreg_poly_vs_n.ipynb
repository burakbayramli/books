{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b77d9c99",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Linear regression as a function of training set size\n",
    "# Based on https://github.com/probml/pmtk3/blob/master/demos/linregPolyVsN.m\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "try:\n",
    "    import probml_utils as pml\n",
    "except ModuleNotFoundError:\n",
    "    %pip install -qq git+https://github.com/probml/probml-utils.git\n",
    "    import probml_utils as pml\n",
    "\n",
    "\n",
    "try:\n",
    "    from sklearn.linear_model import Ridge\n",
    "except ModuleNotFoundError:\n",
    "    %pip install -qq scikit-learn\n",
    "    from sklearn.linear_model import Ridge\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "TrueDeg = 2  # The true degree of the model\n",
    "degrees = [1, 2, 10, 20]  # The degrees of our design matrices\n",
    "\n",
    "\n",
    "def ExpandtoDeg(x, deg):\n",
    "    return np.array([x**i for i in range(deg + 1)]).transpose().reshape(-1, deg + 1)\n",
    "\n",
    "\n",
    "def make_1dregression_data(n=21):\n",
    "    np.random.seed(0)\n",
    "    xtrain = np.linspace(0.0, 20, n)\n",
    "    xtest = np.arange(0.0, 20, 0.1)\n",
    "    sigma2 = 4\n",
    "    w = np.array([-1.5, 1 / 9.0])\n",
    "    fun = lambda x: w[0] * x + w[1] * np.square(x)\n",
    "    ytrain = fun(xtrain) + np.random.normal(0, 1, xtrain.shape) * np.sqrt(sigma2)\n",
    "    ytest = fun(xtest) + np.random.normal(0, 1, xtest.shape) * np.sqrt(sigma2)\n",
    "    return xtrain, ytrain, xtest, ytest\n",
    "\n",
    "\n",
    "for ModDeg in degrees:\n",
    "    ns = [int(n) for n in np.round(np.linspace(10, 210, 20))]\n",
    "    err = []\n",
    "    errtrain = []\n",
    "    for n in ns:\n",
    "        xtrain, ytrain, xtest, ytest = make_1dregression_data(n=n)\n",
    "\n",
    "        # Rescaling data\n",
    "        scaler = MinMaxScaler(feature_range=(-1, 1))\n",
    "        xtrain = scaler.fit_transform(xtrain.reshape(-1, 1))\n",
    "        xtest = scaler.transform(xtest.reshape(-1, 1))\n",
    "\n",
    "        # Fitting ridge regression. Small differences in alpha near zero make a visual difference in the plot when n is close to 0.\n",
    "        regr = Ridge(\n",
    "            alpha=0, fit_intercept=False\n",
    "        )  # Using ridge instead of ordinary least squares for numerical stability\n",
    "        XDesignTrain = ExpandtoDeg(xtrain, ModDeg)\n",
    "        XDesignTest = ExpandtoDeg(xtest, ModDeg)\n",
    "        regr.fit(XDesignTrain, ytrain)\n",
    "        ypred = regr.predict(XDesignTest)\n",
    "        err.append(np.mean((ytest - ypred) ** 2))\n",
    "        errtrain.append(np.mean((ytrain - regr.predict(XDesignTrain)) ** 2))\n",
    "\n",
    "    # Plotting\n",
    "    fig, ax = plt.subplots()\n",
    "    ax.plot(ns, err, color=\"r\", marker=\"s\", label=\"test\")\n",
    "    ax.plot(ns, errtrain, marker=\"x\", label=\"train\")\n",
    "    ax.legend(loc=\"upper right\", shadow=True)\n",
    "    ax.set_xlim([0, 200])\n",
    "    ax.set_ylim([0, 22])\n",
    "    plt.axhline(y=4, color=\"k\", linewidth=2)\n",
    "    plt.xlabel(\"size of training set\")\n",
    "    plt.ylabel(\"mse\")\n",
    "    plt.title(\"truth = degree {}, model = degree {}\".format(TrueDeg, ModDeg))\n",
    "    pml.savefig(\"polyfitN{}.pdf\".format(ModDeg))\n",
    "    plt.show()\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
