{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e36f7600",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "try:\n",
    "    import probml_utils as pml\n",
    "except ModuleNotFoundError:\n",
    "    %pip install -qq git+https://github.com/probml/probml-utils.git\n",
    "    import probml_utils as pml\n",
    "\n",
    "import matplotlib.pyplot as plt \n",
    "try:\n",
    "    from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "except ModuleNotFoundError:\n",
    "    %pip install -qq scikit-learn\n",
    "    from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.decomposition import PCA\n",
    "from scipy import linalg\n",
    "from numpy import array\n",
    "from numpy import mean\n",
    "from numpy import cov\n",
    "from numpy.linalg import eig\n",
    "import numpy as np\n",
    "\n",
    "# Dataset according to matlab code:\n",
    "\n",
    "n = 100 \n",
    "np.random.seed(0)\n",
    "a = np.random.multivariate_normal((1, 3), [[4.0, 0.01], [0.01, 0.1]], n)\n",
    "b = np.random.multivariate_normal((3, 1), [[4.0, 0.01], [0.01, 0.1]], n)\n",
    "\n",
    "X = np.vstack((a, b))\n",
    "\n",
    "Y = np.hstack((np.zeros(n), np.ones(n)))\n",
    "\n",
    "mu_a, mu_b = a.mean(axis=0).reshape(-1,1), b.mean(axis=0).reshape(-1,1)\n",
    "\n",
    "xmax = np.max(X[:, 0])\n",
    "xmin = np.min(X[:, 0])\n",
    "ymax = np.max(X[:, 1]) \n",
    "ymin = np.min(X[:, 1])\n",
    "\n",
    "nMale = 100\n",
    "nFemale = 200\n",
    "\n",
    "\"\"\"##FischerLDA\n",
    "It is done in 2 ways:\n",
    "\n",
    "a) Using sklearn.discriminant \n",
    "\n",
    "b) According to the book (manual calculation))\n",
    "\n",
    "# a)\n",
    "\"\"\"\n",
    "\n",
    "def flda_sklearn(X, Y):\n",
    "    lda = LinearDiscriminantAnalysis()\n",
    "    X_fit = lda.fit(X, Y)\n",
    "    X_tran = lda.transform(X)\n",
    "    w_sk = X_fit.coef_\n",
    "    return X_tran, X_fit, w_sk\n",
    "\n",
    "def Xproj_fish_sk_cal(w_sk):\n",
    "    slope = w_sk[0, 1]/w_sk[0, 0]\n",
    "    Xproj_fish_sk = X.dot(w_sk.T) \n",
    "    return Xproj_fish_sk\n",
    "\n",
    "\"\"\"# b)\"\"\"\n",
    "\n",
    "def calculate_covariance_matrix(X, Y=None):\n",
    "    if Y is None:\n",
    "        Y = X\n",
    "    n_samples = np.shape(X)[0]\n",
    "    covariance_matrix = (1 / (n_samples-1)) * (X - X.mean(axis=0)).T.dot(Y - Y.mean(axis=0))\n",
    "\n",
    "    return np.array(covariance_matrix, dtype=float)\n",
    "\n",
    "def flda_manual(a, b):\n",
    "    # Covariance matrices of the two datasets\n",
    "    cov1 = calculate_covariance_matrix(a)\n",
    "    cov2 = calculate_covariance_matrix(b)\n",
    "    cov_tot = (cov1 + cov2)/2\n",
    "\n",
    "    # Mean of the two datasets\n",
    "    mean1 = a.mean(0)\n",
    "    mean2 = b.mean(0)\n",
    "    mean_diff = np.atleast_1d(mean1 - mean2)\n",
    "\n",
    "    # The vector w, which when X is projected onto it best separates the data by class. \n",
    "    # w = (mean1 - mean2) / (cov1 + cov2) [Formula in topic 9.2.6.1 in the book]\n",
    "\n",
    "    w = -np.linalg.pinv(cov_tot).dot(mean_diff)\n",
    "    \n",
    "    return w\n",
    "\n",
    "def Xproj_fish_man_cal(X, w):\n",
    "    Xproj_fish = X.dot(w) \n",
    "    Xproj_fish_male = Xproj_fish[:nMale]\n",
    "    Xproj_fish_female = Xproj_fish[nMale:nFemale]\n",
    "    return Xproj_fish, Xproj_fish_male, Xproj_fish_female\n",
    "\n",
    "\"\"\"##PCA\n",
    "\n",
    "It is done in 2 ways:\n",
    "\n",
    "a) Using sklearn.decomposition\n",
    "\n",
    "b) Manual principal component analysis\n",
    "\n",
    "# a)\n",
    "\"\"\"\n",
    "\n",
    "def pca_sklearn(X, Y):\n",
    "    pca = PCA(n_components=1)\n",
    "    X_fit = pca.fit(X)\n",
    "    X_tran = pca.transform(X)\n",
    "    return X_fit, X_tran\n",
    "\n",
    "def Xproj_pca_sk_cal(X_fit):\n",
    "  weights = X_fit.components_\n",
    "  Xproj_pca_sk = X.dot(weights.T)\n",
    "  return Xproj_pca_sk\n",
    "\n",
    "\"\"\"# b)\"\"\"\n",
    "\n",
    "def pca_manual(X, Y):\n",
    "    # calculate the mean of each column\n",
    "    M = mean(X.T, axis=1)\n",
    "    # center columns by subtracting column means\n",
    "    C = M - X\n",
    "    # calculate covariance matrix of centered matrix\n",
    "    V = cov(C.T)\n",
    "    # eigendecomposition of covariance matrix\n",
    "    values, vectors = eig(V)\n",
    "    # project data\n",
    "    P = vectors.T.dot(C.T)\n",
    "\n",
    "    return vectors\n",
    "\n",
    "def Xproj_pca_man_cal(X, vectors):\n",
    "  vector = vectors[:, 0]\n",
    "  Xproj_pca = X.dot(vector)\n",
    "  Xproj_pca_male = Xproj_pca[:nMale]\n",
    "  Xproj_pca_female = Xproj_pca[nMale:nFemale]\n",
    "  return Xproj_pca, Xproj_pca_male, Xproj_pca_female\n",
    "\n",
    "\"\"\"Plot functions:\"\"\"\n",
    "\n",
    "def plot_data(a, b):\n",
    "    plt.figure()\n",
    "    plt.plot(a[:,0], a[:,1], 'b.', b[:,0], b[:,1], 'r+')\n",
    "    #plt.plot(mu_a, mu_b, 'black')\n",
    "    plt.legend(['Male', 'Female', 'Means'])\n",
    "    pml.savefig(\"fisher_lda_data.pdf\")\n",
    "    plt.show()\n",
    "\n",
    "def plot_all_vectors(a, b, vectors, w):\n",
    "    mu_a, mu_b = a.mean(axis=0).reshape(-1,1), b.mean(axis=0).reshape(-1,1)\n",
    "    mid_point = (mu_a + mu_b)/2\n",
    "\n",
    "    vector = vectors[:, 0]\n",
    "    slope_pca = vector[1]/vector[0]\n",
    "    c_pca = mid_point[1] - slope_pca*mid_point[0]\n",
    "\n",
    "    slope = w[1]/w[0]\n",
    "    c = mid_point[1] - slope*mid_point[0]\n",
    "\n",
    "    x = np.linspace(xmin+1, xmax+1, 100)\n",
    "    z = np.linspace(xmin+1, xmax+1, 100)\n",
    "\n",
    "    plt.figure()\n",
    "    plt.xlim(xmin, xmax)\n",
    "    plt.ylim(ymin, ymax)\n",
    "    plt.plot(a[:,0], a[:,1], 'b.', b[:,0], b[:,1], 'r+')\n",
    "    plt.plot(x, slope*x + c)\n",
    "    plt.plot(z, slope_pca*z + c_pca)\n",
    "    #plt.plot(mu_a, mu_b, 'black')\n",
    "    plt.legend(['Male', 'Female', 'FisherLDA vector', 'PCA vector'])\n",
    "    #plt.legend(['Male', 'Female', 'FisherLDA vector', 'PCA vector', 'Means'])\n",
    "    pml.savefig(\"fisher_lda_lines.pdf\")\n",
    "    plt.show()\n",
    "\n",
    "def plot_flda_vectors(a, b, vectors, w):\n",
    "    mu_a, mu_b = a.mean(axis=0).reshape(-1,1), b.mean(axis=0).reshape(-1,1)\n",
    "    mid_point = (mu_a + mu_b)/2\n",
    "\n",
    "    vector = vectors[:, 0]\n",
    "    slope_pca = vector[1]/vector[0]\n",
    "    c_pca = mid_point[1] - slope_pca*mid_point[0]\n",
    "\n",
    "    slope = w[1]/w[0]\n",
    "    c = mid_point[1] - slope*mid_point[0]\n",
    "\n",
    "    x = np.linspace(xmin+1, xmax+1, 100)\n",
    "    z = np.linspace(xmin+1, xmax+1, 100)\n",
    "\n",
    "    plt.figure()\n",
    "    plt.xlim(xmin, xmax)\n",
    "    plt.ylim(ymin, ymax)\n",
    "    plt.plot(a[:,0], a[:,1], 'b.', b[:,0], b[:,1], 'r+')\n",
    "    plt.plot(x, slope*x + c)\n",
    "    #plt.plot(z, slope_pca*z + c_pca)\n",
    "    #plt.plot(mu_a, mu_b, 'black')\n",
    "    plt.legend(['Male', 'Female', 'FisherLDA vector'])\n",
    "    #plt.legend(['Male', 'Female', 'FisherLDA vector', 'PCA vector', 'Means'])\n",
    "    pml.savefig(\"fisher_lda_lines_flda.pdf\")\n",
    "    plt.show()\n",
    "\n",
    "def plot_pca_vectors(a, b, vectors, w):\n",
    "    mu_a, mu_b = a.mean(axis=0).reshape(-1,1), b.mean(axis=0).reshape(-1,1)\n",
    "    mid_point = (mu_a + mu_b)/2\n",
    "\n",
    "    vector = vectors[:, 0]\n",
    "    slope_pca = vector[1]/vector[0]\n",
    "    c_pca = mid_point[1] - slope_pca*mid_point[0]\n",
    "\n",
    "    slope = w[1]/w[0]\n",
    "    c = mid_point[1] - slope*mid_point[0]\n",
    "\n",
    "    x = np.linspace(xmin+1, xmax+1, 100)\n",
    "    z = np.linspace(xmin+1, xmax+1, 100)\n",
    "\n",
    "    plt.figure()\n",
    "    plt.xlim(xmin, xmax)\n",
    "    plt.ylim(ymin, ymax)\n",
    "    plt.plot(a[:,0], a[:,1], 'b.', b[:,0], b[:,1], 'r+')\n",
    "    #plt.plot(x, slope*x + c)\n",
    "    plt.plot(z, slope_pca*z + c_pca)\n",
    "    #plt.plot(mu_a, mu_b, 'black')\n",
    "    plt.legend(['Male', 'Female', 'PCA vector'])\n",
    "    #plt.legend(['Male', 'Female', 'FisherLDA vector', 'PCA vector', 'Means'])\n",
    "    pml.savefig(\"fisher_lda_lines_pca.pdf\")\n",
    "    plt.show()\n",
    "\n",
    "def plot_proj(name, argument):\n",
    "    plt.figure()\n",
    "    if name == 'pca':\n",
    "        Xproj_pca_male = argument[:nMale]\n",
    "        Xproj_pca_female = argument[nMale:nFemale]\n",
    "        plt.hist(Xproj_pca_male, color='red', ec='black')\n",
    "        plt.hist(Xproj_pca_female, color='blue', ec='black')\n",
    "        plt.title('Projection of points onto PCA vector')\n",
    "        pml.savefig(\"fisher_lda_pca.pdf\")\n",
    "        plt.show()\n",
    "    else :\n",
    "        Xproj_fish_male = argument[:nMale]\n",
    "        Xproj_fish_female = argument[nMale:nFemale]\n",
    "        plt.hist(Xproj_fish_male, color='red', ec='black')\n",
    "        plt.hist(Xproj_fish_female, color='blue', ec='black')\n",
    "        plt.title('Projection of points onto Fisher vector')\n",
    "        pml.savefig(\"fisher_lda_flda.pdf\")\n",
    "        plt.show()\n",
    "\n",
    "\"\"\"Data\"\"\"\n",
    "\n",
    "plot_data(a, b)\n",
    "\n",
    "\"\"\"FLDA\"\"\"\n",
    "\n",
    "X_tran, X_fit, w_sk = flda_sklearn(X, Y)\n",
    "w = flda_manual(a, b)\n",
    "\n",
    "Xproj_fish_sk = Xproj_fish_sk_cal(w_sk)\n",
    "Xproj_fish_man, Xproj_fish_male, Xproj_fish_female = Xproj_fish_man_cal(X, w)\n",
    "Xproj_fish_man = Xproj_fish_man.reshape(-1, 1)\n",
    "assert np.allclose(Xproj_fish_sk, Xproj_fish_man)\n",
    "\n",
    "\n",
    "plot_proj('flda', Xproj_fish_man) # Or plot_proj('flda', X_tran) as both the methods give similar results\n",
    "\n",
    "\"\"\"PCA\"\"\"\n",
    "\n",
    "X_fit, X_tran = pca_sklearn(X, Y)\n",
    "vectors = pca_manual(X, Y)\n",
    "\n",
    "Xproj_pca_sk = Xproj_pca_sk_cal(X_fit)\n",
    "Xproj_pca_man, Xproj_pca_male, Xproj_pca_female = Xproj_pca_man_cal(X, vectors)\n",
    "Xproj_pca_man = Xproj_pca_man.reshape(-1, 1)\n",
    "assert np.allclose(Xproj_pca_sk, Xproj_pca_man)\n",
    "\n",
    "plot_proj('pca', Xproj_pca_man) # Or plot_proj('pca', X_tran) as both the methods give similar results\n",
    "\n",
    "\"\"\"Plot of vectors\"\"\"\n",
    "\n",
    "plot_all_vectors(a, b, vectors, w)\n",
    "plot_pca_vectors(a, b, vectors, w)\n",
    "plot_flda_vectors(a, b, vectors, w)\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
