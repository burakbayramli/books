{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2ceb88a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Illustrate einstein summation\n",
    "# https://rockt.github.io/2018/04/30/einsum\n",
    "# https://docs.scipy.org/doc/numpy/reference/generated/numpy.einsum.html\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "np.random.seed(42)\n",
    "a = np.arange(3)\n",
    "b = np.arange(3)\n",
    "A = np.arange(6).reshape(2, 3)\n",
    "B = np.arange(15).reshape(3, 5)\n",
    "S = np.arange(9).reshape(3, 3)\n",
    "T = np.random.randn(2, 2, 2, 2)\n",
    "\n",
    "## Single argument\n",
    "\n",
    "# Matrix transpose\n",
    "assert np.allclose(A.T, np.einsum(\"ij->ji\", A))\n",
    "\n",
    "# Sum all elements\n",
    "assert np.allclose(np.sum(A), np.einsum(\"ij->\", A))\n",
    "\n",
    "# Sum across rows\n",
    "assert np.allclose(np.sum(A, axis=0), np.einsum(\"ij->j\", A))\n",
    "\n",
    "# Sum across columns\n",
    "assert np.allclose(np.sum(A, axis=1), np.einsum(\"ij->i\", A))\n",
    "\n",
    "# Sum specific axis of tensor\n",
    "assert np.allclose(np.sum(T, axis=1), np.einsum(\"ijkl->ikl\", T))\n",
    "assert np.allclose(np.sum(np.sum(T, axis=0), axis=0), np.einsum(\"ijkl->kl\", T))\n",
    "\n",
    "# repeated indices with one arg extracts diagonals\n",
    "assert np.allclose(np.diag(S), np.einsum(\"ii->i\", S))\n",
    "\n",
    "# Trace\n",
    "assert np.allclose(np.trace(S), np.einsum(\"ii->\", S))\n",
    "\n",
    "\n",
    "## Two arguments\n",
    "\n",
    "# Matrix vector multiplication\n",
    "assert np.allclose(np.dot(A, b), np.einsum(\"ik,k->i\", A, b))\n",
    "\n",
    "# Matrix matrix multiplication\n",
    "assert np.allclose(np.dot(A, B), np.einsum(\"ik,kj->ij\", A, B))\n",
    "assert np.allclose(np.matmul(A, B), np.einsum(\"ik,kj->ij\", A, B))\n",
    "\n",
    "# Inner product\n",
    "assert np.allclose(np.dot(a, b), np.einsum(\"i,i->\", a, b))\n",
    "assert np.allclose(np.inner(a, b), np.einsum(\"i,i->\", a, b))\n",
    "\n",
    "# Outer product\n",
    "assert np.allclose(np.outer(a, b), np.einsum(\"i,j->ij\", a, b))\n",
    "\n",
    "# Elementwise product\n",
    "assert np.allclose(a * a, np.einsum(\"i,i->i\", a, a))\n",
    "assert np.allclose(A * A, np.einsum(\"ij,ij->ij\", A, A))\n",
    "assert np.allclose(np.multiply(A, A), np.einsum(\"ij,ij->ij\", A, A))\n",
    "\n",
    "# Batch matrix multiplication\n",
    "I = 3\n",
    "J = 2\n",
    "K = 5\n",
    "L = 3\n",
    "AA = np.random.randn(I, J, K)\n",
    "BB = np.random.randn(I, K, L)\n",
    "# C[ijl] = sum_k A[ijk] B[ikl]\n",
    "CC = np.zeros((I, J, L))\n",
    "for i in range(I):\n",
    "    for j in range(J):\n",
    "        for l in range(L):\n",
    "            s = 0\n",
    "            for k in range(K):\n",
    "                s += AA[i, j, k] * BB[i, k, l]\n",
    "            CC[i, j, l] = s\n",
    "assert np.allclose(CC, np.einsum(\"ijk,ikl->ijl\", AA, BB))\n",
    "\n",
    "## >2 arguments\n",
    "\n",
    "# Batch sentence embedding and averaging\n",
    "N = 2\n",
    "C = 3\n",
    "D = 4\n",
    "K = 5\n",
    "T = 6\n",
    "S = np.random.randn(N, T, K)\n",
    "W = np.random.randn(K, D)\n",
    "V = np.random.randn(D, C)\n",
    "L = np.zeros((N, C))\n",
    "for n in range(N):\n",
    "    for c in range(C):\n",
    "        s = 0\n",
    "        for d in range(D):\n",
    "            for k in range(K):\n",
    "                for t in range(T):\n",
    "                    s += S[n, t, k] * W[k, d] * V[d, c]\n",
    "        L[n, c] = s\n",
    "assert np.allclose(L, np.einsum(\"ntk,kd,dc->nc\", S, W, V))\n",
    "\n",
    "\n",
    "path = np.einsum_path(\"ntk,kd,dc->nc\", S, W, V, optimize=\"optimal\")[0]\n",
    "assert np.allclose(L, np.einsum(\"ntk,kd,dc->nc\", S, W, V, optimize=path))\n",
    "\n",
    "\n",
    "import jax.numpy as jnp\n",
    "\n",
    "path = jnp.einsum_path(\"ntk,kd,dc->nc\", S, W, V, optimize=\"optimal\")[0]\n",
    "assert np.allclose(L, jnp.einsum(\"ntk,kd,dc->nc\", S, W, V, optimize=path))\n",
    "\n",
    "# Use full student network from KOller and Friedman\n",
    "str = \"c,dc,gdi,si,lg,jls,hgj->\"\n",
    "K = 5\n",
    "cptC = np.random.randn(K)\n",
    "cptD = np.random.randn(K, K)\n",
    "cptG = np.random.randn(K, K, K)\n",
    "cptS = np.random.randn(K, K)\n",
    "cptL = np.random.randn(K, K)\n",
    "cptJ = np.random.randn(K, K, K)\n",
    "cptH = np.random.randn(K, K, K)\n",
    "cpts = [cptC, cptD, cptG, cptS, cptL, cptJ, cptH]\n",
    "path_info = np.einsum_path(str, *cpts, optimize=\"optimal\")\n",
    "print(path_info[0])  # 'einsum_path', (0, 1), (0, 5), (0, 4), (0, 3), (0, 2), (0, 1)]\n",
    "print(path_info[1])\n",
    "\"\"\"\n",
    "  Complete contraction:  c,dc,gdi,si,lg,jls,hgj->\n",
    "         Naive scaling:  8\n",
    "     Optimized scaling:  4\n",
    "      Naive FLOP count:  2.734e+06\n",
    "  Optimized FLOP count:  2.176e+03\n",
    "   Theoretical speedup:  1256.606\n",
    "  Largest intermediate:  1.250e+02 elements\n",
    "--------------------------------------------------------------------------\n",
    "scaling                  current                                remaining\n",
    "--------------------------------------------------------------------------\n",
    "   2                     dc,c->d                    gdi,si,lg,jls,hgj,d->\n",
    "   3                   d,gdi->gi                       si,lg,jls,hgj,gi->\n",
    "   3                   gi,si->gs                          lg,jls,hgj,gs->\n",
    "   3                  gs,lg->gls                            jls,hgj,gls->\n",
    "   4                 gls,jls->gj                                 hgj,gj->\n",
    "   3                    gj,hgj->                                       ->\n",
    "\"\"\"\n",
    "\n",
    "path_info = np.einsum_path(str, *cpts, optimize=\"greedy\")\n",
    "print(path_info[1])\n",
    "\"\"\"\n",
    "  Complete contraction:  c,dc,gdi,si,lg,jls,hgj->\n",
    "         Naive scaling:  8\n",
    "     Optimized scaling:  5\n",
    "      Naive FLOP count:  2.734e+06\n",
    "  Optimized FLOP count:  7.101e+03\n",
    "   Theoretical speedup:  385.069\n",
    "  Largest intermediate:  1.250e+02 elements\n",
    "--------------------------------------------------------------------------\n",
    "scaling                  current                                remaining\n",
    "--------------------------------------------------------------------------\n",
    "   5                hgj,jls->gls                     c,dc,gdi,si,lg,gls->\n",
    "   3                  gls,lg->gs                         c,dc,gdi,si,gs->\n",
    "   2                     dc,c->d                            gdi,si,gs,d->\n",
    "   3                   d,gdi->gi                               si,gs,gi->\n",
    "   3                   gs,si->gi                                  gi,gi->\n",
    "   2                     gi,gi->                                       ->\n",
    "\"\"\""
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
