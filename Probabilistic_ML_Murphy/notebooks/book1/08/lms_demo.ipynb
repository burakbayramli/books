{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ce8e8ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SGD on linear regression aka least mean squares\n",
    "# Written by Duane Rich\n",
    "# Based on https://github.com/probml/pmtk3/blob/master/demos/LMSdemoSimple.m\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "try:\n",
    "    import probml_utils as pml\n",
    "except ModuleNotFoundError:\n",
    "    %pip install -qq git+https://github.com/probml/probml-utils.git\n",
    "    import probml_utils as pml\n",
    "\n",
    "\n",
    "# from mpl_toolkits.mplot3d import Axes3D\n",
    "from scipy.optimize import minimize\n",
    "\n",
    "plt.rcParams[\"figure.figsize\"] = (5, 5)  # width x height\n",
    "\n",
    "np.random.seed(0)\n",
    "# Generating synthetic data:\n",
    "N = 21\n",
    "wTrue = np.array([1.45, 0.92])\n",
    "X = np.random.uniform(-2, 2, N)\n",
    "X = np.column_stack((np.ones(N), X))\n",
    "\n",
    "y = wTrue[0] * X[:, 0] + wTrue[1] * X[:, 1] + np.random.normal(0, 0.1, N)\n",
    "\n",
    "\n",
    "# Plot SSE surface over parameter space.\n",
    "v = np.arange(-1, 3, 0.1)\n",
    "W0, W1 = np.meshgrid(v, v)\n",
    "SS = np.array([sum((w0 * X[:, 0] + w1 * X[:, 1] - y) ** 2) for w0, w1 in zip(np.ravel(W0), np.ravel(W1))])\n",
    "SS = SS.reshape(W0.shape)\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111, projection=\"3d\")\n",
    "surf = ax.plot_surface(W0, W1, SS)\n",
    "pml.savefig(\"lmsSSE.pdf\")\n",
    "plt.draw()\n",
    "\n",
    "# Mean SE with gradient and Hessian:\n",
    "def LinregLossScaled(w, X, y):\n",
    "    Xt = np.transpose(X)\n",
    "    XtX = Xt.dot(X)\n",
    "    N = X.shape[0]\n",
    "    err = X.dot(w) - y\n",
    "    f = np.mean(err * err)\n",
    "    g = (1 / N) * Xt.dot(err)\n",
    "    H = (1 / N) * XtX\n",
    "    return f, g, H\n",
    "\n",
    "\n",
    "# Starting point from to search for optimal parameters\n",
    "w0 = np.array([-0.5, 2])\n",
    "\n",
    "# Determine loss at optimal param values:\n",
    "def funObj(w):\n",
    "    out, _, _ = LinregLossScaled(w, X, y)\n",
    "    return out\n",
    "\n",
    "\n",
    "res = minimize(funObj, w0, method=\"L-BFGS-B\")\n",
    "wOpt = res.x\n",
    "fopt = funObj(wOpt)\n",
    "# fopt,_ ,_ = LinregLossScaled(wTrue, X, y)\n",
    "\n",
    "# Options for stochastic gradient descent\n",
    "opts = {}\n",
    "opts[\"batchsize\"] = 1\n",
    "opts[\"verbose\"] = True\n",
    "opts[\"storeParamTrace\"] = True\n",
    "opts[\"storeFvalTrace\"] = True\n",
    "opts[\"storeStepTrace\"] = True\n",
    "opts[\"maxUpdates\"] = 30\n",
    "opts[\"eta0\"] = 0.5\n",
    "opts[\"t0\"] = 3\n",
    "\n",
    "# Breaks the matrix X and vector y into batches\n",
    "def batchify(X, y, batchsize):\n",
    "    nTrain = X.shape[0]\n",
    "    batchdata = []\n",
    "    batchlabels = []\n",
    "    for i in range(0, nTrain, batchsize):\n",
    "        nxt = min(i + batchsize, nTrain + 1)\n",
    "        batchdata.append(X[i:nxt, :])\n",
    "        batchlabels.append(y[i:nxt])\n",
    "    return batchdata, batchlabels\n",
    "\n",
    "\n",
    "def stochgradSimple(objFun, w0, X, y, *args, **kwargs):\n",
    "    # Stochastic gradient descent.\n",
    "\n",
    "    # Algorithm works by breaking up the data into batches. It\n",
    "    # determines a gradient for each batch and moves the current\n",
    "    # choice of parameters in that direction. The extent to which\n",
    "    # we move in that direction is determined by our shrinking\n",
    "    # stepsize over time.\n",
    "\n",
    "    # Includes options for the batchsize, total number of sweeps over\n",
    "    # the data (maxepoch), total number of batches inspected (maxUpdated,\n",
    "    # whether the algo should print updates as it progresses, options\n",
    "    # controlling what infomation we keep track of,and parameters to\n",
    "    # determine how the step size shinks over time.\n",
    "\n",
    "    # Default options\n",
    "    batchsize = kwargs[\"batchsize\"] if \"batchsize\" in kwargs else 10\n",
    "    maxepoch = kwargs[\"maxepoch\"] if \"maxepoch\" in kwargs else 500\n",
    "    maxUpdates = kwargs[\"maxUpdates\"] if \"maxUpdates\" in kwargs else 1000\n",
    "    verbose = kwargs[\"verbose\"] if \"verbose\" in kwargs else False\n",
    "    storeParamTrace = kwargs[\"storeParamTrace\"] if \"storeParamTrace\" in kwargs else False\n",
    "    storeFvalTrace = kwargs[\"storeFvalTrace\"] if \"storeFvalTrace\" in kwargs else False\n",
    "    storeStepTrace = kwargs[\"storeStepTrace\"] if \"storeStepTrace\" in kwargs else False\n",
    "    t0 = kwargs[\"t0\"] if \"t0\" in kwargs else 1\n",
    "    eta0 = kwargs[\"eta0\"] if \"eta0\" in kwargs else 0.1\n",
    "    stepSizeFn = kwargs[\"stepSizeFn\"] if \"stepSizeFn\" in kwargs else lambda x: eta0 * t0 / (x + t0)\n",
    "\n",
    "    # Turn the data into batches\n",
    "    batchdata, batchlabels = batchify(X, y, batchsize)\n",
    "    num_batches = len(batchlabels)\n",
    "    if verbose:\n",
    "        print(\"%d batches of size %d\\n\" % (num_batches, batchsize))\n",
    "\n",
    "    w = w0\n",
    "    trace = {}\n",
    "    trace[\"fvalMinibatch\"] = []\n",
    "    trace[\"params\"] = []\n",
    "    trace[\"stepSize\"] = []\n",
    "\n",
    "    # Main loop:\n",
    "    nupdates = 1\n",
    "    for epoch in range(1, maxepoch + 1):\n",
    "        if verbose:\n",
    "            print(\"epoch %d\\n\" % epoch)\n",
    "        for b in range(num_batches):\n",
    "            bdata = batchdata[b]\n",
    "            blabels = batchlabels[b]\n",
    "            if verbose and b % 100 == 0:\n",
    "                print(\"epoch %d batch %d nupdates %d\\n\" % (epoch, b, nupdates))\n",
    "            fb, g, _ = objFun(w, bdata, blabels, *args)\n",
    "            eta = stepSizeFn(nupdates)\n",
    "            w = w - eta * g  # steepest descent\n",
    "            nupdates += 1\n",
    "            if storeParamTrace:\n",
    "                # Storing the history of the parameters may take a lot of space\n",
    "                trace[\"params\"].append(w)\n",
    "            if storeFvalTrace:\n",
    "                trace[\"fvalMinibatch\"].append(fb)\n",
    "            if storeStepTrace:\n",
    "                trace[\"stepSize\"].append(eta)\n",
    "            if nupdates > maxUpdates:\n",
    "                break\n",
    "        if nupdates > maxUpdates:\n",
    "            break\n",
    "    return w, trace\n",
    "\n",
    "\n",
    "w, trace = stochgradSimple(LinregLossScaled, w0, X, y, **opts)\n",
    "\n",
    "\n",
    "def stochgradTracePostprocess(objFun, trace, X, y, *args):\n",
    "    # This is to determine the losses for each set of parameters\n",
    "    # chosen over the parameter path.\n",
    "    fvalhist = []\n",
    "    for t in range(len(trace)):\n",
    "        fval, _, _ = objFun(trace[t], X, y, *args)\n",
    "        fvalhist.append(fval)\n",
    "    return fvalhist\n",
    "\n",
    "\n",
    "print(w)\n",
    "whist = np.asarray(trace[\"params\"])\n",
    "\n",
    "# Parameter trajectory\n",
    "if True:\n",
    "    fig, ax = plt.subplots()\n",
    "    ax.set_title(\"LMS trajectory\")\n",
    "    CS = plt.contour(W0, W1, SS)\n",
    "    plt.plot(wOpt[0], wOpt[1], \"x\", color=\"r\", ms=10, mew=5)\n",
    "    plt.plot(whist[:, 0], whist[:, 1], \"ko-\", lw=2)\n",
    "    pml.savefig(\"lmsTraj.pdf\")\n",
    "    plt.draw()\n",
    "\n",
    "# Loss values over the parameter path compared to the optimal loss.\n",
    "if True:\n",
    "    fvalhist = np.asarray(stochgradTracePostprocess(LinregLossScaled, trace[\"params\"], X, y))\n",
    "    fig, ax = plt.subplots()\n",
    "    ax.set_title(\"RSS vs iteration\")\n",
    "    plt.plot(fvalhist, \"ko-\", lw=2)\n",
    "    plt.axhline(fopt)\n",
    "    pml.savefig(\"lmsRssHist.pdf\")\n",
    "    plt.draw()\n",
    "\n",
    "# Stepsize graph if desired:\n",
    "if True:\n",
    "    stephist = np.asarray(trace[\"stepSize\"])\n",
    "    fig, ax = plt.subplots()\n",
    "    ax.set_title(\"Stepsize vs iteration\")\n",
    "    plt.plot(stephist, \"ko-\", lw=2)\n",
    "    pml.savefig(\"lmsStepSizeHist.pdf\")\n",
    "    plt.draw()\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
