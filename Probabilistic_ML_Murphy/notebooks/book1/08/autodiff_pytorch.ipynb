{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "name": "autodiff-pytorch.ipynb",
   "provenance": [],
   "toc_visible": true,
   "include_colab_link": true
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  },
  "accelerator": "GPU"
 },
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "view-in-github",
    "colab_type": "text"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/probml/pyprobml/blob/master/book1/supplements/autodiff_pytorch.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "b520E1nCIBHc"
   },
   "source": [
    "\n",
    "# Automatic differentation using PyTorch\n",
    "\n",
    "We show how to do Automatic differentation using PyTorch.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "UeuOgABaIENZ"
   },
   "source": [
    "import sklearn\n",
    "import scipy\n",
    "import scipy.optimize\n",
    "import matplotlib.pyplot as plt\n",
    "import itertools\n",
    "import time\n",
    "from functools import partial\n",
    "import os\n",
    "\n",
    "import numpy as np\n",
    "from scipy.special import logsumexp\n",
    "\n",
    "np.set_printoptions(precision=3)"
   ],
   "execution_count": 1,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "GPozRwDAKFb8",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "b716e003-11c4-4c9d-9984-c3b325040b10"
   },
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "\n",
    "print(\"torch version {}\".format(torch.__version__))\n",
    "if torch.cuda.is_available():\n",
    "    print(torch.cuda.get_device_name(0))\n",
    "    print(\"current device {}\".format(torch.cuda.current_device()))\n",
    "else:\n",
    "    print(\"Torch cannot find GPU\")\n",
    "\n",
    "use_cuda = torch.cuda.is_available()\n",
    "device = torch.device(\"cuda:0\" if use_cuda else \"cpu\")"
   ],
   "execution_count": 2,
   "outputs": [
    {
     "output_type": "stream",
     "text": [
      "torch version 1.8.0+cu101\n",
      "Tesla P100-PCIE-16GB\n",
      "current device 0\n"
     ],
     "name": "stdout"
    }
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wCdU93g4V6_O"
   },
   "source": [
    "# Example: binary logistic regression\n",
    "\n",
    "Objective = NLL for binary logistic regression\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "aSYkjaAO6n3A",
    "outputId": "5a6caeb3-42e2-42f3-fd66-d18ca656ae1c"
   },
   "source": [
    "# Fit the model usign sklearn\n",
    "\n",
    "import sklearn.datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "iris = sklearn.datasets.load_iris()\n",
    "X = iris[\"data\"]\n",
    "y = (iris[\"target\"] == 2).astype(np.int)  # 1 if Iris-Virginica, else 0'\n",
    "N, D = X.shape  # 150, 4\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# We set C to a large number to turn off regularization.\n",
    "# We don't fit the bias term to simplify the comparison below.\n",
    "log_reg = LogisticRegression(solver=\"lbfgs\", C=1e5, fit_intercept=False)\n",
    "log_reg.fit(X_train, y_train)\n",
    "w_mle_sklearn = np.ravel(log_reg.coef_)\n",
    "print(w_mle_sklearn)"
   ],
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "text": [
      "[-4.414 -9.111  6.539 12.686]\n"
     ],
     "name": "stdout"
    }
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0p5y7b8NbyZp"
   },
   "source": [
    "## Computing gradients by hand\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "iS5AB9NjLZ_i"
   },
   "source": [
    "# Binary cross entropy\n",
    "def BCE_with_logits(logits, targets):\n",
    "    N = logits.shape[0]\n",
    "    logits = logits.reshape(N, 1)\n",
    "    logits_plus = np.hstack([np.zeros((N, 1)), logits])  # e^0=1\n",
    "    logits_minus = np.hstack([np.zeros((N, 1)), -logits])\n",
    "    logp1 = -logsumexp(logits_minus, axis=1)\n",
    "    logp0 = -logsumexp(logits_plus, axis=1)\n",
    "    logprobs = logp1 * targets + logp0 * (1 - targets)\n",
    "    return -np.sum(logprobs) / N\n",
    "\n",
    "\n",
    "# Compute using numpy\n",
    "def sigmoid(x):\n",
    "    return 0.5 * (np.tanh(x / 2.0) + 1)\n",
    "\n",
    "\n",
    "def predict_logit(weights, inputs):\n",
    "    return np.dot(inputs, weights)  # Already vectorized\n",
    "\n",
    "\n",
    "def predict_np(weights, inputs):\n",
    "    return sigmoid(predict_logit(weights, inputs))\n",
    "\n",
    "\n",
    "def NLL(weights, batch):\n",
    "    X, y = batch\n",
    "    logits = predict_logit(weights, X)\n",
    "    return BCE_with_logits(logits, y)\n",
    "\n",
    "\n",
    "def NLL_grad(weights, batch):\n",
    "    X, y = batch\n",
    "    N = X.shape[0]\n",
    "    mu = predict_np(weights, X)\n",
    "    g = np.sum(np.dot(np.diag(mu - y), X), axis=0) / N\n",
    "    return g"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "f9mD8S18746_",
    "outputId": "e023b766-2aaf-47bd-f552-3575c226e998"
   },
   "source": [
    "w_np = w_mle_sklearn\n",
    "y_pred = predict_np(w_np, X_test)\n",
    "loss_np = NLL(w_np, (X_test, y_test))\n",
    "grad_np = NLL_grad(w_np, (X_test, y_test))\n",
    "print(\"params {}\".format(w_np))\n",
    "# print(\"pred {}\".format(y_pred))\n",
    "print(\"loss {}\".format(loss_np))\n",
    "print(\"grad {}\".format(grad_np))"
   ],
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "text": [
      "params [-4.414 -9.111 6.539 12.686]\n",
      "loss 0.1182400709961879\n",
      "grad [-0.235 -0.122 -0.198 -0.064]\n"
     ],
     "name": "stdout"
    }
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YeGQ7SJTNHMk"
   },
   "source": [
    "## PyTorch code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Is7yJlgsL4BT"
   },
   "source": [
    "To compute the gradient using torch, we proceed as follows.\n",
    "\n",
    "- declare all the variables that you want to take derivatives with respect to using the requires_grad=True argumnet\n",
    "- define the (scalar output) objective function you want to differentiate in terms of these variables, and evaluate it at a point. This will generate a computation graph and store all the tensors.\n",
    "- call objective.backward() to trigger backpropagation (chain rule) on this graph.\n",
    "- extract the gradients from each variable using variable.grad field. (These will be torch tensors.)\n",
    "\n",
    "See the example below."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "Wl_SK0WUlvNl"
   },
   "source": [
    "# data. By default, numpy uses double but torch uses float\n",
    "X_train_t = torch.tensor(X_train, dtype=torch.float)\n",
    "y_train_t = torch.tensor(y_train, dtype=torch.float)\n",
    "\n",
    "X_test_t = torch.tensor(X_test, dtype=torch.float)\n",
    "y_test_t = torch.tensor(y_test, dtype=torch.float)"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "0L5NxIaVLu64",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "a4cd1bbd-7069-4e5f-ade7-5e563a0fe11d"
   },
   "source": [
    "# parameters\n",
    "W = np.reshape(w_mle_sklearn, [D, 1])  # convert 1d vector to 2d matrix\n",
    "w_torch = torch.tensor(W, requires_grad=True, dtype=torch.float)\n",
    "# w_torch.requires_grad_()\n",
    "\n",
    "\n",
    "# binary logistic regression in one line of Pytorch\n",
    "def predict(X, w):\n",
    "    y_pred = torch.sigmoid(torch.matmul(X, w))[:, 0]\n",
    "    return y_pred\n",
    "\n",
    "\n",
    "# This returns Nx1 probabilities\n",
    "y_pred = predict(X_test_t, w_torch)\n",
    "\n",
    "# loss function is average NLL\n",
    "criterion = torch.nn.BCELoss(reduction=\"mean\")\n",
    "loss_torch = criterion(y_pred, y_test_t)\n",
    "print(loss_torch)\n",
    "\n",
    "# Backprop\n",
    "loss_torch.backward()\n",
    "print(w_torch.grad)\n",
    "\n",
    "# convert to numpy. We have to \"detach\" the gradient tracing feature\n",
    "loss_torch = loss_torch.detach().numpy()\n",
    "grad_torch = w_torch.grad[:, 0].detach().numpy()"
   ],
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "text": [
      "tensor(0.1182, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "tensor([[-0.2353],\n",
      "        [-0.1223],\n",
      "        [-0.1976],\n",
      "        [-0.0638]])\n"
     ],
     "name": "stdout"
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "CSKAJvrBNKQC",
    "outputId": "db315c9e-db41-46be-9bea-62f1d6c670c5"
   },
   "source": [
    "# Test\n",
    "assert np.allclose(loss_np, loss_torch)\n",
    "assert np.allclose(grad_np, grad_torch)\n",
    "\n",
    "print(\"loss {}\".format(loss_torch))\n",
    "print(\"grad {}\".format(grad_torch))"
   ],
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "text": [
      "loss 0.11824005842208862\n",
      "grad [-0.235 -0.122 -0.198 -0.064]\n"
     ],
     "name": "stdout"
    }
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wnDGAWolHvr6"
   },
   "source": [
    "# Autograd on a DNN\n",
    "\n",
    "Below we show how to define more complex deep neural networks, and how to access\n",
    "their parameters. We can then call backward() on the scalar loss function, and extract their gradients. We base our presentation on http://d2l.ai/chapter_deep-learning-computation/parameters.html."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "V2U62DaVJWdZ"
   },
   "source": [
    "## Sequential models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hJLeA_iSILO9"
   },
   "source": [
    "First we create a shallow MLP."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wF1XbC4FINmU",
    "outputId": "43075b01-fdb0-442f-c752-0caaf9cdf95d"
   },
   "source": [
    "torch.manual_seed(0)\n",
    "net = nn.Sequential(nn.Linear(4, 8), nn.ReLU(), nn.Linear(8, 1))\n",
    "X = torch.rand(size=(2, 4))  # batch x Din, batch=2, Din=4\n",
    "out = net(X)  # batch x Dout, Dout=1\n",
    "print(out)"
   ],
   "execution_count": 3,
   "outputs": [
    {
     "output_type": "stream",
     "text": [
      "tensor([[-0.2531],\n",
      "        [-0.3098]], grad_fn=<AddmmBackward>)\n"
     ],
     "name": "stdout"
    }
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lqm0UMNqImmo"
   },
   "source": [
    "Let's visualize the model and all the parameters in each layer."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "NRpwKHHkIqGB",
    "outputId": "699f940b-ac43-42b5-e520-3fab8ac00cb6"
   },
   "source": [
    "print(net)"
   ],
   "execution_count": 4,
   "outputs": [
    {
     "output_type": "stream",
     "text": [
      "Sequential(\n",
      "  (0): Linear(in_features=4, out_features=8, bias=True)\n",
      "  (1): ReLU()\n",
      "  (2): Linear(in_features=8, out_features=1, bias=True)\n",
      ")\n"
     ],
     "name": "stdout"
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4awxRZVWIrZ5",
    "outputId": "cb526a22-c1ac-4fd9-8fd0-55c4d8c1f89b"
   },
   "source": [
    "for i in range(3):\n",
    "    print(f\"layer {i}\")\n",
    "    print(net[i].state_dict())"
   ],
   "execution_count": 6,
   "outputs": [
    {
     "output_type": "stream",
     "text": [
      "layer 0\n",
      "OrderedDict([('weight', tensor([[-0.0037,  0.2682, -0.4115, -0.3680],\n",
      "        [-0.1926,  0.1341, -0.0099,  0.3964],\n",
      "        [-0.0444,  0.1323, -0.1511, -0.0983],\n",
      "        [-0.4777, -0.3311, -0.2061,  0.0185],\n",
      "        [ 0.1977,  0.3000, -0.3390, -0.2177],\n",
      "        [ 0.1816,  0.4152, -0.1029,  0.3742],\n",
      "        [-0.0806,  0.0529,  0.4527, -0.4638],\n",
      "        [-0.3148, -0.1266, -0.1949,  0.4320]])), ('bias', tensor([-0.3241, -0.2302, -0.3493, -0.4683, -0.2919,  0.4298,  0.2231,  0.2423]))])\n",
      "layer 1\n",
      "OrderedDict()\n",
      "layer 2\n",
      "OrderedDict([('weight', tensor([[ 0.0186, -0.1813,  0.0598, -0.3301, -0.2555, -0.1823,  0.2231,  0.2073]])), ('bias', tensor([-0.1568]))])\n"
     ],
     "name": "stdout"
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2IQvcLI3JIao",
    "outputId": "70fb65ce-1aea-4bd6-ef90-42589f58910e"
   },
   "source": [
    "print(*[(name, param.shape) for name, param in net.named_parameters()])"
   ],
   "execution_count": 9,
   "outputs": [
    {
     "output_type": "stream",
     "text": [
      "('0.weight', torch.Size([8, 4])) ('0.bias', torch.Size([8])) ('2.weight', torch.Size([1, 8])) ('2.bias', torch.Size([1]))\n"
     ],
     "name": "stdout"
    }
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NOgo3ZDVI65-"
   },
   "source": [
    "Access a specific parameter."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9uc8WcZbI5lm",
    "outputId": "cb8d8dbe-23c4-4b1b-bfc4-f572a2763086"
   },
   "source": [
    "print(type(net[2].bias))\n",
    "print(net[2].bias)\n",
    "print(net[2].bias.data)\n",
    "\n",
    "print(net.state_dict()[\"2.bias\"].data)"
   ],
   "execution_count": 10,
   "outputs": [
    {
     "output_type": "stream",
     "text": [
      "<class 'torch.nn.parameter.Parameter'>\n",
      "Parameter containing:\n",
      "tensor([-0.1568], requires_grad=True)\n",
      "tensor([-0.1568])\n",
      "tensor([-0.1568])\n"
     ],
     "name": "stdout"
    }
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "n3jLejNZJCr0"
   },
   "source": [
    "The gradient is not defined until we call backward."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "k24THwyaJFLy",
    "outputId": "7606013b-f2e5-48f3-f768-b59fc7d68802"
   },
   "source": [
    "net[2].weight.grad == None"
   ],
   "execution_count": 8,
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "metadata": {
      "tags": []
     },
     "execution_count": 8
    }
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9SWFmadHJYwh"
   },
   "source": [
    "## Nested models"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4C7zBkNbJab9",
    "outputId": "aa803c46-c2a8-4c81-d267-8a710cba557b"
   },
   "source": [
    "def block1():\n",
    "    return nn.Sequential(nn.Linear(4, 8), nn.ReLU(), nn.Linear(8, 4), nn.ReLU())\n",
    "\n",
    "\n",
    "def block2():\n",
    "    net = nn.Sequential()\n",
    "    for i in range(4):\n",
    "        # Nested here\n",
    "        net.add_module(f\"block {i}\", block1())\n",
    "    return net\n",
    "\n",
    "\n",
    "rgnet = nn.Sequential(block2(), nn.Linear(4, 1))\n",
    "print(rgnet(X))\n",
    "print(rgnet)"
   ],
   "execution_count": 12,
   "outputs": [
    {
     "output_type": "stream",
     "text": [
      "tensor([[0.2138],\n",
      "        [0.2138]], grad_fn=<AddmmBackward>)\n",
      "Sequential(\n",
      "  (0): Sequential(\n",
      "    (block 0): Sequential(\n",
      "      (0): Linear(in_features=4, out_features=8, bias=True)\n",
      "      (1): ReLU()\n",
      "      (2): Linear(in_features=8, out_features=4, bias=True)\n",
      "      (3): ReLU()\n",
      "    )\n",
      "    (block 1): Sequential(\n",
      "      (0): Linear(in_features=4, out_features=8, bias=True)\n",
      "      (1): ReLU()\n",
      "      (2): Linear(in_features=8, out_features=4, bias=True)\n",
      "      (3): ReLU()\n",
      "    )\n",
      "    (block 2): Sequential(\n",
      "      (0): Linear(in_features=4, out_features=8, bias=True)\n",
      "      (1): ReLU()\n",
      "      (2): Linear(in_features=8, out_features=4, bias=True)\n",
      "      (3): ReLU()\n",
      "    )\n",
      "    (block 3): Sequential(\n",
      "      (0): Linear(in_features=4, out_features=8, bias=True)\n",
      "      (1): ReLU()\n",
      "      (2): Linear(in_features=8, out_features=4, bias=True)\n",
      "      (3): ReLU()\n",
      "    )\n",
      "  )\n",
      "  (1): Linear(in_features=4, out_features=1, bias=True)\n",
      ")\n"
     ],
     "name": "stdout"
    }
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8OEtpNDYJkb8"
   },
   "source": [
    "Let us access the 0 element of the top level sequence,\n",
    "which is block 0-3. Then we access element 1 of this,\n",
    "which is block 1. Then we access element 0 of this, \n",
    "which is the first linear layer."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3Mw3kRZrJl4w",
    "outputId": "c4c283c1-b9cc-43ad-f476-ffe015003d3f"
   },
   "source": [
    "rgnet[0][1][0].bias.data"
   ],
   "execution_count": 13,
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "tensor([ 0.1753, -0.4905, -0.4271,  0.2333, -0.2832,  0.2405, -0.3530, -0.2477])"
      ]
     },
     "metadata": {
      "tags": []
     },
     "execution_count": 13
    }
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ptfMznAmJ9Pl"
   },
   "source": [
    "## Backprop"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0SBfDYcYJ-n1",
    "outputId": "6099ed4a-f174-4654-b4eb-71bce6a5b030"
   },
   "source": [
    "# set loss function to output squared\n",
    "out = rgnet(X)\n",
    "loss = torch.mean(out**2, dim=0)\n",
    "\n",
    "# Backprop\n",
    "loss.backward()\n",
    "print(rgnet[0][1][0].bias.grad)"
   ],
   "execution_count": 15,
   "outputs": [
    {
     "output_type": "stream",
     "text": [
      "tensor([-6.0363e-05,  0.0000e+00,  0.0000e+00,  7.7047e-05,  0.0000e+00,\n",
      "         5.7246e-05,  0.0000e+00,  0.0000e+00])\n"
     ],
     "name": "stdout"
    }
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LCkFzrRtNbQF"
   },
   "source": [
    "## Tied parameters\n",
    "\n",
    "Sometimes parameters are reused in multiple layers, as we show below.\n",
    "In this case, the gradients are added."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "dzbKIBg5NiLM",
    "outputId": "b0444359-3573-4f0e-beec-00edbfba5ea0",
    "colab": {
     "base_uri": "https://localhost:8080/"
    }
   },
   "source": [
    "# We need to give the shared layer a name so that we can refer to its\n",
    "# parameters\n",
    "torch.manual_seed(0)\n",
    "shared = nn.Linear(8, 8)\n",
    "net = nn.Sequential(nn.Linear(4, 8), nn.ReLU(), shared, nn.ReLU(), shared, nn.ReLU(), nn.Linear(8, 1))\n",
    "net(X)\n",
    "# Check whether the parameters are the same\n",
    "print(net[2].weight.data[0] == net[4].weight.data[0])\n",
    "net[2].weight.data[0, 0] = 100\n",
    "# Make sure that they are actually the same object rather than just having the\n",
    "# same value\n",
    "print(net[2].weight.data[0] == net[4].weight.data[0])"
   ],
   "execution_count": 16,
   "outputs": [
    {
     "output_type": "stream",
     "text": [
      "tensor([True, True, True, True, True, True, True, True])\n",
      "tensor([True, True, True, True, True, True, True, True])\n"
     ],
     "name": "stdout"
    }
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OxwspvGxTprm"
   },
   "source": [
    "# Other material\n",
    "\n",
    "- [Stackoverflow post on gradient accumulation](https://stackoverflow.com/questions/62067400/understanding-accumulated-gradients-in-pytorch)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mtKIyIrBU-s4"
   },
   "source": [
    "To compute gradient of a function that does not return a scalar\n",
    "(eg the gradient of each output wrt each input), you can do the following."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "QJG9BTRPUXqV",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "428735cf-8a41-480a-b9fc-fe69a1c6cb94"
   },
   "source": [
    "x = torch.tensor([-2, -1, 0, 1, 2], dtype=float, requires_grad=True)\n",
    "print(x)\n",
    "y = torch.pow(x, 2)\n",
    "print(y)\n",
    "y.backward(torch.ones_like(x))\n",
    "print(x.grad)"
   ],
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "text": [
      "tensor([-2., -1.,  0.,  1.,  2.], dtype=torch.float64, requires_grad=True)\n",
      "tensor([4., 1., 0., 1., 4.], dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "tensor([-4., -2.,  0.,  2.,  4.], dtype=torch.float64)\n"
     ],
     "name": "stdout"
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "KQHYKAQSVbAR"
   },
   "source": [
    ""
   ],
   "execution_count": null,
   "outputs": []
  }
 ]
}