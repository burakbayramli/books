{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acb98eed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Robust Bayesian Binary logistic regression in 1d for iris flowers\n",
    "\n",
    "# Code is based on\n",
    "# https://github.com/aloctavodia/BAP/blob/master/code/Chp4/04_Generalizing_linear_models.ipynb\n",
    "\n",
    "\n",
    "try:\n",
    "    import pymc3 as pm\n",
    "except ModuleNotFoundError:\n",
    "    %pip install -qq pymc3\n",
    "    import pymc3 as pm\n",
    "import numpy as np\n",
    "\n",
    "try:\n",
    "    import pandas as pd\n",
    "except ModuleNotFoundError:\n",
    "    %pip install -qq pandas\n",
    "    import pandas as pd\n",
    "try:\n",
    "    import theano.tensor as tt\n",
    "except ModuleNotFoundError:\n",
    "    %pip install -qq theano\n",
    "    import theano.tensor as tt\n",
    "# import seaborn as sns\n",
    "import scipy.stats as stats\n",
    "from scipy.special import expit as logistic\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "try:\n",
    "    import arviz as az\n",
    "except ModuleNotFoundError:\n",
    "    %pip install -qq arviz\n",
    "    import arviz as az\n",
    "try:\n",
    "    from sklearn.datasets import load_iris\n",
    "except ModuleNotFoundError:\n",
    "    %pip install -qq scikit-learn\n",
    "    from sklearn.datasets import load_iris\n",
    "try:\n",
    "    import probml_utils as pml\n",
    "except ModuleNotFoundError:\n",
    "    %pip install -qq git+https://github.com/probml/probml-utils.git\n",
    "    import probml_utils as pml\n",
    "\n",
    "iris = load_iris()\n",
    "X = iris.data\n",
    "y = iris.target\n",
    "\n",
    "# Convert to pandas dataframe\n",
    "df_iris = pd.DataFrame(data=iris.data, columns=[\"sepal_length\", \"sepal_width\", \"petal_length\", \"petal_width\"])\n",
    "df_iris[\"species\"] = pd.Series(iris.target_names[y], dtype=\"category\")\n",
    "\n",
    "\n",
    "df = df_iris.query(\"species == ('setosa', 'versicolor')\")\n",
    "y_0 = pd.Categorical(df[\"species\"]).codes\n",
    "x_n = \"sepal_length\"\n",
    "x_0 = df[x_n].values\n",
    "\n",
    "# Create outliers\n",
    "x_outliers = np.array([4.2, 4.5, 4.0, 4.3, 4.2, 4.4])\n",
    "y_outliers = np.ones_like(x_outliers, dtype=int)\n",
    "\n",
    "\n",
    "Ninliers = len(x_0)\n",
    "Noutliers = len(x_outliers)\n",
    "N = Ninliers + Noutliers\n",
    "inlier_ndx = np.arange(0, Ninliers)\n",
    "outlier_ndx = np.arange(Ninliers, N)\n",
    "\n",
    "y_0 = np.concatenate((y_0, y_outliers))\n",
    "x_0 = np.concatenate((x_0, x_outliers))\n",
    "\n",
    "xmean = np.mean(x_0)\n",
    "x_c = x_0 - xmean\n",
    "\n",
    "\n",
    "def plot_training_data():\n",
    "    plt.figure()\n",
    "    for c in [0, 1]:\n",
    "        ndx_c = np.where(y_0 == c)[0]\n",
    "        color = f\"C{c}\"\n",
    "        sigma = 0.02  # for vertical jittering\n",
    "        inliers = np.intersect1d(ndx_c, inlier_ndx)\n",
    "        plt.scatter(x_c[inliers], np.random.normal(y_0[inliers], sigma), marker=\"o\", color=color)\n",
    "        outliers = np.intersect1d(ndx_c, outlier_ndx)\n",
    "        plt.scatter(x_c[outliers], np.random.normal(y_0[outliers], sigma), marker=\"x\", color=color)\n",
    "\n",
    "    plt.xlabel(x_n)\n",
    "    plt.ylabel(\"p(y=1)\", rotation=0)\n",
    "    # use original scale for xticks\n",
    "    locs, _ = plt.xticks()\n",
    "    plt.xticks(locs, np.round(locs + xmean, 1))\n",
    "    plt.tight_layout()\n",
    "\n",
    "\n",
    "def infer_nonrobust_model():\n",
    "    with pm.Model() as model_0:\n",
    "        α = pm.Normal(\"α\", mu=0, sd=10)\n",
    "        β = pm.Normal(\"β\", mu=0, sd=10)\n",
    "\n",
    "        μ = α + pm.math.dot(x_c, β)\n",
    "        θ = pm.Deterministic(\"θ\", pm.math.sigmoid(μ))\n",
    "        bd = pm.Deterministic(\"bd\", -α / β)  # decision boundary\n",
    "\n",
    "        yl = pm.Bernoulli(\"yl\", p=θ, observed=y_0)\n",
    "\n",
    "        trace = pm.sample(1000, cores=1, chains=2)\n",
    "\n",
    "    varnames = [\"α\", \"β\", \"bd\"]\n",
    "    az.summary(trace, varnames)\n",
    "    return trace\n",
    "\n",
    "\n",
    "def infer_robust_model():\n",
    "    with pm.Model() as model_0:\n",
    "        α = pm.Normal(\"α\", mu=0, sd=10)\n",
    "        β = pm.Normal(\"β\", mu=0, sd=10)\n",
    "\n",
    "        μ = α + pm.math.dot(x_c, β)\n",
    "        θ = pm.Deterministic(\"θ\", pm.math.sigmoid(μ))\n",
    "        bd = pm.Deterministic(\"bd\", -α / β)  # decision boundary\n",
    "\n",
    "        # yl = pm.Bernoulli('yl', p=θ, observed=y_0)\n",
    "        π = pm.Beta(\"π\", 1.0, 1.0)  # probability of contamination\n",
    "        p = π * 0.5 + (1 - π) * θ  # true prob or 0.5\n",
    "        yl = pm.Bernoulli(\"yl\", p=p, observed=y_0)\n",
    "\n",
    "        trace = pm.sample(1000, cores=1, chains=2)\n",
    "\n",
    "    varnames = [\"α\", \"β\", \"bd\", \"π\"]\n",
    "    az.summary(trace, varnames)\n",
    "    return trace\n",
    "\n",
    "\n",
    "def make_plot(trace):\n",
    "    plot_training_data()\n",
    "    # plot logistic curve\n",
    "    theta = trace[\"θ\"].mean(axis=0)\n",
    "    idx = np.argsort(x_c)\n",
    "    plt.plot(x_c[idx], theta[idx], color=\"C2\", lw=3)\n",
    "    az.plot_hdi(x_c, trace[\"θ\"], color=\"C2\")\n",
    "\n",
    "    # plot decision boundary\n",
    "    plt.vlines(trace[\"bd\"].mean(), 0, 1, color=\"k\")\n",
    "    bd_hpd = az.hdi(trace[\"bd\"])\n",
    "    plt.fill_betweenx([0, 1], bd_hpd[0], bd_hpd[1], color=\"k\", alpha=0.5)\n",
    "\n",
    "\n",
    "trace = infer_robust_model()\n",
    "make_plot(trace)\n",
    "pml.savefig(\"logreg_iris_bayes_robust_1d.pdf\", dpi=300)\n",
    "\n",
    "trace = infer_nonrobust_model()\n",
    "make_plot(trace)\n",
    "pml.savefig(\"logreg_iris_bayes_nonrobust_1d.pdf\", dpi=300)\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
